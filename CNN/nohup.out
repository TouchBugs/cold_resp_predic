nohup: ignoring input
2024-06-22-18:28:00
冻排序残差阈值0.4
创建模型实例
模型实例创建完成
加载预训练参数
预训练参数加载完成
Epoch [1/100], Loss: 61.6257
train_Accuracy: [91m0.7926[0m
train_Precision: [4;34m0.7784[0m,               train_Recall: [4;33m0.8297[0m,                 train_F1 Score: [4;35m0.7969[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3408
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7659],
        [0.9307],
        [0.9170],
        [0.0797],
        [0.8230],
        [0.2869],
        [0.2926],
        [0.4595],
        [0.5416],
        [0.7971],
        [0.0456],
        [0.0408]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 15), 1)
((1, 30), 1)
((2, 22), 1)
((3, 28), 1)
((4, 31), 1)
((5, 29), 1)
((6, 27), 1)
((7, 27), 1)
((8, 30), 1)
((9, 19), 1)
((10, 24), 1)
((11, 17), 1)
((12, 25), 1)
((13, 30), 1)
((14, 19), 1)
((15, 23), 1)
((16, 28), 1)
((17, 29), 1)
((18, 25), 1)
((19, 29), 1)
((20, 31), 1)
((21, 27), 1)
((22, 31), 1)
((23, 30), 1)
((24, 30), 1)
((25, 29), 1)
((26, 21), 1)
Epoch [1/100], Loss: 15.0428
val_Accuracy: [92m0.7942[0m
val_Precision: [4;34m0.8368[0m,               val_Recall: [4;33m0.7252[0m,                 val_F1 Score: [4;35m0.7706[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  683
Epoch [2/100], Loss: 57.8046
train_Accuracy: [91m0.8121[0m
train_Precision: [4;34m0.8006[0m,               train_Recall: [4;33m0.8416[0m,                 train_F1 Score: [4;35m0.8148[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3492
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8014],
        [0.9325],
        [0.9208],
        [0.0834],
        [0.8431],
        [0.2533],
        [0.2662],
        [0.3774],
        [0.5409],
        [0.8186],
        [0.0472],
        [0.0461]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 21), 1)
((1, 13), 1)
((1, 13), 1)
((3, 15), 1)
((4, 21), 1)
((5, 30), 1)
((6, 30), 1)
((7, 13), 1)
((8, 14), 1)
((9, 23), 1)
((10, 0), 1)
((11, 23), 1)
((12, 18), 1)
((13, 0), 1)
((14, 2), 1)
((15, 31), 1)
((16, 24), 1)
((16, 24), 1)
((16, 24), 1)
((19, 12), 1)
((20, 29), 1)
((21, 22), 1)
((21, 22), 1)
((21, 22), 1)
((24, 31), 1)
((24, 31), 1)
((24, 31), 1)
Epoch [2/100], Loss: 16.8824
val_Accuracy: [92m0.7733[0m
val_Precision: [4;34m0.8559[0m,               val_Recall: [4;33m0.6487[0m,                 val_F1 Score: [4;35m0.7293[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  665
Epoch [3/100], Loss: 56.4336
train_Accuracy: [91m0.8153[0m
train_Precision: [4;34m0.8022[0m,               train_Recall: [4;33m0.8470[0m,                 train_F1 Score: [4;35m0.8184[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3506
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8394],
        [0.9184],
        [0.9277],
        [0.0878],
        [0.8586],
        [0.2546],
        [0.2480],
        [0.3622],
        [0.5790],
        [0.8454],
        [0.0389],
        [0.0444]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 30), 1)
((0, 30), 1)
((0, 30), 1)
((3, 10), 1)
((4, 25), 1)
((5, 23), 1)
((5, 23), 1)
((5, 23), 1)
((5, 23), 1)
((9, 24), 1)
((9, 24), 1)
((9, 24), 1)
((12, 7), 1)
((13, 6), 1)
((13, 6), 1)
((13, 6), 1)
((13, 6), 1)
((17, 31), 1)
((17, 31), 1)
((17, 31), 1)
((17, 31), 1)
((21, 9), 1)
((21, 9), 1)
((23, 8), 1)
((23, 8), 1)
((25, 15), 1)
((25, 15), 1)
Epoch [3/100], Loss: 17.9393
val_Accuracy: [92m0.7547[0m
val_Precision: [4;34m0.8529[0m,               val_Recall: [4;33m0.6123[0m,                 val_F1 Score: [4;35m0.7037[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  649
Epoch [4/100], Loss: 55.2538
train_Accuracy: [91m0.8200[0m
train_Precision: [4;34m0.8078[0m,               train_Recall: [4;33m0.8506[0m,                 train_F1 Score: [4;35m0.8230[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3526
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8304],
        [0.9141],
        [0.9377],
        [0.0782],
        [0.8636],
        [0.2531],
        [0.2328],
        [0.3542],
        [0.5952],
        [0.8629],
        [0.0361],
        [0.0483]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 15), 1)
((25, 15), 1)
((25, 15), 1)
((25, 15), 1)
((25, 15), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
Epoch [4/100], Loss: 17.9007
val_Accuracy: [92m0.7733[0m
val_Precision: [4;34m0.8711[0m,               val_Recall: [4;33m0.6452[0m,                 val_F1 Score: [4;35m0.7278[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  665
Epoch [5/100], Loss: 54.2040
train_Accuracy: [91m0.8240[0m
train_Precision: [4;34m0.8093[0m,               train_Recall: [4;33m0.8567[0m,                 train_F1 Score: [4;35m0.8270[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3543
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8670],
        [0.9050],
        [0.9355],
        [0.0739],
        [0.8528],
        [0.2786],
        [0.2122],
        [0.3451],
        [0.6161],
        [0.8710],
        [0.0299],
        [0.0542]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((5, 18), 1)
((6, 22), 1)
((6, 22), 1)
((6, 22), 1)
((6, 22), 1)
((6, 22), 1)
((6, 22), 1)
((12, 21), 1)
((12, 21), 1)
((12, 21), 1)
((12, 21), 1)
((12, 21), 1)
((12, 21), 1)
((12, 21), 1)
((12, 21), 1)
((12, 21), 1)
((12, 21), 1)
((22, 11), 1)
((22, 11), 1)
((22, 11), 1)
((22, 11), 1)
((26, 25), 1)
Epoch [5/100], Loss: 17.4914
val_Accuracy: [92m0.7709[0m
val_Precision: [4;34m0.8498[0m,               val_Recall: [4;33m0.6536[0m,                 val_F1 Score: [4;35m0.7297[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  663
Epoch [6/100], Loss: 53.1984
train_Accuracy: [91m0.8267[0m
train_Precision: [4;34m0.8115[0m,               train_Recall: [4;33m0.8610[0m,                 train_F1 Score: [4;35m0.8302[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3555
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8620],
        [0.8919],
        [0.9405],
        [0.0795],
        [0.8600],
        [0.2528],
        [0.2130],
        [0.3399],
        [0.6581],
        [0.9000],
        [0.0265],
        [0.0471]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
((1, 8), 1)
Epoch [6/100], Loss: 17.2548
val_Accuracy: [92m0.7814[0m
val_Precision: [4;34m0.8527[0m,               val_Recall: [4;33m0.6732[0m,                 val_F1 Score: [4;35m0.7435[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  672
Epoch [7/100], Loss: 52.0675
train_Accuracy: [91m0.8295[0m
train_Precision: [4;34m0.8127[0m,               train_Recall: [4;33m0.8658[0m,                 train_F1 Score: [4;35m0.8332[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3567
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8589],
        [0.9001],
        [0.9444],
        [0.0658],
        [0.8896],
        [0.2355],
        [0.1664],
        [0.3406],
        [0.7277],
        [0.9187],
        [0.0240],
        [0.0492]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((1, 8), 1)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
((1, 8), 2)
Epoch [7/100], Loss: 17.4307
val_Accuracy: [92m0.7814[0m
val_Precision: [4;34m0.8496[0m,               val_Recall: [4;33m0.6822[0m,                 val_F1 Score: [4;35m0.7484[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  672
Epoch [8/100], Loss: 51.0480
train_Accuracy: [91m0.8302[0m
train_Precision: [4;34m0.8118[0m,               train_Recall: [4;33m0.8688[0m,                 train_F1 Score: [4;35m0.8340[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3570
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8762],
        [0.9067],
        [0.9510],
        [0.0758],
        [0.9063],
        [0.2226],
        [0.1279],
        [0.3268],
        [0.7394],
        [0.9141],
        [0.0212],
        [0.0419]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((1, 8), 2)
((1, 8), 3)
((1, 8), 3)
((1, 8), 3)
((1, 8), 3)
((1, 8), 3)
((1, 8), 3)
((1, 8), 3)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
Epoch [8/100], Loss: 17.3065
val_Accuracy: [92m0.7872[0m
val_Precision: [4;34m0.8427[0m,               val_Recall: [4;33m0.6978[0m,                 val_F1 Score: [4;35m0.7567[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  677
Epoch [9/100], Loss: 49.8198
train_Accuracy: [91m0.8367[0m
train_Precision: [4;34m0.8171[0m,               train_Recall: [4;33m0.8758[0m,                 train_F1 Score: [4;35m0.8403[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3598
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8958],
        [0.8852],
        [0.9618],
        [0.0843],
        [0.9394],
        [0.1511],
        [0.1204],
        [0.3051],
        [0.7921],
        [0.9240],
        [0.0201],
        [0.0470]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((4, 1), 1)
((4, 1), 1)
((6, 26), 1)
((6, 26), 1)
((6, 26), 1)
((6, 26), 1)
((6, 26), 1)
((6, 26), 1)
((6, 26), 1)
((6, 26), 1)
((6, 26), 1)
((15, 10), 1)
((15, 10), 1)
((15, 10), 1)
((15, 10), 1)
((15, 10), 1)
((20, 9), 1)
((20, 9), 1)
((20, 9), 1)
((23, 31), 1)
((23, 31), 1)
((23, 31), 1)
((23, 31), 1)
Epoch [9/100], Loss: 17.8509
val_Accuracy: [92m0.7802[0m
val_Precision: [4;34m0.8356[0m,               val_Recall: [4;33m0.6880[0m,                 val_F1 Score: [4;35m0.7481[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  671
Epoch [10/100], Loss: 48.3791
train_Accuracy: [91m0.8423[0m
train_Precision: [4;34m0.8236[0m,               train_Recall: [4;33m0.8806[0m,                 train_F1 Score: [4;35m0.8461[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3622
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8865],
        [0.8879],
        [0.9810],
        [0.0723],
        [0.9380],
        [0.1661],
        [0.0963],
        [0.2406],
        [0.8601],
        [0.9494],
        [0.0181],
        [0.0361]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((23, 31), 1)
((23, 31), 1)
((2, 7), 1)
((2, 7), 1)
((4, 11), 1)
((4, 11), 1)
((6, 3), 1)
((7, 4), 1)
((8, 11), 1)
((9, 31), 1)
((9, 31), 1)
((9, 31), 1)
((9, 31), 1)
((9, 31), 1)
((9, 31), 1)
((9, 31), 1)
((16, 30), 1)
((16, 30), 1)
((18, 29), 1)
((18, 29), 1)
((20, 7), 1)
((20, 7), 1)
((20, 7), 1)
((20, 7), 1)
((20, 7), 1)
((20, 7), 1)
((20, 7), 1)
Epoch [10/100], Loss: 16.6039
val_Accuracy: [92m0.7814[0m
val_Precision: [4;34m0.8132[0m,               val_Recall: [4;33m0.7250[0m,                 val_F1 Score: [4;35m0.7585[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  672
Epoch [11/100], Loss: 46.9800
train_Accuracy: [91m0.8470[0m
train_Precision: [4;34m0.8288[0m,               train_Recall: [4;33m0.8832[0m,                 train_F1 Score: [4;35m0.8502[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3642
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9000],
        [0.8928],
        [0.9918],
        [0.0721],
        [0.9246],
        [0.1707],
        [0.0846],
        [0.2226],
        [0.8725],
        [0.9543],
        [0.0126],
        [0.0236]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 6), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((1, 7), 1)
((13, 27), 1)
((13, 27), 1)
((13, 27), 1)
((13, 27), 1)
((13, 27), 1)
((18, 0), 1)
((18, 0), 1)
((18, 0), 1)
((18, 0), 1)
((18, 0), 1)
((18, 0), 1)
((18, 0), 1)
((25, 31), 1)
((25, 31), 1)
Epoch [11/100], Loss: 16.8072
val_Accuracy: [92m0.7767[0m
val_Precision: [4;34m0.8198[0m,               val_Recall: [4;33m0.7120[0m,                 val_F1 Score: [4;35m0.7520[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  668
Epoch [12/100], Loss: 45.6614
train_Accuracy: [91m0.8491[0m
train_Precision: [4;34m0.8321[0m,               train_Recall: [4;33m0.8831[0m,                 train_F1 Score: [4;35m0.8517[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3651
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8691],
        [0.9017],
        [0.9891],
        [0.0714],
        [0.9516],
        [0.1154],
        [0.0859],
        [0.1265],
        [0.9333],
        [0.9630],
        [0.0131],
        [0.0315]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 31), 1)
((1, 18), 1)
((2, 20), 1)
((3, 6), 1)
((4, 3), 1)
((4, 3), 1)
((4, 3), 1)
((4, 3), 1)
((4, 3), 1)
((9, 29), 1)
((9, 29), 1)
((11, 30), 1)
((12, 17), 1)
((12, 17), 1)
((12, 17), 1)
((12, 17), 1)
((12, 17), 1)
((17, 23), 1)
((17, 23), 1)
((17, 23), 1)
((17, 23), 1)
((17, 23), 1)
((22, 19), 1)
((22, 19), 1)
((22, 19), 1)
((25, 18), 1)
((25, 18), 1)
Epoch [12/100], Loss: 18.5007
val_Accuracy: [92m0.7535[0m
val_Precision: [4;34m0.8212[0m,               val_Recall: [4;33m0.6428[0m,                 val_F1 Score: [4;35m0.7141[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  648
Epoch [13/100], Loss: 43.9599
train_Accuracy: [91m0.8502[0m
train_Precision: [4;34m0.8332[0m,               train_Recall: [4;33m0.8836[0m,                 train_F1 Score: [4;35m0.8526[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3656
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8788],
        [0.9086],
        [0.9945],
        [0.0578],
        [0.9684],
        [0.1462],
        [0.0385],
        [0.0985],
        [0.9331],
        [0.9773],
        [0.0092],
        [0.0210]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 18), 1)
((25, 18), 1)
((25, 18), 1)
((25, 18), 1)
((25, 18), 1)
((5, 7), 1)
((5, 7), 1)
((5, 7), 1)
((5, 7), 1)
((9, 2), 1)
((9, 2), 1)
((11, 31), 1)
((12, 10), 1)
((13, 15), 1)
((13, 15), 1)
((13, 15), 1)
((13, 15), 1)
((17, 15), 1)
((18, 7), 1)
((18, 7), 1)
((20, 17), 1)
((20, 17), 1)
((22, 28), 1)
((22, 28), 1)
((22, 28), 1)
((22, 28), 1)
((22, 28), 1)
Epoch [13/100], Loss: 17.1516
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7934[0m,               val_Recall: [4;33m0.6855[0m,                 val_F1 Score: [4;35m0.7280[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [14/100], Loss: 41.8914
train_Accuracy: [91m0.8614[0m
train_Precision: [4;34m0.8443[0m,               train_Recall: [4;33m0.8934[0m,                 train_F1 Score: [4;35m0.8634[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3704
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9034],
        [0.8957],
        [0.9944],
        [0.0513],
        [0.9743],
        [0.0849],
        [0.0243],
        [0.1314],
        [0.9098],
        [0.9797],
        [0.0052],
        [0.0233]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 13), 1)
((1, 20), 1)
((1, 20), 1)
((3, 26), 1)
((4, 20), 1)
((4, 20), 1)
((4, 20), 1)
((7, 6), 1)
((7, 6), 1)
((7, 6), 1)
((10, 31), 1)
((10, 31), 1)
((10, 31), 1)
((13, 13), 1)
((13, 13), 1)
((15, 12), 1)
((16, 11), 1)
((16, 11), 1)
((18, 31), 1)
((19, 1), 1)
((20, 11), 1)
((21, 14), 1)
((22, 27), 1)
((22, 27), 1)
((24, 24), 1)
((25, 23), 1)
((26, 2), 1)
Epoch [14/100], Loss: 18.4276
val_Accuracy: [92m0.7337[0m
val_Precision: [4;34m0.7400[0m,               val_Recall: [4;33m0.7233[0m,                 val_F1 Score: [4;35m0.7257[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  631
Epoch [15/100], Loss: 39.6588
train_Accuracy: [91m0.8698[0m
train_Precision: [4;34m0.8523[0m,               train_Recall: [4;33m0.9000[0m,                 train_F1 Score: [4;35m0.8710[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3740
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9463],
        [0.9180],
        [0.9988],
        [0.0258],
        [0.9907],
        [0.0719],
        [0.0117],
        [0.0634],
        [0.8992],
        [0.9690],
        [0.0050],
        [0.0320]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 14), 1)
((1, 25), 1)
((2, 30), 1)
((2, 30), 1)
((4, 19), 1)
((4, 19), 1)
((4, 19), 1)
((7, 30), 1)
((7, 30), 1)
((7, 30), 1)
((7, 30), 1)
((11, 6), 1)
((11, 6), 1)
((11, 6), 1)
((14, 29), 1)
((15, 4), 1)
((16, 3), 1)
((17, 28), 1)
((17, 28), 1)
((19, 31), 1)
((19, 31), 1)
((19, 31), 1)
((19, 31), 1)
((23, 22), 1)
((23, 22), 1)
((23, 22), 1)
((26, 24), 1)
Epoch [15/100], Loss: 22.8707
val_Accuracy: [92m0.7163[0m
val_Precision: [4;34m0.7987[0m,               val_Recall: [4;33m0.5799[0m,                 val_F1 Score: [4;35m0.6645[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  616
Epoch [16/100], Loss: 37.8704
train_Accuracy: [91m0.8740[0m
train_Precision: [4;34m0.8529[0m,               train_Recall: [4;33m0.9088[0m,                 train_F1 Score: [4;35m0.8753[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3758
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9556],
        [0.8692],
        [0.9986],
        [0.0206],
        [0.9967],
        [0.0537],
        [0.0082],
        [0.0614],
        [0.9594],
        [0.9610],
        [0.0049],
        [0.0168]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 24), 1)
((26, 24), 1)
((26, 24), 1)
((26, 24), 1)
((26, 24), 1)
((26, 24), 1)
((26, 24), 1)
((26, 24), 1)
((26, 24), 1)
((26, 24), 1)
((10, 5), 1)
((10, 5), 1)
((10, 5), 1)
((10, 5), 1)
((10, 5), 1)
((10, 5), 1)
((16, 31), 1)
((17, 9), 1)
((17, 9), 1)
((17, 9), 1)
((17, 9), 1)
((17, 9), 1)
((17, 9), 1)
((17, 9), 1)
((17, 9), 1)
((17, 9), 1)
((17, 9), 1)
Epoch [16/100], Loss: 21.8278
val_Accuracy: [92m0.7558[0m
val_Precision: [4;34m0.7810[0m,               val_Recall: [4;33m0.7082[0m,                 val_F1 Score: [4;35m0.7367[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  650
Epoch [17/100], Loss: 35.3737
train_Accuracy: [91m0.8821[0m
train_Precision: [4;34m0.8656[0m,               train_Recall: [4;33m0.9119[0m,                 train_F1 Score: [4;35m0.8833[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3793
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9377],
        [0.8880],
        [0.9984],
        [0.0171],
        [0.9976],
        [0.0826],
        [0.0018],
        [0.1033],
        [0.9615],
        [0.9479],
        [0.0021],
        [0.0358]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 9), 1)
((1, 24), 1)
((1, 24), 1)
((1, 24), 1)
((1, 24), 1)
((1, 24), 1)
((6, 12), 1)
((6, 12), 1)
((6, 12), 1)
((6, 12), 1)
((10, 16), 1)
((11, 19), 1)
((12, 26), 1)
((13, 28), 1)
((14, 31), 1)
((14, 31), 1)
((14, 31), 1)
((14, 31), 1)
((14, 31), 1)
((14, 31), 1)
((14, 31), 1)
((21, 8), 1)
((22, 26), 1)
((22, 26), 1)
((24, 17), 1)
((24, 17), 1)
((24, 17), 1)
Epoch [17/100], Loss: 19.2043
val_Accuracy: [92m0.7384[0m
val_Precision: [4;34m0.7539[0m,               val_Recall: [4;33m0.7064[0m,                 val_F1 Score: [4;35m0.7250[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  635
Epoch [18/100], Loss: 32.7919
train_Accuracy: [91m0.8930[0m
train_Precision: [4;34m0.8751[0m,               train_Recall: [4;33m0.9244[0m,                 train_F1 Score: [4;35m0.8945[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3840
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9868],
        [0.8276],
        [0.9981],
        [0.0080],
        [0.9977],
        [0.0506],
        [0.0018],
        [0.0452],
        [0.9734],
        [0.9934],
        [0.0017],
        [0.0190]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 27), 1)
((0, 27), 1)
((0, 27), 1)
((0, 27), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((4, 24), 1)
((17, 30), 1)
((17, 30), 1)
((17, 30), 1)
((17, 30), 1)
((21, 28), 1)
((21, 28), 1)
((21, 28), 1)
((21, 28), 1)
((21, 28), 1)
((21, 28), 1)
Epoch [18/100], Loss: 24.0740
val_Accuracy: [92m0.7419[0m
val_Precision: [4;34m0.7950[0m,               val_Recall: [4;33m0.6593[0m,                 val_F1 Score: [4;35m0.7113[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  638
Epoch [19/100], Loss: 31.1800
train_Accuracy: [91m0.8960[0m
train_Precision: [4;34m0.8796[0m,               train_Recall: [4;33m0.9230[0m,                 train_F1 Score: [4;35m0.8964[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3853
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9313],
        [0.9838],
        [0.9994],
        [0.0053],
        [0.9926],
        [0.0386],
        [0.0017],
        [0.0220],
        [0.9821],
        [0.9952],
        [0.0012],
        [0.0088]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((21, 28), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((1, 14), 1)
((18, 18), 1)
((19, 26), 1)
((20, 23), 1)
((21, 26), 1)
((21, 26), 1)
((21, 26), 1)
((21, 26), 1)
((25, 9), 1)
((25, 9), 1)
Epoch [19/100], Loss: 30.3777
val_Accuracy: [92m0.7465[0m
val_Precision: [4;34m0.7618[0m,               val_Recall: [4;33m0.7033[0m,                 val_F1 Score: [4;35m0.7245[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  642
Epoch [20/100], Loss: 30.1426
train_Accuracy: [91m0.9051[0m
train_Precision: [4;34m0.8873[0m,               train_Recall: [4;33m0.9304[0m,                 train_F1 Score: [4;35m0.9052[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3892
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[8.7763e-01],
        [9.7770e-01],
        [9.9989e-01],
        [7.9280e-03],
        [9.9644e-01],
        [1.2313e-02],
        [9.3492e-04],
        [1.1041e-02],
        [9.0813e-01],
        [9.9886e-01],
        [5.6084e-03],
        [5.0325e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 9), 1)
((1, 9), 1)
((2, 29), 1)
((2, 29), 1)
((2, 29), 1)
((2, 29), 1)
((2, 29), 1)
((7, 21), 1)
((7, 21), 1)
((7, 21), 1)
((10, 29), 1)
((11, 15), 1)
((12, 30), 1)
((13, 24), 1)
((14, 7), 1)
((14, 7), 1)
((14, 7), 1)
((14, 7), 1)
((14, 7), 1)
((14, 7), 1)
((20, 19), 1)
((21, 10), 1)
((21, 10), 1)
((23, 18), 1)
((24, 4), 1)
((25, 20), 1)
((25, 20), 1)
Epoch [20/100], Loss: 29.3871
val_Accuracy: [92m0.7151[0m
val_Precision: [4;34m0.8254[0m,               val_Recall: [4;33m0.5535[0m,                 val_F1 Score: [4;35m0.6478[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  615
Epoch [21/100], Loss: 27.2500
train_Accuracy: [91m0.9109[0m
train_Precision: [4;34m0.8939[0m,               train_Recall: [4;33m0.9354[0m,                 train_F1 Score: [4;35m0.9108[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3917
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9662e-01],
        [9.4777e-01],
        [9.9995e-01],
        [3.4838e-03],
        [9.9891e-01],
        [3.6444e-03],
        [4.1424e-04],
        [3.3119e-02],
        [9.6182e-01],
        [9.9470e-01],
        [1.0811e-03],
        [2.5119e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 20), 1)
((25, 20), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((5, 19), 1)
((6, 6), 1)
((7, 10), 1)
((7, 10), 1)
((9, 25), 1)
((9, 25), 1)
((9, 25), 1)
((9, 25), 1)
((13, 2), 1)
((13, 2), 1)
((15, 17), 1)
((15, 17), 1)
((17, 26), 1)
((17, 26), 1)
((17, 26), 1)
((20, 16), 1)
((20, 16), 1)
((20, 16), 1)
((23, 28), 1)
((24, 23), 1)
((25, 21), 1)
((26, 22), 1)
Epoch [21/100], Loss: 40.3308
val_Accuracy: [92m0.7023[0m
val_Precision: [4;34m0.8667[0m,               val_Recall: [4;33m0.4822[0m,                 val_F1 Score: [4;35m0.6068[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  604
Epoch [22/100], Loss: 25.2520
train_Accuracy: [91m0.9195[0m
train_Precision: [4;34m0.9047[0m,               train_Recall: [4;33m0.9405[0m,                 train_F1 Score: [4;35m0.9191[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3954
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.5539e-01],
        [9.8523e-01],
        [9.9969e-01],
        [1.1546e-03],
        [9.9981e-01],
        [2.8358e-02],
        [8.0064e-04],
        [3.8977e-03],
        [9.7137e-01],
        [9.9956e-01],
        [9.0585e-04],
        [6.4177e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 22), 1)
((26, 22), 1)
((2, 15), 1)
((2, 15), 1)
((2, 15), 1)
((5, 27), 1)
((5, 27), 1)
((5, 27), 1)
((5, 27), 1)
((9, 15), 1)
((10, 20), 1)
((11, 13), 1)
((12, 15), 1)
((12, 15), 1)
((14, 12), 1)
((15, 3), 1)
((15, 3), 1)
((15, 3), 1)
((15, 3), 1)
((15, 3), 1)
((15, 3), 1)
((15, 3), 1)
((15, 3), 1)
((15, 3), 1)
((24, 20), 1)
((24, 20), 1)
((24, 20), 1)
Epoch [22/100], Loss: 41.5962
val_Accuracy: [92m0.7512[0m
val_Precision: [4;34m0.7569[0m,               val_Recall: [4;33m0.7423[0m,                 val_F1 Score: [4;35m0.7419[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  646
Epoch [23/100], Loss: 23.4809
train_Accuracy: [91m0.9244[0m
train_Precision: [4;34m0.9097[0m,               train_Recall: [4;33m0.9471[0m,                 train_F1 Score: [4;35m0.9244[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3975
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9941e-01],
        [9.7601e-01],
        [1.0000e+00],
        [4.2032e-03],
        [9.9980e-01],
        [2.5425e-03],
        [2.5391e-05],
        [3.5720e-02],
        [9.8566e-01],
        [9.9854e-01],
        [2.7756e-04],
        [9.2841e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((24, 20), 1)
((1, 10), 1)
((1, 10), 1)
((1, 10), 1)
((1, 10), 1)
((1, 10), 1)
((1, 10), 1)
((1, 10), 1)
((1, 10), 1)
((1, 10), 1)
((1, 10), 1)
((1, 10), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((12, 22), 1)
((24, 18), 1)
((24, 18), 1)
((24, 18), 1)
Epoch [23/100], Loss: 38.7819
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7675[0m,               val_Recall: [4;33m0.7166[0m,                 val_F1 Score: [4;35m0.7334[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [24/100], Loss: 21.4663
train_Accuracy: [91m0.9342[0m
train_Precision: [4;34m0.9212[0m,               train_Recall: [4;33m0.9507[0m,                 train_F1 Score: [4;35m0.9331[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4017
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9998e-01],
        [9.4097e-01],
        [9.9999e-01],
        [2.2851e-03],
        [9.9827e-01],
        [1.4773e-03],
        [3.5076e-06],
        [6.5948e-03],
        [9.9051e-01],
        [9.9951e-01],
        [9.7288e-05],
        [1.6777e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((24, 18), 1)
((24, 18), 1)
((2, 8), 1)
((3, 18), 1)
((4, 17), 1)
((4, 17), 1)
((6, 19), 1)
((7, 28), 1)
((8, 7), 1)
((8, 7), 1)
((10, 25), 1)
((10, 25), 1)
((10, 25), 1)
((10, 25), 1)
((10, 25), 1)
((15, 15), 1)
((15, 15), 1)
((15, 15), 1)
((15, 15), 1)
((19, 20), 1)
((19, 20), 1)
((19, 20), 1)
((22, 15), 1)
((22, 15), 1)
((24, 25), 1)
((24, 25), 1)
((26, 27), 1)
Epoch [24/100], Loss: 33.3990
val_Accuracy: [92m0.6965[0m
val_Precision: [4;34m0.7731[0m,               val_Recall: [4;33m0.5697[0m,                 val_F1 Score: [4;35m0.6478[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  599
Epoch [25/100], Loss: 20.6233
train_Accuracy: [91m0.9374[0m
train_Precision: [4;34m0.9239[0m,               train_Recall: [4;33m0.9559[0m,                 train_F1 Score: [4;35m0.9371[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4031
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9997e-01],
        [9.8825e-01],
        [1.0000e+00],
        [1.8384e-03],
        [9.9362e-01],
        [4.1233e-03],
        [3.7584e-05],
        [2.6191e-03],
        [9.8104e-01],
        [9.9808e-01],
        [1.3171e-05],
        [2.8961e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((5, 8), 1)
((5, 8), 1)
((7, 31), 1)
((7, 31), 1)
((7, 31), 1)
((7, 31), 1)
((7, 31), 1)
((7, 31), 1)
((7, 31), 1)
((7, 31), 1)
((7, 31), 1)
((16, 5), 1)
((16, 5), 1)
((16, 5), 1)
((16, 5), 1)
((16, 5), 1)
((16, 5), 1)
((16, 5), 1)
((23, 5), 1)
((23, 5), 1)
((23, 5), 1)
((26, 11), 1)
Epoch [25/100], Loss: 39.1743
val_Accuracy: [92m0.7000[0m
val_Precision: [4;34m0.8170[0m,               val_Recall: [4;33m0.5277[0m,                 val_F1 Score: [4;35m0.6319[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  602
Epoch [26/100], Loss: 17.7372
train_Accuracy: [91m0.9481[0m
train_Precision: [4;34m0.9381[0m,               train_Recall: [4;33m0.9610[0m,                 train_F1 Score: [4;35m0.9474[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4077
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9997e-01],
        [9.6863e-01],
        [1.0000e+00],
        [1.9768e-03],
        [9.9714e-01],
        [4.9545e-02],
        [1.1150e-06],
        [2.1780e-02],
        [9.5753e-01],
        [9.9887e-01],
        [5.1517e-06],
        [1.5920e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
((26, 11), 1)
Epoch [26/100], Loss: 38.4826
val_Accuracy: [92m0.7384[0m
val_Precision: [4;34m0.8056[0m,               val_Recall: [4;33m0.6335[0m,                 val_F1 Score: [4;35m0.7009[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  635
Epoch [27/100], Loss: 18.3930
train_Accuracy: [91m0.9435[0m
train_Precision: [4;34m0.9319[0m,               train_Recall: [4;33m0.9584[0m,                 train_F1 Score: [4;35m0.9429[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4057
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9637e-01],
        [9.9947e-01],
        [1.0000e+00],
        [5.9876e-03],
        [9.8875e-01],
        [3.0187e-02],
        [8.1299e-06],
        [6.8444e-02],
        [9.9772e-01],
        [9.9967e-01],
        [1.0030e-05],
        [1.8089e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 11), 1)
((26, 11), 1)
((2, 18), 1)
((3, 11), 1)
((4, 16), 1)
((4, 16), 1)
((6, 13), 1)
((7, 15), 1)
((8, 23), 1)
((8, 23), 1)
((10, 18), 1)
((11, 14), 1)
((12, 31), 1)
((13, 20), 1)
((14, 28), 1)
((15, 29), 1)
((16, 19), 1)
((16, 19), 1)
((18, 26), 1)
((19, 30), 1)
((20, 5), 1)
((21, 30), 1)
((22, 20), 1)
((22, 20), 1)
((24, 19), 1)
((25, 19), 1)
((26, 0), 1)
Epoch [27/100], Loss: 47.6245
val_Accuracy: [92m0.7081[0m
val_Precision: [4;34m0.6707[0m,               val_Recall: [4;33m0.8319[0m,                 val_F1 Score: [4;35m0.7365[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  609
Epoch [28/100], Loss: 17.7864
train_Accuracy: [91m0.9481[0m
train_Precision: [4;34m0.9345[0m,               train_Recall: [4;33m0.9662[0m,                 train_F1 Score: [4;35m0.9479[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4077
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9957e-01],
        [9.9930e-01],
        [1.0000e+00],
        [2.1608e-03],
        [9.9949e-01],
        [2.9261e-04],
        [3.0164e-06],
        [5.5856e-05],
        [9.9213e-01],
        [9.9992e-01],
        [8.2436e-06],
        [8.4028e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 0), 1)
((1, 19), 1)
((2, 27), 1)
((2, 27), 1)
((4, 27), 1)
((5, 25), 1)
((5, 25), 1)
((7, 25), 1)
((8, 25), 1)
((8, 25), 1)
((10, 28), 1)
((11, 27), 1)
((11, 27), 1)
((11, 27), 1)
((11, 27), 1)
((11, 27), 1)
((16, 17), 1)
((16, 17), 1)
((16, 17), 1)
((16, 17), 1)
((20, 30), 1)
((21, 5), 1)
((21, 5), 1)
((21, 5), 1)
((24, 14), 1)
((25, 26), 1)
((25, 26), 1)
Epoch [28/100], Loss: 35.0333
val_Accuracy: [92m0.6791[0m
val_Precision: [4;34m0.6883[0m,               val_Recall: [4;33m0.6590[0m,                 val_F1 Score: [4;35m0.6674[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  584
Epoch [29/100], Loss: 14.4451
train_Accuracy: [91m0.9558[0m
train_Precision: [4;34m0.9441[0m,               train_Recall: [4;33m0.9712[0m,                 train_F1 Score: [4;35m0.9558[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4110
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [9.9454e-01],
        [1.0000e+00],
        [1.0930e-03],
        [9.9957e-01],
        [8.8965e-04],
        [1.5580e-06],
        [8.6710e-04],
        [9.9852e-01],
        [9.9993e-01],
        [2.2259e-06],
        [6.9443e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 26), 1)
((25, 26), 1)
((25, 26), 1)
((3, 20), 1)
((3, 20), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((21, 4), 1)
((21, 4), 1)
((21, 4), 1)
((21, 4), 1)
((21, 4), 1)
((21, 4), 1)
Epoch [29/100], Loss: 40.7973
val_Accuracy: [92m0.7174[0m
val_Precision: [4;34m0.7079[0m,               val_Recall: [4;33m0.7356[0m,                 val_F1 Score: [4;35m0.7178[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  617
Epoch [30/100], Loss: 13.7074
train_Accuracy: [91m0.9607[0m
train_Precision: [4;34m0.9495[0m,               train_Recall: [4;33m0.9734[0m,                 train_F1 Score: [4;35m0.9598[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4131
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9833e-01],
        [9.9060e-01],
        [1.0000e+00],
        [1.4758e-04],
        [9.9898e-01],
        [4.5145e-03],
        [2.2874e-04],
        [1.3594e-03],
        [9.9929e-01],
        [9.9941e-01],
        [7.0195e-06],
        [1.1419e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((21, 4), 1)
((1, 26), 1)
((2, 1), 1)
((2, 1), 1)
((2, 1), 1)
((2, 1), 1)
((2, 1), 1)
((7, 23), 1)
((8, 20), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((9, 8), 1)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
Epoch [30/100], Loss: 54.7082
val_Accuracy: [92m0.7267[0m
val_Precision: [4;34m0.6973[0m,               val_Recall: [4;33m0.7984[0m,                 val_F1 Score: [4;35m0.7407[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  625
Epoch [31/100], Loss: 13.1299
train_Accuracy: [91m0.9626[0m
train_Precision: [4;34m0.9526[0m,               train_Recall: [4;33m0.9748[0m,                 train_F1 Score: [4;35m0.9622[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4139
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9918e-01],
        [9.9712e-01],
        [1.0000e+00],
        [2.6266e-05],
        [9.9864e-01],
        [2.0914e-03],
        [1.7611e-04],
        [1.0938e-03],
        [9.9318e-01],
        [9.9929e-01],
        [1.2541e-07],
        [2.0572e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((23, 12), 1)
((23, 12), 1)
((2, 11), 1)
((3, 30), 1)
((4, 28), 1)
((4, 28), 1)
((4, 28), 1)
((4, 28), 1)
((4, 28), 1)
((4, 28), 1)
((4, 28), 1)
((11, 29), 1)
((11, 29), 1)
((11, 29), 1)
((14, 0), 1)
((15, 26), 1)
((16, 21), 1)
((16, 21), 1)
((18, 24), 1)
((18, 24), 1)
((18, 24), 1)
((18, 24), 1)
((22, 18), 1)
((22, 18), 1)
((22, 18), 1)
((25, 13), 1)
((25, 13), 1)
Epoch [31/100], Loss: 35.5156
val_Accuracy: [92m0.6337[0m
val_Precision: [4;34m0.6439[0m,               val_Recall: [4;33m0.5998[0m,                 val_F1 Score: [4;35m0.6152[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  545
Epoch [32/100], Loss: 10.7590
train_Accuracy: [91m0.9714[0m
train_Precision: [4;34m0.9607[0m,               train_Recall: [4;33m0.9815[0m,                 train_F1 Score: [4;35m0.9700[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4177
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.0510e-01],
        [9.9913e-01],
        [1.0000e+00],
        [2.8524e-02],
        [9.9970e-01],
        [9.6150e-03],
        [2.5398e-06],
        [1.2596e-03],
        [9.7454e-01],
        [9.9891e-01],
        [1.7587e-07],
        [6.2372e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 13), 1)
((25, 13), 1)
((2, 24), 1)
((2, 24), 1)
((2, 24), 1)
((5, 22), 1)
((6, 15), 1)
((7, 24), 1)
((7, 24), 1)
((7, 24), 1)
((7, 24), 1)
((7, 24), 1)
((7, 24), 1)
((13, 31), 1)
((13, 31), 1)
((13, 31), 1)
((13, 31), 1)
((13, 31), 1)
((18, 2), 1)
((18, 2), 1)
((18, 2), 1)
((18, 2), 1)
((18, 2), 1)
((18, 2), 1)
((18, 2), 1)
((25, 30), 1)
((25, 30), 1)
Epoch [32/100], Loss: 36.2034
val_Accuracy: [92m0.6826[0m
val_Precision: [4;34m0.6729[0m,               val_Recall: [4;33m0.7264[0m,                 val_F1 Score: [4;35m0.6927[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  587
Epoch [33/100], Loss: 8.7611
train_Accuracy: [91m0.9774[0m
train_Precision: [4;34m0.9709[0m,               train_Recall: [4;33m0.9856[0m,                 train_F1 Score: [4;35m0.9774[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4203
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9984e-01],
        [9.4475e-01],
        [1.0000e+00],
        [1.2806e-04],
        [1.0000e+00],
        [5.1199e-02],
        [9.0240e-05],
        [2.2907e-03],
        [9.8489e-01],
        [9.9624e-01],
        [5.6508e-07],
        [5.7796e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 30), 1)
((1, 11), 1)
((1, 11), 1)
((1, 11), 1)
((1, 11), 1)
((5, 20), 1)
((5, 20), 1)
((7, 18), 1)
((8, 21), 1)
((8, 21), 1)
((10, 14), 1)
((10, 14), 1)
((10, 14), 1)
((10, 14), 1)
((14, 4), 1)
((15, 19), 1)
((15, 19), 1)
((15, 19), 1)
((15, 19), 1)
((15, 19), 1)
((15, 19), 1)
((15, 19), 1)
((15, 19), 1)
((23, 15), 1)
((24, 12), 1)
((25, 14), 1)
((25, 14), 1)
Epoch [33/100], Loss: 39.4965
val_Accuracy: [92m0.6360[0m
val_Precision: [4;34m0.6498[0m,               val_Recall: [4;33m0.6120[0m,                 val_F1 Score: [4;35m0.6234[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  547
Epoch [34/100], Loss: 9.0820
train_Accuracy: [91m0.9742[0m
train_Precision: [4;34m0.9670[0m,               train_Recall: [4;33m0.9834[0m,                 train_F1 Score: [4;35m0.9743[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4189
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.8356e-01],
        [9.9999e-01],
        [1.0000e+00],
        [3.9626e-03],
        [1.0000e+00],
        [2.3326e-03],
        [1.5975e-06],
        [5.3302e-03],
        [9.9957e-01],
        [9.9999e-01],
        [1.5173e-07],
        [2.3877e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
Epoch [34/100], Loss: 49.0695
val_Accuracy: [92m0.7186[0m
val_Precision: [4;34m0.7563[0m,               val_Recall: [4;33m0.6533[0m,                 val_F1 Score: [4;35m0.6932[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  618
Epoch [35/100], Loss: 8.6062
train_Accuracy: [91m0.9777[0m
train_Precision: [4;34m0.9717[0m,               train_Recall: [4;33m0.9843[0m,                 train_F1 Score: [4;35m0.9770[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4204
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9347e-01],
        [9.9962e-01],
        [1.0000e+00],
        [5.3452e-03],
        [9.9999e-01],
        [7.4540e-04],
        [2.9791e-04],
        [1.3150e-05],
        [9.9834e-01],
        [9.9267e-01],
        [1.7622e-07],
        [1.5877e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 14), 1)
((25, 14), 1)
((25, 14), 1)
((3, 12), 1)
((3, 12), 1)
((3, 12), 1)
((3, 12), 1)
((3, 12), 1)
((3, 12), 1)
((9, 16), 1)
((9, 16), 1)
((9, 16), 1)
((9, 16), 1)
((9, 16), 1)
((9, 16), 1)
((9, 16), 1)
((9, 16), 1)
((9, 16), 1)
((9, 16), 1)
((19, 0), 1)
((19, 0), 1)
((19, 0), 1)
((19, 0), 1)
((19, 0), 1)
((19, 0), 1)
((19, 0), 1)
((19, 0), 1)
Epoch [35/100], Loss: 55.2249
val_Accuracy: [92m0.6884[0m
val_Precision: [4;34m0.7919[0m,               val_Recall: [4;33m0.5126[0m,                 val_F1 Score: [4;35m0.6139[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  592
Epoch [36/100], Loss: 14.5131
train_Accuracy: [91m0.9702[0m
train_Precision: [4;34m0.9618[0m,               train_Recall: [4;33m0.9777[0m,                 train_F1 Score: [4;35m0.9686[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4172
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.3320e-01],
        [9.9896e-01],
        [1.0000e+00],
        [1.1644e-04],
        [9.9998e-01],
        [4.7920e-05],
        [1.6318e-06],
        [1.1127e-04],
        [9.8630e-01],
        [9.9531e-01],
        [6.0002e-06],
        [2.8548e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((19, 0), 1)
((1, 1), 1)
((1, 1), 1)
((1, 1), 1)
((4, 23), 1)
((4, 23), 1)
((6, 29), 1)
((7, 1), 1)
((7, 1), 1)
((7, 1), 1)
((7, 1), 1)
((7, 1), 1)
((7, 1), 1)
((7, 1), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
Epoch [36/100], Loss: 42.9289
val_Accuracy: [92m0.6930[0m
val_Precision: [4;34m0.7021[0m,               val_Recall: [4;33m0.6706[0m,                 val_F1 Score: [4;35m0.6827[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  596
Epoch [37/100], Loss: 10.0246
train_Accuracy: [91m0.9700[0m
train_Precision: [4;34m0.9609[0m,               train_Recall: [4;33m0.9807[0m,                 train_F1 Score: [4;35m0.9696[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4171
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9831e-01],
        [9.9578e-01],
        [1.0000e+00],
        [3.5490e-05],
        [9.9997e-01],
        [1.1561e-01],
        [7.5513e-05],
        [1.8107e-06],
        [9.9011e-01],
        [9.9992e-01],
        [4.7292e-08],
        [1.1234e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((14, 26), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
Epoch [37/100], Loss: 56.2059
val_Accuracy: [92m0.7128[0m
val_Precision: [4;34m0.7008[0m,               val_Recall: [4;33m0.7509[0m,                 val_F1 Score: [4;35m0.7193[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  613
Epoch [38/100], Loss: 10.0478
train_Accuracy: [91m0.9733[0m
train_Precision: [4;34m0.9638[0m,               train_Recall: [4;33m0.9841[0m,                 train_F1 Score: [4;35m0.9730[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4185
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9796e-01],
        [9.8301e-01],
        [1.0000e+00],
        [4.1971e-04],
        [1.0000e+00],
        [2.6175e-02],
        [8.0660e-06],
        [2.5413e-05],
        [9.9274e-01],
        [9.9999e-01],
        [2.5125e-09],
        [1.2063e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 1)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
Epoch [38/100], Loss: 74.7743
val_Accuracy: [92m0.7337[0m
val_Precision: [4;34m0.7335[0m,               val_Recall: [4;33m0.7359[0m,                 val_F1 Score: [4;35m0.7298[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  631
Epoch [39/100], Loss: 8.2399
train_Accuracy: [91m0.9777[0m
train_Precision: [4;34m0.9690[0m,               train_Recall: [4;33m0.9876[0m,                 train_F1 Score: [4;35m0.9774[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4204
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9451e-01],
        [9.9924e-01],
        [1.0000e+00],
        [8.1412e-06],
        [9.9938e-01],
        [1.6546e-02],
        [3.5109e-05],
        [1.0163e-03],
        [9.9666e-01],
        [9.9998e-01],
        [5.5970e-09],
        [2.0519e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
Epoch [39/100], Loss: 76.1108
val_Accuracy: [92m0.7291[0m
val_Precision: [4;34m0.7155[0m,               val_Recall: [4;33m0.7569[0m,                 val_F1 Score: [4;35m0.7304[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  627
Epoch [40/100], Loss: 7.5391
train_Accuracy: [91m0.9812[0m
train_Precision: [4;34m0.9737[0m,               train_Recall: [4;33m0.9885[0m,                 train_F1 Score: [4;35m0.9803[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4219
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9997e-01],
        [9.9953e-01],
        [1.0000e+00],
        [2.4769e-06],
        [9.9996e-01],
        [1.0346e-04],
        [1.5104e-03],
        [3.8826e-06],
        [9.9972e-01],
        [9.9988e-01],
        [1.1035e-09],
        [8.5265e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((17, 24), 2)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
((9, 6), 1)
Epoch [40/100], Loss: 55.6861
val_Accuracy: [92m0.7140[0m
val_Precision: [4;34m0.7507[0m,               val_Recall: [4;33m0.6364[0m,                 val_F1 Score: [4;35m0.6834[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  614
Epoch [41/100], Loss: 9.2512
train_Accuracy: [91m0.9756[0m
train_Precision: [4;34m0.9678[0m,               train_Recall: [4;33m0.9835[0m,                 train_F1 Score: [4;35m0.9748[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4195
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9223e-01],
        [9.9998e-01],
        [1.0000e+00],
        [2.1387e-05],
        [9.9998e-01],
        [8.8911e-04],
        [1.3977e-05],
        [1.5409e-03],
        [9.9675e-01],
        [9.9995e-01],
        [1.1083e-11],
        [1.2514e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 12), 1)
((0, 12), 1)
((0, 12), 1)
((0, 12), 1)
((0, 12), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((5, 24), 1)
((25, 0), 1)
((26, 9), 1)
Epoch [41/100], Loss: 57.5133
val_Accuracy: [92m0.6884[0m
val_Precision: [4;34m0.6870[0m,               val_Recall: [4;33m0.6851[0m,                 val_F1 Score: [4;35m0.6821[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  592
Epoch [42/100], Loss: 10.2054
train_Accuracy: [91m0.9737[0m
train_Precision: [4;34m0.9667[0m,               train_Recall: [4;33m0.9825[0m,                 train_F1 Score: [4;35m0.9737[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4187
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9776e-01],
        [9.9999e-01],
        [1.0000e+00],
        [4.7264e-05],
        [9.9812e-01],
        [2.7076e-04],
        [8.1960e-06],
        [1.8431e-04],
        [9.9037e-01],
        [9.9991e-01],
        [4.1333e-09],
        [2.2897e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 9), 1)
((26, 9), 1)
((26, 9), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((3, 29), 1)
((17, 20), 1)
((17, 20), 1)
((17, 20), 1)
((20, 4), 1)
((20, 4), 1)
((20, 4), 1)
((23, 13), 1)
((23, 13), 1)
((25, 27), 1)
((25, 27), 1)
Epoch [42/100], Loss: 57.0094
val_Accuracy: [92m0.6930[0m
val_Precision: [4;34m0.6902[0m,               val_Recall: [4;33m0.7130[0m,                 val_F1 Score: [4;35m0.6942[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  596
Epoch [43/100], Loss: 7.2247
train_Accuracy: [91m0.9819[0m
train_Precision: [4;34m0.9738[0m,               train_Recall: [4;33m0.9900[0m,                 train_F1 Score: [4;35m0.9811[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4222
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [2.1570e-06],
        [9.9997e-01],
        [5.0717e-03],
        [2.6270e-04],
        [2.8862e-05],
        [9.7647e-01],
        [9.9674e-01],
        [3.2912e-09],
        [5.3857e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 27), 1)
((1, 28), 1)
((1, 28), 1)
((1, 28), 1)
((4, 13), 1)
((5, 31), 1)
((5, 31), 1)
((7, 3), 1)
((7, 3), 1)
((7, 3), 1)
((10, 21), 1)
((10, 21), 1)
((10, 21), 1)
((10, 21), 1)
((10, 21), 1)
((10, 21), 1)
((16, 4), 1)
((16, 4), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
Epoch [43/100], Loss: 54.8983
val_Accuracy: [92m0.6535[0m
val_Precision: [4;34m0.6977[0m,               val_Recall: [4;33m0.5456[0m,                 val_F1 Score: [4;35m0.6022[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  562
Epoch [44/100], Loss: 5.8833
train_Accuracy: [91m0.9842[0m
train_Precision: [4;34m0.9809[0m,               train_Recall: [4;33m0.9890[0m,                 train_F1 Score: [4;35m0.9845[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4232
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9972e-01],
        [9.9995e-01],
        [1.0000e+00],
        [2.4197e-05],
        [1.0000e+00],
        [2.0757e-04],
        [3.8419e-05],
        [5.2620e-06],
        [9.7169e-01],
        [9.9126e-01],
        [2.2084e-09],
        [2.5222e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
Epoch [44/100], Loss: 73.0222
val_Accuracy: [92m0.7349[0m
val_Precision: [4;34m0.7872[0m,               val_Recall: [4;33m0.6411[0m,                 val_F1 Score: [4;35m0.7011[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  632
Epoch [45/100], Loss: 4.3473
train_Accuracy: [91m0.9914[0m
train_Precision: [4;34m0.9879[0m,               train_Recall: [4;33m0.9949[0m,                 train_F1 Score: [4;35m0.9911[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4263
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9415e-01],
        [9.9999e-01],
        [1.0000e+00],
        [8.6436e-06],
        [9.9999e-01],
        [5.2591e-05],
        [1.7334e-05],
        [3.0372e-05],
        [8.5980e-01],
        [9.9993e-01],
        [1.7374e-09],
        [5.7998e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
Epoch [45/100], Loss: 65.6343
val_Accuracy: [92m0.7105[0m
val_Precision: [4;34m0.7608[0m,               val_Recall: [4;33m0.6138[0m,                 val_F1 Score: [4;35m0.6728[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  611
Epoch [46/100], Loss: 4.2982
train_Accuracy: [91m0.9919[0m
train_Precision: [4;34m0.9886[0m,               train_Recall: [4;33m0.9948[0m,                 train_F1 Score: [4;35m0.9913[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4265
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9335e-01],
        [1.0000e+00],
        [1.0000e+00],
        [9.7439e-08],
        [9.9729e-01],
        [3.3369e-05],
        [3.4373e-05],
        [1.0386e-03],
        [9.9924e-01],
        [9.9995e-01],
        [1.6531e-09],
        [4.7258e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
Epoch [46/100], Loss: 80.2661
val_Accuracy: [92m0.7221[0m
val_Precision: [4;34m0.7454[0m,               val_Recall: [4;33m0.6779[0m,                 val_F1 Score: [4;35m0.7035[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  621
Epoch [47/100], Loss: 5.3023
train_Accuracy: [91m0.9867[0m
train_Precision: [4;34m0.9799[0m,               train_Recall: [4;33m0.9932[0m,                 train_F1 Score: [4;35m0.9860[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4243
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.3026e-04],
        [9.9945e-01],
        [8.9158e-06],
        [3.1649e-05],
        [5.0057e-04],
        [9.9943e-01],
        [9.9999e-01],
        [7.9424e-10],
        [3.1282e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((18, 9), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
Epoch [47/100], Loss: 70.6150
val_Accuracy: [92m0.7163[0m
val_Precision: [4;34m0.8341[0m,               val_Recall: [4;33m0.5469[0m,                 val_F1 Score: [4;35m0.6508[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  616
Epoch [48/100], Loss: 4.7828
train_Accuracy: [91m0.9898[0m
train_Precision: [4;34m0.9858[0m,               train_Recall: [4;33m0.9931[0m,                 train_F1 Score: [4;35m0.9891[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4256
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.7471e-01],
        [9.9996e-01],
        [1.0000e+00],
        [4.3510e-04],
        [9.9980e-01],
        [4.6114e-06],
        [3.7038e-05],
        [3.2240e-05],
        [9.6970e-01],
        [9.9987e-01],
        [1.5143e-07],
        [1.5388e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((6, 18), 1)
((9, 27), 1)
((9, 27), 1)
((9, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((12, 27), 1)
((26, 5), 1)
Epoch [48/100], Loss: 68.0959
val_Accuracy: [92m0.7000[0m
val_Precision: [4;34m0.7423[0m,               val_Recall: [4;33m0.6202[0m,                 val_F1 Score: [4;35m0.6681[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  602
Epoch [49/100], Loss: 6.2067
train_Accuracy: [91m0.9828[0m
train_Precision: [4;34m0.9789[0m,               train_Recall: [4;33m0.9875[0m,                 train_F1 Score: [4;35m0.9826[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4226
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[6.5558e-01],
        [1.0000e+00],
        [1.0000e+00],
        [4.0999e-05],
        [9.9576e-01],
        [3.2857e-04],
        [1.8983e-05],
        [5.6193e-05],
        [9.9300e-01],
        [9.9863e-01],
        [4.7042e-12],
        [2.7962e-02]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 19), 1)
((0, 19), 1)
((0, 19), 1)
((0, 19), 1)
((0, 19), 1)
((0, 19), 1)
((0, 19), 1)
((0, 19), 1)
((0, 19), 1)
((9, 20), 1)
((9, 20), 1)
((9, 20), 1)
((12, 24), 1)
((12, 24), 1)
((12, 24), 1)
((12, 24), 1)
((12, 24), 1)
((12, 24), 1)
((12, 24), 1)
((12, 24), 1)
((12, 24), 1)
((21, 17), 1)
((21, 17), 1)
((21, 17), 1)
((24, 3), 1)
((24, 3), 1)
((24, 3), 1)
Epoch [49/100], Loss: 103.1995
val_Accuracy: [92m0.7186[0m
val_Precision: [4;34m0.7356[0m,               val_Recall: [4;33m0.6885[0m,                 val_F1 Score: [4;35m0.7041[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  618
Epoch [50/100], Loss: 11.3195
train_Accuracy: [91m0.9681[0m
train_Precision: [4;34m0.9614[0m,               train_Recall: [4;33m0.9771[0m,                 train_F1 Score: [4;35m0.9683[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4163
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [2.3007e-04],
        [9.9836e-01],
        [6.6658e-03],
        [6.9348e-05],
        [1.2250e-09],
        [9.8696e-01],
        [9.9999e-01],
        [1.8936e-13],
        [2.9669e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((24, 3), 1)
((24, 3), 1)
((24, 3), 1)
((24, 3), 1)
((24, 3), 1)
((24, 3), 1)
((24, 3), 1)
((24, 3), 1)
((24, 3), 1)
((9, 22), 1)
((9, 22), 1)
((9, 22), 1)
((9, 22), 1)
((9, 22), 1)
((9, 22), 1)
((9, 22), 1)
((9, 22), 1)
((9, 22), 1)
((9, 22), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
Epoch [50/100], Loss: 81.3989
val_Accuracy: [92m0.6930[0m
val_Precision: [4;34m0.7468[0m,               val_Recall: [4;33m0.5908[0m,                 val_F1 Score: [4;35m0.6517[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  596
Epoch [51/100], Loss: 9.2076
train_Accuracy: [91m0.9751[0m
train_Precision: [4;34m0.9695[0m,               train_Recall: [4;33m0.9811[0m,                 train_F1 Score: [4;35m0.9745[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4193
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9888e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.9815e-02],
        [9.9994e-01],
        [1.3017e-04],
        [1.1765e-04],
        [1.2078e-06],
        [9.9675e-01],
        [9.9997e-01],
        [2.1528e-10],
        [3.8369e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((19, 13), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
Epoch [51/100], Loss: 73.9997
val_Accuracy: [92m0.7093[0m
val_Precision: [4;34m0.7369[0m,               val_Recall: [4;33m0.6477[0m,                 val_F1 Score: [4;35m0.6836[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  610
Epoch [52/100], Loss: 3.4250
train_Accuracy: [91m0.9914[0m
train_Precision: [4;34m0.9860[0m,               train_Recall: [4;33m0.9965[0m,                 train_F1 Score: [4;35m0.9909[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4263
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9990e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.5213e-04],
        [9.9973e-01],
        [5.4294e-03],
        [4.5004e-05],
        [2.5375e-06],
        [8.8535e-01],
        [9.9902e-01],
        [3.1059e-11],
        [6.5889e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
Epoch [52/100], Loss: 67.5857
val_Accuracy: [92m0.6988[0m
val_Precision: [4;34m0.7271[0m,               val_Recall: [4;33m0.6342[0m,                 val_F1 Score: [4;35m0.6692[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  601
Epoch [53/100], Loss: 3.0059
train_Accuracy: [91m0.9951[0m
train_Precision: [4;34m0.9942[0m,               train_Recall: [4;33m0.9960[0m,                 train_F1 Score: [4;35m0.9949[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4279
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9978e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.0142e-02],
        [9.9969e-01],
        [2.7243e-04],
        [4.7481e-04],
        [2.3504e-04],
        [9.8928e-01],
        [9.9062e-01],
        [3.3002e-11],
        [2.2627e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
Epoch [53/100], Loss: 92.0776
val_Accuracy: [92m0.7407[0m
val_Precision: [4;34m0.7597[0m,               val_Recall: [4;33m0.6977[0m,                 val_F1 Score: [4;35m0.7222[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  637
Epoch [54/100], Loss: 2.9120
train_Accuracy: [91m0.9937[0m
train_Precision: [4;34m0.9923[0m,               train_Recall: [4;33m0.9956[0m,                 train_F1 Score: [4;35m0.9937[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4273
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9999e-01],
        [1.0000e+00],
        [1.0000e+00],
        [3.0044e-04],
        [9.9865e-01],
        [6.0386e-05],
        [6.5828e-07],
        [6.8370e-05],
        [9.9847e-01],
        [1.0000e+00],
        [1.6588e-10],
        [1.3512e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((23, 24), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
Epoch [54/100], Loss: 79.6271
val_Accuracy: [92m0.7256[0m
val_Precision: [4;34m0.7715[0m,               val_Recall: [4;33m0.6384[0m,                 val_F1 Score: [4;35m0.6910[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  624
Epoch [55/100], Loss: 5.0257
train_Accuracy: [91m0.9870[0m
train_Precision: [4;34m0.9820[0m,               train_Recall: [4;33m0.9920[0m,                 train_F1 Score: [4;35m0.9865[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4244
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9995e-01],
        [9.9999e-01],
        [1.0000e+00],
        [1.9938e-05],
        [9.9743e-01],
        [4.4129e-08],
        [1.0087e-06],
        [1.6495e-03],
        [9.9764e-01],
        [9.9999e-01],
        [4.6228e-12],
        [9.5350e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((19, 5), 1)
((17, 18), 1)
((18, 21), 1)
((18, 21), 1)
((18, 21), 1)
((18, 21), 1)
((18, 21), 1)
((18, 21), 1)
((18, 21), 1)
((18, 21), 1)
((18, 21), 1)
Epoch [55/100], Loss: 88.2894
val_Accuracy: [92m0.6872[0m
val_Precision: [4;34m0.7793[0m,               val_Recall: [4;33m0.5242[0m,                 val_F1 Score: [4;35m0.6215[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  591
Epoch [56/100], Loss: 8.2917
train_Accuracy: [91m0.9791[0m
train_Precision: [4;34m0.9762[0m,               train_Recall: [4;33m0.9828[0m,                 train_F1 Score: [4;35m0.9787[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4210
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9934e-01],
        [1.0000e+00],
        [1.0000e+00],
        [5.3153e-05],
        [9.9459e-01],
        [6.1362e-04],
        [8.7263e-07],
        [2.4968e-05],
        [9.8861e-01],
        [9.9781e-01],
        [2.0014e-09],
        [1.4145e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((18, 21), 1)
((18, 21), 1)
((2, 0), 1)
((2, 0), 1)
((2, 0), 1)
((2, 0), 1)
((2, 0), 1)
((2, 0), 1)
((2, 0), 1)
((2, 0), 1)
((2, 0), 1)
((2, 0), 1)
((2, 0), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
Epoch [56/100], Loss: 73.7574
val_Accuracy: [92m0.7070[0m
val_Precision: [4;34m0.7425[0m,               val_Recall: [4;33m0.6347[0m,                 val_F1 Score: [4;35m0.6786[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  608
Epoch [57/100], Loss: 4.6121
train_Accuracy: [91m0.9874[0m
train_Precision: [4;34m0.9847[0m,               train_Recall: [4;33m0.9912[0m,                 train_F1 Score: [4;35m0.9876[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4246
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9918e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.9785e-03],
        [9.9992e-01],
        [2.7910e-08],
        [1.0574e-06],
        [1.0392e-04],
        [9.9576e-01],
        [1.0000e+00],
        [1.4489e-10],
        [3.8961e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((13, 7), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
Epoch [57/100], Loss: 104.7737
val_Accuracy: [92m0.7407[0m
val_Precision: [4;34m0.8003[0m,               val_Recall: [4;33m0.6418[0m,                 val_F1 Score: [4;35m0.7059[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  637
Epoch [58/100], Loss: 6.1462
train_Accuracy: [91m0.9856[0m
train_Precision: [4;34m0.9808[0m,               train_Recall: [4;33m0.9909[0m,                 train_F1 Score: [4;35m0.9853[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4238
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9921e-01],
        [1.0000e+00],
        [1.0000e+00],
        [6.6559e-04],
        [9.9957e-01],
        [1.1657e-03],
        [6.0960e-06],
        [6.3352e-06],
        [9.9893e-01],
        [8.5772e-01],
        [1.5599e-10],
        [5.2872e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
Epoch [58/100], Loss: 77.9752
val_Accuracy: [92m0.6895[0m
val_Precision: [4;34m0.7197[0m,               val_Recall: [4;33m0.6330[0m,                 val_F1 Score: [4;35m0.6656[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  593
Epoch [59/100], Loss: 3.9816
train_Accuracy: [91m0.9912[0m
train_Precision: [4;34m0.9892[0m,               train_Recall: [4;33m0.9932[0m,                 train_F1 Score: [4;35m0.9909[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4262
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9994e-01],
        [9.9852e-01],
        [1.0000e+00],
        [4.7520e-04],
        [1.0000e+00],
        [2.1772e-05],
        [1.3005e-07],
        [6.2310e-06],
        [9.9947e-01],
        [9.9973e-01],
        [5.4376e-08],
        [1.6866e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
Epoch [59/100], Loss: 103.3146
val_Accuracy: [92m0.7174[0m
val_Precision: [4;34m0.7208[0m,               val_Recall: [4;33m0.7041[0m,                 val_F1 Score: [4;35m0.7068[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  617
Epoch [60/100], Loss: 1.8531
train_Accuracy: [91m0.9974[0m
train_Precision: [4;34m0.9969[0m,               train_Recall: [4;33m0.9983[0m,                 train_F1 Score: [4;35m0.9976[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4289
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9895e-01],
        [1.0000e+00],
        [1.0000e+00],
        [4.3453e-05],
        [9.9996e-01],
        [1.4968e-04],
        [9.3637e-06],
        [3.2908e-06],
        [9.9418e-01],
        [9.9940e-01],
        [1.6693e-10],
        [5.6845e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
Epoch [60/100], Loss: 89.3185
val_Accuracy: [92m0.7372[0m
val_Precision: [4;34m0.7737[0m,               val_Recall: [4;33m0.6698[0m,                 val_F1 Score: [4;35m0.7123[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  634
Epoch [61/100], Loss: 1.5441
train_Accuracy: [91m0.9974[0m
train_Precision: [4;34m0.9970[0m,               train_Recall: [4;33m0.9978[0m,                 train_F1 Score: [4;35m0.9973[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4289
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9966e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.7710e-04],
        [9.9944e-01],
        [2.2409e-06],
        [2.1519e-06],
        [1.6879e-04],
        [9.9698e-01],
        [9.9999e-01],
        [1.5689e-11],
        [9.7616e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
Epoch [61/100], Loss: 92.6098
val_Accuracy: [92m0.7291[0m
val_Precision: [4;34m0.7301[0m,               val_Recall: [4;33m0.7255[0m,                 val_F1 Score: [4;35m0.7227[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  627
Epoch [62/100], Loss: 0.9638
train_Accuracy: [91m0.9991[0m
train_Precision: [4;34m0.9977[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m0.9988[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4296
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9886e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.8572e-04],
        [9.9790e-01],
        [1.9969e-05],
        [1.3739e-06],
        [1.7477e-04],
        [9.9475e-01],
        [1.0000e+00],
        [1.4096e-10],
        [1.4939e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((11, 2), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
Epoch [62/100], Loss: 98.1215
val_Accuracy: [92m0.7314[0m
val_Precision: [4;34m0.7340[0m,               val_Recall: [4;33m0.7288[0m,                 val_F1 Score: [4;35m0.7259[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  629
Epoch [63/100], Loss: 0.4327
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9918e-01],
        [1.0000e+00],
        [1.0000e+00],
        [8.8959e-05],
        [9.9984e-01],
        [1.7213e-06],
        [7.9355e-09],
        [1.0326e-03],
        [9.9841e-01],
        [1.0000e+00],
        [1.6468e-10],
        [6.7258e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
Epoch [63/100], Loss: 101.3236
val_Accuracy: [92m0.7337[0m
val_Precision: [4;34m0.7314[0m,               val_Recall: [4;33m0.7454[0m,                 val_F1 Score: [4;35m0.7329[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  631
Epoch [64/100], Loss: 3.1907
train_Accuracy: [91m0.9923[0m
train_Precision: [4;34m0.9895[0m,               train_Recall: [4;33m0.9957[0m,                 train_F1 Score: [4;35m0.9923[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4267
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.8849e-01],
        [9.9997e-01],
        [1.0000e+00],
        [8.5956e-06],
        [9.9712e-01],
        [4.9799e-06],
        [2.0256e-07],
        [1.7241e-04],
        [9.9990e-01],
        [1.0000e+00],
        [2.3083e-08],
        [7.8480e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((23, 20), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
Epoch [64/100], Loss: 114.4362
val_Accuracy: [92m0.7360[0m
val_Precision: [4;34m0.7543[0m,               val_Recall: [4;33m0.6955[0m,                 val_F1 Score: [4;35m0.7190[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  633
Epoch [65/100], Loss: 18.7486
train_Accuracy: [91m0.9602[0m
train_Precision: [4;34m0.9566[0m,               train_Recall: [4;33m0.9661[0m,                 train_F1 Score: [4;35m0.9600[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4129
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0903e-05],
        [1.0000e+00],
        [1.3081e-06],
        [9.1486e-09],
        [6.4256e-05],
        [9.6646e-01],
        [9.9910e-01],
        [8.1193e-09],
        [2.9033e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
Epoch [65/100], Loss: 110.7611
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7982[0m,               val_Recall: [4;33m0.6584[0m,                 val_F1 Score: [4;35m0.7152[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [66/100], Loss: 9.9757
train_Accuracy: [91m0.9723[0m
train_Precision: [4;34m0.9663[0m,               train_Recall: [4;33m0.9812[0m,                 train_F1 Score: [4;35m0.9726[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4181
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9996e-01],
        [1.0000e+00],
        [1.0000e+00],
        [6.3196e-06],
        [9.9997e-01],
        [6.3622e-07],
        [6.1513e-06],
        [3.1645e-03],
        [9.9910e-01],
        [1.0000e+00],
        [4.9017e-14],
        [6.8355e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((20, 10), 1)
((15, 25), 1)
((15, 25), 1)
((15, 25), 1)
((18, 28), 1)
((19, 9), 1)
((19, 9), 1)
((21, 12), 1)
((21, 12), 1)
((21, 12), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
Epoch [66/100], Loss: 62.5597
val_Accuracy: [92m0.6709[0m
val_Precision: [4;34m0.7053[0m,               val_Recall: [4;33m0.5833[0m,                 val_F1 Score: [4;35m0.6326[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  577
Epoch [67/100], Loss: 6.0066
train_Accuracy: [91m0.9833[0m
train_Precision: [4;34m0.9801[0m,               train_Recall: [4;33m0.9858[0m,                 train_F1 Score: [4;35m0.9823[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4228
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.8610e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.4859e-05],
        [9.9998e-01],
        [6.4798e-05],
        [5.5229e-05],
        [2.2761e-04],
        [9.9907e-01],
        [9.9990e-01],
        [3.8491e-12],
        [2.1935e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
Epoch [67/100], Loss: 73.6181
val_Accuracy: [92m0.7081[0m
val_Precision: [4;34m0.7208[0m,               val_Recall: [4;33m0.6709[0m,                 val_F1 Score: [4;35m0.6902[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  609
Epoch [68/100], Loss: 3.9231
train_Accuracy: [91m0.9909[0m
train_Precision: [4;34m0.9869[0m,               train_Recall: [4;33m0.9944[0m,                 train_F1 Score: [4;35m0.9904[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4261
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9696e-01],
        [1.0000e+00],
        [1.0000e+00],
        [6.3079e-06],
        [9.9945e-01],
        [4.6767e-07],
        [1.4375e-04],
        [2.6613e-03],
        [9.9517e-01],
        [9.9996e-01],
        [1.1411e-10],
        [5.9906e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((24, 29), 1)
((22, 3), 1)
((22, 3), 1)
((22, 3), 1)
((22, 3), 1)
((22, 3), 1)
Epoch [68/100], Loss: 95.0784
val_Accuracy: [92m0.7163[0m
val_Precision: [4;34m0.7182[0m,               val_Recall: [4;33m0.7095[0m,                 val_F1 Score: [4;35m0.7085[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  616
Epoch [69/100], Loss: 4.0509
train_Accuracy: [91m0.9902[0m
train_Precision: [4;34m0.9901[0m,               train_Recall: [4;33m0.9911[0m,                 train_F1 Score: [4;35m0.9902[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4258
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.8654e-01],
        [1.0000e+00],
        [1.0000e+00],
        [8.8428e-05],
        [9.9872e-01],
        [5.6664e-03],
        [5.5565e-05],
        [7.8650e-05],
        [9.4091e-01],
        [9.9997e-01],
        [8.1341e-09],
        [1.2274e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 23), 1)
((0, 23), 1)
((0, 23), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((3, 3), 1)
((25, 11), 1)
((25, 11), 1)
Epoch [69/100], Loss: 89.7670
val_Accuracy: [92m0.7140[0m
val_Precision: [4;34m0.7010[0m,               val_Recall: [4;33m0.7408[0m,                 val_F1 Score: [4;35m0.7136[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  614
Epoch [70/100], Loss: 2.8394
train_Accuracy: [91m0.9937[0m
train_Precision: [4;34m0.9913[0m,               train_Recall: [4;33m0.9959[0m,                 train_F1 Score: [4;35m0.9933[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4273
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9985e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.2392e-05],
        [9.9954e-01],
        [1.1537e-02],
        [2.8374e-03],
        [6.5973e-04],
        [9.7553e-01],
        [9.9995e-01],
        [2.0334e-12],
        [1.2886e-02]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((25, 11), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
Epoch [70/100], Loss: 83.3142
val_Accuracy: [92m0.7023[0m
val_Precision: [4;34m0.7151[0m,               val_Recall: [4;33m0.6666[0m,                 val_F1 Score: [4;35m0.6849[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  604
Epoch [71/100], Loss: 2.9200
train_Accuracy: [91m0.9930[0m
train_Precision: [4;34m0.9903[0m,               train_Recall: [4;33m0.9951[0m,                 train_F1 Score: [4;35m0.9924[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4270
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9499e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.1611e-04],
        [9.5883e-01],
        [4.2595e-06],
        [2.2924e-05],
        [3.3120e-03],
        [9.9445e-01],
        [9.9994e-01],
        [1.9596e-10],
        [9.4315e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
Epoch [71/100], Loss: 86.0905
val_Accuracy: [92m0.7128[0m
val_Precision: [4;34m0.7136[0m,               val_Recall: [4;33m0.7172[0m,                 val_F1 Score: [4;35m0.7085[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  613
Epoch [72/100], Loss: 1.8159
train_Accuracy: [91m0.9963[0m
train_Precision: [4;34m0.9964[0m,               train_Recall: [4;33m0.9966[0m,                 train_F1 Score: [4;35m0.9964[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4284
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9896e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.2527e-03],
        [9.9995e-01],
        [3.3204e-07],
        [1.3086e-06],
        [5.4283e-03],
        [9.9318e-01],
        [9.9986e-01],
        [3.8333e-13],
        [4.8964e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((14, 20), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
Epoch [72/100], Loss: 77.7066
val_Accuracy: [92m0.7140[0m
val_Precision: [4;34m0.7161[0m,               val_Recall: [4;33m0.7096[0m,                 val_F1 Score: [4;35m0.7067[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  614
Epoch [73/100], Loss: 1.6455
train_Accuracy: [91m0.9974[0m
train_Precision: [4;34m0.9976[0m,               train_Recall: [4;33m0.9976[0m,                 train_F1 Score: [4;35m0.9975[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4289
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9924e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.0345e-02],
        [1.0000e+00],
        [1.1823e-06],
        [7.5207e-06],
        [3.5319e-03],
        [9.9320e-01],
        [9.9994e-01],
        [3.0216e-13],
        [1.7902e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 5), 1)
((4, 15), 1)
((4, 15), 1)
((4, 15), 1)
((4, 15), 1)
((4, 15), 1)
((4, 15), 1)
((4, 15), 1)
((4, 15), 1)
((4, 15), 1)
((13, 18), 1)
((13, 18), 1)
((15, 21), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
Epoch [73/100], Loss: 62.9594
val_Accuracy: [92m0.6709[0m
val_Precision: [4;34m0.6657[0m,               val_Recall: [4;33m0.6864[0m,                 val_F1 Score: [4;35m0.6685[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  577
Epoch [74/100], Loss: 4.8882
train_Accuracy: [91m0.9970[0m
train_Precision: [4;34m0.9969[0m,               train_Recall: [4;33m0.9975[0m,                 train_F1 Score: [4;35m0.9971[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4287
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9995e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.0253e-03],
        [1.0000e+00],
        [3.4301e-08],
        [9.6936e-06],
        [1.1410e-02],
        [9.9063e-01],
        [9.9915e-01],
        [1.3752e-11],
        [6.1418e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
Epoch [74/100], Loss: 77.6771
val_Accuracy: [92m0.7047[0m
val_Precision: [4;34m0.7556[0m,               val_Recall: [4;33m0.6071[0m,                 val_F1 Score: [4;35m0.6656[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  606
Epoch [75/100], Loss: 9.0293
train_Accuracy: [91m0.9858[0m
train_Precision: [4;34m0.9827[0m,               train_Recall: [4;33m0.9894[0m,                 train_F1 Score: [4;35m0.9857[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4239
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9675e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.0111e-05],
        [1.0000e+00],
        [8.2763e-06],
        [4.9515e-07],
        [5.6462e-02],
        [9.7818e-01],
        [9.9798e-01],
        [1.6102e-16],
        [1.6134e-01]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((16, 20), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
Epoch [75/100], Loss: 76.7863
val_Accuracy: [92m0.6953[0m
val_Precision: [4;34m0.7341[0m,               val_Recall: [4;33m0.6016[0m,                 val_F1 Score: [4;35m0.6556[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  598
Epoch [76/100], Loss: 7.7504
train_Accuracy: [91m0.9765[0m
train_Precision: [4;34m0.9704[0m,               train_Recall: [4;33m0.9825[0m,                 train_F1 Score: [4;35m0.9756[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4199
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[7.8847e-01],
        [1.0000e+00],
        [1.0000e+00],
        [5.5011e-05],
        [1.0000e+00],
        [6.0492e-05],
        [1.4140e-07],
        [1.1518e-04],
        [7.0990e-01],
        [9.9998e-01],
        [2.2709e-11],
        [4.7204e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 13), 1)
((22, 17), 1)
((22, 17), 1)
((22, 17), 1)
((22, 17), 1)
((22, 17), 1)
Epoch [76/100], Loss: 92.0457
val_Accuracy: [92m0.6837[0m
val_Precision: [4;34m0.7286[0m,               val_Recall: [4;33m0.5870[0m,                 val_F1 Score: [4;35m0.6432[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  588
Epoch [77/100], Loss: 6.8937
train_Accuracy: [91m0.9802[0m
train_Precision: [4;34m0.9741[0m,               train_Recall: [4;33m0.9862[0m,                 train_F1 Score: [4;35m0.9794[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4215
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9992e-01],
        [9.9998e-01],
        [1.0000e+00],
        [6.7856e-05],
        [9.9998e-01],
        [9.8136e-05],
        [1.1915e-05],
        [1.2510e-04],
        [1.0000e+00],
        [9.9999e-01],
        [3.7927e-15],
        [1.2669e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((22, 17), 1)
((22, 17), 1)
((22, 17), 1)
((22, 17), 1)
((22, 17), 1)
((22, 17), 1)
((22, 17), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
Epoch [77/100], Loss: 103.1827
val_Accuracy: [92m0.7535[0m
val_Precision: [4;34m0.7816[0m,               val_Recall: [4;33m0.7088[0m,                 val_F1 Score: [4;35m0.7377[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  648
Epoch [78/100], Loss: 7.9430
train_Accuracy: [91m0.9786[0m
train_Precision: [4;34m0.9738[0m,               train_Recall: [4;33m0.9825[0m,                 train_F1 Score: [4;35m0.9774[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4208
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9994e-01],
        [9.9795e-01],
        [1.0000e+00],
        [1.2252e-01],
        [1.0000e+00],
        [2.0679e-06],
        [3.2366e-05],
        [1.6719e-02],
        [9.9964e-01],
        [9.7912e-01],
        [1.0493e-12],
        [5.4770e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((7, 5), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
Epoch [78/100], Loss: 81.5548
val_Accuracy: [92m0.7070[0m
val_Precision: [4;34m0.7392[0m,               val_Recall: [4;33m0.6392[0m,                 val_F1 Score: [4;35m0.6791[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  608
Epoch [79/100], Loss: 5.1561
train_Accuracy: [91m0.9851[0m
train_Precision: [4;34m0.9814[0m,               train_Recall: [4;33m0.9894[0m,                 train_F1 Score: [4;35m0.9848[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4236
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [2.5787e-03],
        [1.0000e+00],
        [1.3912e-06],
        [2.4419e-06],
        [1.5321e-02],
        [9.9984e-01],
        [9.2373e-01],
        [9.9413e-12],
        [1.1625e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((9, 17), 1)
((14, 17), 1)
((14, 17), 1)
((14, 17), 1)
((14, 17), 1)
((14, 17), 1)
((14, 17), 1)
((20, 20), 1)
((20, 20), 1)
((20, 20), 1)
((20, 20), 1)
((20, 20), 1)
((20, 20), 1)
((20, 20), 1)
Epoch [79/100], Loss: 72.7090
val_Accuracy: [92m0.6756[0m
val_Precision: [4;34m0.6727[0m,               val_Recall: [4;33m0.6780[0m,                 val_F1 Score: [4;35m0.6679[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  581
Epoch [80/100], Loss: 2.7286
train_Accuracy: [91m0.9956[0m
train_Precision: [4;34m0.9943[0m,               train_Recall: [4;33m0.9969[0m,                 train_F1 Score: [4;35m0.9955[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4281
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9985e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.6920e-04],
        [9.9997e-01],
        [7.1356e-04],
        [8.1566e-07],
        [6.5981e-03],
        [9.9823e-01],
        [9.9133e-01],
        [2.6921e-10],
        [3.1644e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((20, 20), 1)
((20, 20), 1)
((20, 20), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
Epoch [80/100], Loss: 93.0090
val_Accuracy: [92m0.7337[0m
val_Precision: [4;34m0.7513[0m,               val_Recall: [4;33m0.6935[0m,                 val_F1 Score: [4;35m0.7154[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  631
Epoch [81/100], Loss: 1.2973
train_Accuracy: [91m0.9972[0m
train_Precision: [4;34m0.9950[0m,               train_Recall: [4;33m0.9992[0m,                 train_F1 Score: [4;35m0.9970[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4288
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9963e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.3684e-07],
        [1.0000e+00],
        [1.5356e-03],
        [6.3410e-06],
        [4.5059e-03],
        [9.9183e-01],
        [9.7146e-01],
        [2.2701e-12],
        [2.1333e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((3, 9), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((8, 16), 1)
((26, 17), 1)
Epoch [81/100], Loss: 98.9774
val_Accuracy: [92m0.7337[0m
val_Precision: [4;34m0.7262[0m,               val_Recall: [4;33m0.7522[0m,                 val_F1 Score: [4;35m0.7319[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  631
Epoch [82/100], Loss: 0.6223
train_Accuracy: [91m0.9995[0m
train_Precision: [4;34m0.9996[0m,               train_Recall: [4;33m0.9996[0m,                 train_F1 Score: [4;35m0.9996[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4298
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9863e-01],
        [1.0000e+00],
        [1.0000e+00],
        [7.0860e-06],
        [1.0000e+00],
        [2.4786e-04],
        [4.6741e-07],
        [6.2023e-03],
        [9.9749e-01],
        [9.9987e-01],
        [7.0893e-12],
        [1.6202e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
((0, 7), 1)
Epoch [82/100], Loss: 95.6157
val_Accuracy: [92m0.7326[0m
val_Precision: [4;34m0.7206[0m,               val_Recall: [4;33m0.7569[0m,                 val_F1 Score: [4;35m0.7329[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  630
Epoch [83/100], Loss: 0.2856
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9888e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.4812e-06],
        [1.0000e+00],
        [3.4928e-04],
        [3.5084e-07],
        [7.4608e-04],
        [9.9851e-01],
        [9.9996e-01],
        [2.4393e-11],
        [4.9446e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [83/100], Loss: 107.8854
val_Accuracy: [92m0.7453[0m
val_Precision: [4;34m0.7358[0m,               val_Recall: [4;33m0.7652[0m,                 val_F1 Score: [4;35m0.7443[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  641
Epoch [84/100], Loss: 0.1619
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9916e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.6926e-06],
        [1.0000e+00],
        [3.7406e-04],
        [2.6688e-07],
        [5.9794e-04],
        [9.9880e-01],
        [9.9997e-01],
        [2.4345e-11],
        [2.8837e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [84/100], Loss: 105.8009
val_Accuracy: [92m0.7453[0m
val_Precision: [4;34m0.7371[0m,               val_Recall: [4;33m0.7631[0m,                 val_F1 Score: [4;35m0.7440[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  641
Epoch [85/100], Loss: 0.1309
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9931e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.9279e-06],
        [1.0000e+00],
        [3.6305e-04],
        [2.1335e-07],
        [5.6195e-04],
        [9.9900e-01],
        [9.9998e-01],
        [2.2693e-11],
        [2.1907e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [85/100], Loss: 106.2652
val_Accuracy: [92m0.7453[0m
val_Precision: [4;34m0.7371[0m,               val_Recall: [4;33m0.7633[0m,                 val_F1 Score: [4;35m0.7442[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  641
Epoch [86/100], Loss: 0.1125
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9942e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.1995e-06],
        [1.0000e+00],
        [3.4827e-04],
        [1.7511e-07],
        [4.9629e-04],
        [9.9919e-01],
        [9.9998e-01],
        [2.0292e-11],
        [1.8135e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [86/100], Loss: 106.6766
val_Accuracy: [92m0.7465[0m
val_Precision: [4;34m0.7388[0m,               val_Recall: [4;33m0.7633[0m,                 val_F1 Score: [4;35m0.7449[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  642
Epoch [87/100], Loss: 0.0991
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9950e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.5434e-06],
        [1.0000e+00],
        [3.2673e-04],
        [1.4556e-07],
        [5.1129e-04],
        [9.9931e-01],
        [9.9998e-01],
        [1.8227e-11],
        [1.4492e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [87/100], Loss: 107.0251
val_Accuracy: [92m0.7453[0m
val_Precision: [4;34m0.7375[0m,               val_Recall: [4;33m0.7633[0m,                 val_F1 Score: [4;35m0.7442[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  641
Epoch [88/100], Loss: 0.0887
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9956e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.9925e-06],
        [1.0000e+00],
        [3.2027e-04],
        [1.1998e-07],
        [4.6429e-04],
        [9.9941e-01],
        [9.9999e-01],
        [1.6088e-11],
        [1.3243e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [88/100], Loss: 107.3127
val_Accuracy: [92m0.7465[0m
val_Precision: [4;34m0.7388[0m,               val_Recall: [4;33m0.7633[0m,                 val_F1 Score: [4;35m0.7450[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  642
Epoch [89/100], Loss: 0.0804
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9963e-01],
        [1.0000e+00],
        [1.0000e+00],
        [3.4555e-06],
        [1.0000e+00],
        [3.1752e-04],
        [1.0170e-07],
        [4.2888e-04],
        [9.9951e-01],
        [9.9999e-01],
        [1.4349e-11],
        [1.0308e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [89/100], Loss: 110.2388
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7379[0m,               val_Recall: [4;33m0.7670[0m,                 val_F1 Score: [4;35m0.7463[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [90/100], Loss: 0.0733
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9968e-01],
        [1.0000e+00],
        [1.0000e+00],
        [4.0217e-06],
        [1.0000e+00],
        [3.1888e-04],
        [8.0049e-08],
        [4.7878e-04],
        [9.9957e-01],
        [9.9999e-01],
        [1.2188e-11],
        [8.6890e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [90/100], Loss: 110.4963
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7379[0m,               val_Recall: [4;33m0.7670[0m,                 val_F1 Score: [4;35m0.7463[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [91/100], Loss: 0.0675
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9973e-01],
        [1.0000e+00],
        [1.0000e+00],
        [4.4435e-06],
        [1.0000e+00],
        [3.0643e-04],
        [6.6869e-08],
        [4.2726e-04],
        [9.9962e-01],
        [9.9999e-01],
        [9.7370e-12],
        [9.6194e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [91/100], Loss: 110.7415
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7379[0m,               val_Recall: [4;33m0.7670[0m,                 val_F1 Score: [4;35m0.7463[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [92/100], Loss: 0.0627
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9977e-01],
        [1.0000e+00],
        [1.0000e+00],
        [4.9766e-06],
        [1.0000e+00],
        [2.9812e-04],
        [5.4189e-08],
        [4.3220e-04],
        [9.9968e-01],
        [9.9999e-01],
        [8.3689e-12],
        [7.7572e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [92/100], Loss: 110.9985
val_Accuracy: [92m0.7500[0m
val_Precision: [4;34m0.7410[0m,               val_Recall: [4;33m0.7670[0m,                 val_F1 Score: [4;35m0.7479[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  645
Epoch [93/100], Loss: 0.0583
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9980e-01],
        [1.0000e+00],
        [1.0000e+00],
        [5.2889e-06],
        [1.0000e+00],
        [2.7721e-04],
        [4.4909e-08],
        [4.0473e-04],
        [9.9971e-01],
        [9.9999e-01],
        [6.9515e-12],
        [7.3257e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [93/100], Loss: 113.8338
val_Accuracy: [92m0.7500[0m
val_Precision: [4;34m0.7411[0m,               val_Recall: [4;33m0.7670[0m,                 val_F1 Score: [4;35m0.7479[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  645
Epoch [94/100], Loss: 0.0545
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9984e-01],
        [1.0000e+00],
        [1.0000e+00],
        [5.6107e-06],
        [1.0000e+00],
        [2.5324e-04],
        [3.7795e-08],
        [3.6548e-04],
        [9.9976e-01],
        [1.0000e+00],
        [5.8336e-12],
        [6.4495e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [94/100], Loss: 111.4407
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7402[0m,               val_Recall: [4;33m0.7626[0m,                 val_F1 Score: [4;35m0.7449[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [95/100], Loss: 0.0511
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9985e-01],
        [1.0000e+00],
        [1.0000e+00],
        [6.0368e-06],
        [1.0000e+00],
        [2.4804e-04],
        [3.0815e-08],
        [3.2314e-04],
        [9.9977e-01],
        [1.0000e+00],
        [4.7558e-12],
        [6.7842e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [95/100], Loss: 111.6519
val_Accuracy: [92m0.7465[0m
val_Precision: [4;34m0.7388[0m,               val_Recall: [4;33m0.7626[0m,                 val_F1 Score: [4;35m0.7440[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  642
Epoch [96/100], Loss: 0.0482
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9987e-01],
        [1.0000e+00],
        [1.0000e+00],
        [6.9790e-06],
        [1.0000e+00],
        [2.3366e-04],
        [2.5803e-08],
        [2.8814e-04],
        [9.9980e-01],
        [1.0000e+00],
        [4.0590e-12],
        [6.0956e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [96/100], Loss: 111.9148
val_Accuracy: [92m0.7465[0m
val_Precision: [4;34m0.7388[0m,               val_Recall: [4;33m0.7626[0m,                 val_F1 Score: [4;35m0.7440[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  642
Epoch [97/100], Loss: 0.0456
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9989e-01],
        [1.0000e+00],
        [1.0000e+00],
        [8.3918e-06],
        [1.0000e+00],
        [2.3919e-04],
        [2.2598e-08],
        [2.5636e-04],
        [9.9982e-01],
        [1.0000e+00],
        [3.2996e-12],
        [5.1807e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [97/100], Loss: 112.1178
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7404[0m,               val_Recall: [4;33m0.7626[0m,                 val_F1 Score: [4;35m0.7448[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [98/100], Loss: 0.0433
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9989e-01],
        [1.0000e+00],
        [1.0000e+00],
        [9.3109e-06],
        [1.0000e+00],
        [2.5345e-04],
        [1.8771e-08],
        [2.2993e-04],
        [9.9983e-01],
        [1.0000e+00],
        [2.8276e-12],
        [4.6245e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [98/100], Loss: 112.3090
val_Accuracy: [92m0.7465[0m
val_Precision: [4;34m0.7391[0m,               val_Recall: [4;33m0.7634[0m,                 val_F1 Score: [4;35m0.7447[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  642
Epoch [99/100], Loss: 0.0411
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9991e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.0879e-05],
        [1.0000e+00],
        [2.5043e-04],
        [1.6245e-08],
        [2.2250e-04],
        [9.9985e-01],
        [1.0000e+00],
        [2.4519e-12],
        [3.5543e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [99/100], Loss: 112.5237
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7406[0m,               val_Recall: [4;33m0.7634[0m,                 val_F1 Score: [4;35m0.7455[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [100/100], Loss: 0.0392
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9992e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.2073e-05],
        [1.0000e+00],
        [2.4757e-04],
        [1.3516e-08],
        [2.0161e-04],
        [9.9987e-01],
        [1.0000e+00],
        [1.9026e-12],
        [4.0758e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
((0, 7), 2)
Epoch [100/100], Loss: 112.7867
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7406[0m,               val_Recall: [4;33m0.7634[0m,                 val_F1 Score: [4;35m0.7455[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
第1批第0个, 100
第1批第22个, 100
第2批第12个, 100
第3批第21个, 100
第3批第28个, 100
send email successfully
