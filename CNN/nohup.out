2024-06-23-16:07:43
不冻排序128阈值0.4
创建模型实例
模型实例创建完成
加载预训练参数
预训练参数加载完成
Epoch [1/100], Loss: 61.2221
train_Accuracy: [91m0.7965[0m
train_Precision: [4;34m0.7900[0m,               train_Recall: [4;33m0.8230[0m,                 train_F1 Score: [4;35m0.8001[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3425
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9282],
        [0.7848],
        [0.9466],
        [0.1656],
        [0.8303],
        [0.1102],
        [0.4835],
        [0.3639],
        [0.4732],
        [0.9351],
        [0.0608],
        [0.0578]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [1/100], T_AUC: [4m0.8026[0m
Epoch [1/100], Loss: 14.3066
val_Accuracy: [92m0.7698[0m
val_Precision: [4;34m0.7421[0m,               val_Recall: [4;33m0.8135[0m,                 val_F1 Score: [4;35m0.7724[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  662
Epoch [1/100], V_AUC: [4m0.7675[0m
Epoch [2/100], Loss: 58.6988
train_Accuracy: [91m0.8077[0m
train_Precision: [4;34m0.7970[0m,               train_Recall: [4;33m0.8348[0m,                 train_F1 Score: [4;35m0.8098[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3473
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9213],
        [0.7538],
        [0.9722],
        [0.1225],
        [0.8456],
        [0.0747],
        [0.4145],
        [0.5208],
        [0.5285],
        [0.9167],
        [0.0714],
        [0.0542]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [2/100], T_AUC: [4m0.8125[0m
Epoch [2/100], Loss: 14.1404
val_Accuracy: [92m0.7826[0m
val_Precision: [4;34m0.7701[0m,               val_Recall: [4;33m0.7941[0m,                 val_F1 Score: [4;35m0.7774[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  673
Epoch [2/100], V_AUC: [4m0.7815[0m
Epoch [3/100], Loss: 56.9024
train_Accuracy: [91m0.8109[0m
train_Precision: [4;34m0.8003[0m,               train_Recall: [4;33m0.8382[0m,                 train_F1 Score: [4;35m0.8134[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3487
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9135],
        [0.7376],
        [0.9743],
        [0.1497],
        [0.8720],
        [0.0538],
        [0.3620],
        [0.4437],
        [0.5864],
        [0.9410],
        [0.0834],
        [0.0459]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [3/100], T_AUC: [4m0.8165[0m
Epoch [3/100], Loss: 14.2668
val_Accuracy: [92m0.7791[0m
val_Precision: [4;34m0.7650[0m,               val_Recall: [4;33m0.7957[0m,                 val_F1 Score: [4;35m0.7753[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  670
Epoch [3/100], V_AUC: [4m0.7769[0m
Epoch [4/100], Loss: 55.3613
train_Accuracy: [91m0.8151[0m
train_Precision: [4;34m0.8045[0m,               train_Recall: [4;33m0.8451[0m,                 train_F1 Score: [4;35m0.8187[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3505
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9251],
        [0.8379],
        [0.9721],
        [0.1313],
        [0.8799],
        [0.0330],
        [0.3311],
        [0.3114],
        [0.6302],
        [0.9537],
        [0.0876],
        [0.0575]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [4/100], T_AUC: [4m0.8210[0m
Epoch [4/100], Loss: 14.4278
val_Accuracy: [92m0.7860[0m
val_Precision: [4;34m0.7735[0m,               val_Recall: [4;33m0.7993[0m,                 val_F1 Score: [4;35m0.7803[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  676
Epoch [4/100], V_AUC: [4m0.7839[0m
Epoch [5/100], Loss: 54.1968
train_Accuracy: [91m0.8230[0m
train_Precision: [4;34m0.8122[0m,               train_Recall: [4;33m0.8516[0m,                 train_F1 Score: [4;35m0.8257[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3539
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9423],
        [0.8441],
        [0.9766],
        [0.0847],
        [0.9146],
        [0.0379],
        [0.3057],
        [0.2696],
        [0.5838],
        [0.9513],
        [0.0898],
        [0.0591]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [5/100], T_AUC: [4m0.8293[0m
Epoch [5/100], Loss: 14.7112
val_Accuracy: [92m0.7698[0m
val_Precision: [4;34m0.7502[0m,               val_Recall: [4;33m0.8001[0m,                 val_F1 Score: [4;35m0.7685[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  662
Epoch [5/100], V_AUC: [4m0.7686[0m
Epoch [6/100], Loss: 52.4624
train_Accuracy: [91m0.8260[0m
train_Precision: [4;34m0.8141[0m,               train_Recall: [4;33m0.8540[0m,                 train_F1 Score: [4;35m0.8285[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3552
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9364],
        [0.8531],
        [0.9776],
        [0.0999],
        [0.9053],
        [0.0264],
        [0.1445],
        [0.2762],
        [0.6646],
        [0.9730],
        [0.1266],
        [0.0615]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [6/100], T_AUC: [4m0.8315[0m
Epoch [6/100], Loss: 15.2194
val_Accuracy: [92m0.7814[0m
val_Precision: [4;34m0.7813[0m,               val_Recall: [4;33m0.7717[0m,                 val_F1 Score: [4;35m0.7715[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  672
Epoch [6/100], V_AUC: [4m0.7771[0m
Epoch [7/100], Loss: 50.5878
train_Accuracy: [91m0.8340[0m
train_Precision: [4;34m0.8168[0m,               train_Recall: [4;33m0.8697[0m,                 train_F1 Score: [4;35m0.8373[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3586
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9612],
        [0.7733],
        [0.9903],
        [0.0647],
        [0.9038],
        [0.0344],
        [0.2349],
        [0.2463],
        [0.6897],
        [0.9534],
        [0.1126],
        [0.0419]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [7/100], T_AUC: [4m0.8396[0m
Epoch [7/100], Loss: 15.4514
val_Accuracy: [92m0.7698[0m
val_Precision: [4;34m0.7571[0m,               val_Recall: [4;33m0.7776[0m,                 val_F1 Score: [4;35m0.7628[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  662
Epoch [7/100], V_AUC: [4m0.7655[0m
Epoch [8/100], Loss: 50.0861
train_Accuracy: [91m0.8349[0m
train_Precision: [4;34m0.8190[0m,               train_Recall: [4;33m0.8721[0m,                 train_F1 Score: [4;35m0.8390[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3590
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9389],
        [0.8654],
        [0.9875],
        [0.0484],
        [0.9414],
        [0.0207],
        [0.1435],
        [0.1593],
        [0.6786],
        [0.9712],
        [0.1337],
        [0.1000]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [8/100], T_AUC: [4m0.8413[0m
Epoch [8/100], Loss: 15.5696
val_Accuracy: [92m0.7686[0m
val_Precision: [4;34m0.7519[0m,               val_Recall: [4;33m0.7909[0m,                 val_F1 Score: [4;35m0.7660[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  661
Epoch [8/100], V_AUC: [4m0.7646[0m
Epoch [9/100], Loss: 45.9113
train_Accuracy: [91m0.8530[0m
train_Precision: [4;34m0.8364[0m,               train_Recall: [4;33m0.8841[0m,                 train_F1 Score: [4;35m0.8553[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3668
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8855],
        [0.8933],
        [0.9981],
        [0.0167],
        [0.9344],
        [0.0414],
        [0.1598],
        [0.1239],
        [0.8114],
        [0.9592],
        [0.0875],
        [0.0629]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [9/100], T_AUC: [4m0.8578[0m
Epoch [9/100], Loss: 16.7483
val_Accuracy: [92m0.7674[0m
val_Precision: [4;34m0.7728[0m,               val_Recall: [4;33m0.7486[0m,                 val_F1 Score: [4;35m0.7547[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  660
Epoch [9/100], V_AUC: [4m0.7631[0m
Epoch [10/100], Loss: 45.3366
train_Accuracy: [91m0.8509[0m
train_Precision: [4;34m0.8396[0m,               train_Recall: [4;33m0.8780[0m,                 train_F1 Score: [4;35m0.8535[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3659
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9151],
        [0.7225],
        [0.9982],
        [0.0351],
        [0.8952],
        [0.0466],
        [0.0748],
        [0.1961],
        [0.7712],
        [0.9764],
        [0.0915],
        [0.0940]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [10/100], T_AUC: [4m0.8564[0m
Epoch [10/100], Loss: 16.8331
val_Accuracy: [92m0.7698[0m
val_Precision: [4;34m0.8080[0m,               val_Recall: [4;33m0.6998[0m,                 val_F1 Score: [4;35m0.7456[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  662
Epoch [10/100], V_AUC: [4m0.7670[0m
Epoch [11/100], Loss: 42.3991
train_Accuracy: [91m0.8616[0m
train_Precision: [4;34m0.8480[0m,               train_Recall: [4;33m0.8908[0m,                 train_F1 Score: [4;35m0.8637[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3705
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6461],
        [0.9554],
        [0.9915],
        [0.0579],
        [0.9822],
        [0.0212],
        [0.1420],
        [0.1981],
        [0.8625],
        [0.9250],
        [0.0494],
        [0.1465]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [11/100], T_AUC: [4m0.8673[0m
Epoch [11/100], Loss: 17.4207
val_Accuracy: [92m0.7651[0m
val_Precision: [4;34m0.7705[0m,               val_Recall: [4;33m0.7393[0m,                 val_F1 Score: [4;35m0.7501[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  658
Epoch [11/100], V_AUC: [4m0.7635[0m
Epoch [12/100], Loss: 41.3895
train_Accuracy: [91m0.8649[0m
train_Precision: [4;34m0.8515[0m,               train_Recall: [4;33m0.8924[0m,                 train_F1 Score: [4;35m0.8668[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3719
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9444],
        [0.8274],
        [0.9525],
        [0.0311],
        [0.9736],
        [0.0088],
        [0.0507],
        [0.1919],
        [0.9289],
        [0.9960],
        [0.0672],
        [0.1677]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [12/100], T_AUC: [4m0.8700[0m
Epoch [12/100], Loss: 18.2813
val_Accuracy: [92m0.7605[0m
val_Precision: [4;34m0.8146[0m,               val_Recall: [4;33m0.6681[0m,                 val_F1 Score: [4;35m0.7257[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  654
Epoch [12/100], V_AUC: [4m0.7584[0m
Epoch [13/100], Loss: 48.4128
train_Accuracy: [91m0.8340[0m
train_Precision: [4;34m0.8181[0m,               train_Recall: [4;33m0.8676[0m,                 train_F1 Score: [4;35m0.8372[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3586
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9929],
        [0.7109],
        [0.6649],
        [0.0768],
        [0.6866],
        [0.2674],
        [0.1871],
        [0.5829],
        [0.6054],
        [0.9796],
        [0.0832],
        [0.0777]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [13/100], T_AUC: [4m0.8388[0m
Epoch [13/100], Loss: 16.3728
val_Accuracy: [92m0.7256[0m
val_Precision: [4;34m0.7379[0m,               val_Recall: [4;33m0.6957[0m,                 val_F1 Score: [4;35m0.7113[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  624
Epoch [13/100], V_AUC: [4m0.7229[0m
Epoch [14/100], Loss: 68.5903
train_Accuracy: [91m0.7556[0m
train_Precision: [4;34m0.7417[0m,               train_Recall: [4;33m0.7981[0m,                 train_F1 Score: [4;35m0.7626[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3249
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9062],
        [0.8463],
        [0.9452],
        [0.0667],
        [0.5742],
        [0.1834],
        [0.3317],
        [0.5856],
        [0.5876],
        [0.9659],
        [0.0636],
        [0.1332]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [14/100], T_AUC: [4m0.7614[0m
Epoch [14/100], Loss: 15.2355
val_Accuracy: [92m0.7512[0m
val_Precision: [4;34m0.7900[0m,               val_Recall: [4;33m0.6827[0m,                 val_F1 Score: [4;35m0.7278[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  646
Epoch [14/100], V_AUC: [4m0.7503[0m
Epoch [15/100], Loss: 60.8177
train_Accuracy: [91m0.7923[0m
train_Precision: [4;34m0.7821[0m,               train_Recall: [4;33m0.8214[0m,                 train_F1 Score: [4;35m0.7952[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3407
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8867],
        [0.7979],
        [0.9673],
        [0.0760],
        [0.9275],
        [0.1901],
        [0.1675],
        [0.4155],
        [0.5659],
        [0.9430],
        [0.0877],
        [0.0741]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [15/100], T_AUC: [4m0.7985[0m
Epoch [15/100], Loss: 15.3295
val_Accuracy: [92m0.7651[0m
val_Precision: [4;34m0.8208[0m,               val_Recall: [4;33m0.6762[0m,                 val_F1 Score: [4;35m0.7359[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  658
Epoch [15/100], V_AUC: [4m0.7653[0m
Epoch [16/100], Loss: 56.3700
train_Accuracy: [91m0.8123[0m
train_Precision: [4;34m0.8014[0m,               train_Recall: [4;33m0.8407[0m,                 train_F1 Score: [4;35m0.8147[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3493
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8325],
        [0.8473],
        [0.9585],
        [0.0220],
        [0.9333],
        [0.1048],
        [0.2682],
        [0.3566],
        [0.6768],
        [0.9930],
        [0.0470],
        [0.0896]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [16/100], T_AUC: [4m0.8181[0m
Epoch [16/100], Loss: 15.3975
val_Accuracy: [92m0.7663[0m
val_Precision: [4;34m0.8025[0m,               val_Recall: [4;33m0.7074[0m,                 val_F1 Score: [4;35m0.7459[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  659
Epoch [16/100], V_AUC: [4m0.7656[0m
Epoch [17/100], Loss: 51.5436
train_Accuracy: [91m0.8291[0m
train_Precision: [4;34m0.8138[0m,               train_Recall: [4;33m0.8622[0m,                 train_F1 Score: [4;35m0.8321[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3565
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9414],
        [0.9054],
        [0.9561],
        [0.0152],
        [0.9273],
        [0.0968],
        [0.1455],
        [0.3192],
        [0.6198],
        [0.9951],
        [0.0526],
        [0.0565]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [17/100], T_AUC: [4m0.8344[0m
Epoch [17/100], Loss: 14.9718
val_Accuracy: [92m0.7709[0m
val_Precision: [4;34m0.7868[0m,               val_Recall: [4;33m0.7409[0m,                 val_F1 Score: [4;35m0.7578[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  663
Epoch [17/100], V_AUC: [4m0.7693[0m
Epoch [18/100], Loss: 46.0980
train_Accuracy: [91m0.8523[0m
train_Precision: [4;34m0.8362[0m,               train_Recall: [4;33m0.8840[0m,                 train_F1 Score: [4;35m0.8546[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3665
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7935],
        [0.9373],
        [0.9858],
        [0.0177],
        [0.9703],
        [0.1018],
        [0.0817],
        [0.2739],
        [0.7200],
        [0.9955],
        [0.0296],
        [0.0570]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [18/100], T_AUC: [4m0.8573[0m
Epoch [18/100], Loss: 15.4820
val_Accuracy: [92m0.7733[0m
val_Precision: [4;34m0.7736[0m,               val_Recall: [4;33m0.7705[0m,                 val_F1 Score: [4;35m0.7678[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  665
Epoch [18/100], V_AUC: [4m0.7711[0m
Epoch [19/100], Loss: 42.6875
train_Accuracy: [91m0.8677[0m
train_Precision: [4;34m0.8550[0m,               train_Recall: [4;33m0.8923[0m,                 train_F1 Score: [4;35m0.8687[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3731
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6771],
        [0.9704],
        [0.9635],
        [0.0217],
        [0.9886],
        [0.0713],
        [0.0885],
        [0.1269],
        [0.8136],
        [0.9964],
        [0.0314],
        [0.0932]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [19/100], T_AUC: [4m0.8731[0m
Epoch [19/100], Loss: 16.1428
val_Accuracy: [92m0.7744[0m
val_Precision: [4;34m0.7855[0m,               val_Recall: [4;33m0.7565[0m,                 val_F1 Score: [4;35m0.7650[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  666
Epoch [19/100], V_AUC: [4m0.7721[0m
Epoch [20/100], Loss: 38.2148
train_Accuracy: [91m0.8767[0m
train_Precision: [4;34m0.8608[0m,               train_Recall: [4;33m0.9064[0m,                 train_F1 Score: [4;35m0.8784[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3770
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9109],
        [0.9746],
        [0.9905],
        [0.0133],
        [0.9776],
        [0.0374],
        [0.0322],
        [0.1739],
        [0.8368],
        [0.9915],
        [0.0446],
        [0.0925]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [20/100], T_AUC: [4m0.8826[0m
Epoch [20/100], Loss: 17.5606
val_Accuracy: [92m0.7605[0m
val_Precision: [4;34m0.7670[0m,               val_Recall: [4;33m0.7468[0m,                 val_F1 Score: [4;35m0.7520[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  654
Epoch [20/100], V_AUC: [4m0.7608[0m
Epoch [21/100], Loss: 34.6548
train_Accuracy: [91m0.8926[0m
train_Precision: [4;34m0.8750[0m,               train_Recall: [4;33m0.9211[0m,                 train_F1 Score: [4;35m0.8936[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3838
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9141],
        [0.9889],
        [0.9843],
        [0.0112],
        [0.9813],
        [0.0207],
        [0.1921],
        [0.0236],
        [0.9568],
        [0.9979],
        [0.0122],
        [0.0343]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [21/100], T_AUC: [4m0.8974[0m
Epoch [21/100], Loss: 18.4675
val_Accuracy: [92m0.7802[0m
val_Precision: [4;34m0.8012[0m,               val_Recall: [4;33m0.7429[0m,                 val_F1 Score: [4;35m0.7675[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  671
Epoch [21/100], V_AUC: [4m0.7784[0m
Epoch [22/100], Loss: 31.7677
train_Accuracy: [91m0.9000[0m
train_Precision: [4;34m0.8846[0m,               train_Recall: [4;33m0.9260[0m,                 train_F1 Score: [4;35m0.9006[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3870
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9483],
        [0.9947],
        [0.9953],
        [0.0096],
        [0.9229],
        [0.0144],
        [0.0735],
        [0.0367],
        [0.9508],
        [0.9985],
        [0.0088],
        [0.0544]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [22/100], T_AUC: [4m0.9055[0m
Epoch [22/100], Loss: 20.6168
val_Accuracy: [92m0.7698[0m
val_Precision: [4;34m0.8173[0m,               val_Recall: [4;33m0.6957[0m,                 val_F1 Score: [4;35m0.7453[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  662
Epoch [22/100], V_AUC: [4m0.7679[0m
Epoch [23/100], Loss: 27.8296
train_Accuracy: [91m0.9172[0m
train_Precision: [4;34m0.9027[0m,               train_Recall: [4;33m0.9399[0m,                 train_F1 Score: [4;35m0.9171[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3944
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8824],
        [0.9991],
        [0.6150],
        [0.0239],
        [0.9984],
        [0.0162],
        [0.0106],
        [0.0529],
        [0.9899],
        [0.9845],
        [0.0142],
        [0.2134]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [23/100], T_AUC: [4m0.9220[0m
Epoch [23/100], Loss: 20.6068
val_Accuracy: [92m0.7488[0m
val_Precision: [4;34m0.7587[0m,               val_Recall: [4;33m0.7286[0m,                 val_F1 Score: [4;35m0.7382[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  644
Epoch [23/100], V_AUC: [4m0.7478[0m
Epoch [24/100], Loss: 25.7451
train_Accuracy: [91m0.9184[0m
train_Precision: [4;34m0.8999[0m,               train_Recall: [4;33m0.9431[0m,                 train_F1 Score: [4;35m0.9176[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3949
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9983e-01],
        [9.8773e-01],
        [8.2081e-01],
        [1.5579e-02],
        [9.9820e-01],
        [4.4628e-04],
        [9.4096e-02],
        [1.7963e-01],
        [5.7819e-01],
        [9.9559e-01],
        [1.0504e-02],
        [1.0513e-01]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [24/100], T_AUC: [4m0.9226[0m
Epoch [24/100], Loss: 22.2228
val_Accuracy: [92m0.7256[0m
val_Precision: [4;34m0.7340[0m,               val_Recall: [4;33m0.6936[0m,                 val_F1 Score: [4;35m0.7085[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  624
Epoch [24/100], V_AUC: [4m0.7229[0m
Epoch [25/100], Loss: 44.3533
train_Accuracy: [91m0.8581[0m
train_Precision: [4;34m0.8426[0m,               train_Recall: [4;33m0.8889[0m,                 train_F1 Score: [4;35m0.8598[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3690
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9879],
        [0.9960],
        [0.9935],
        [0.0046],
        [0.8495],
        [0.0166],
        [0.4459],
        [0.0248],
        [0.8345],
        [0.9554],
        [0.1726],
        [0.1348]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [25/100], T_AUC: [4m0.8637[0m
Epoch [25/100], Loss: 19.2878
val_Accuracy: [92m0.7372[0m
val_Precision: [4;34m0.7194[0m,               val_Recall: [4;33m0.7681[0m,                 val_F1 Score: [4;35m0.7387[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  634
Epoch [25/100], V_AUC: [4m0.7336[0m
Epoch [26/100], Loss: 29.7790
train_Accuracy: [91m0.9072[0m
train_Precision: [4;34m0.8924[0m,               train_Recall: [4;33m0.9313[0m,                 train_F1 Score: [4;35m0.9073[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3901
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9983],
        [0.9956],
        [0.9993],
        [0.0134],
        [0.9896],
        [0.0043],
        [0.0633],
        [0.0133],
        [0.8424],
        [0.8887],
        [0.0347],
        [0.0518]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [26/100], T_AUC: [4m0.9122[0m
Epoch [26/100], Loss: 20.1104
val_Accuracy: [92m0.7500[0m
val_Precision: [4;34m0.7456[0m,               val_Recall: [4;33m0.7550[0m,                 val_F1 Score: [4;35m0.7451[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  645
Epoch [26/100], V_AUC: [4m0.7479[0m
Epoch [27/100], Loss: 22.8569
train_Accuracy: [91m0.9335[0m
train_Precision: [4;34m0.9186[0m,               train_Recall: [4;33m0.9532[0m,                 train_F1 Score: [4;35m0.9330[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4014
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9758],
        [0.9970],
        [0.9999],
        [0.0029],
        [0.9942],
        [0.0035],
        [0.0401],
        [0.0153],
        [0.9731],
        [0.9460],
        [0.0240],
        [0.0381]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [27/100], T_AUC: [4m0.9379[0m
Epoch [27/100], Loss: 23.0725
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7749[0m,               val_Recall: [4;33m0.6950[0m,                 val_F1 Score: [4;35m0.7270[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [27/100], V_AUC: [4m0.7448[0m
Epoch [28/100], Loss: 17.3455
train_Accuracy: [91m0.9512[0m
train_Precision: [4;34m0.9341[0m,               train_Recall: [4;33m0.9706[0m,                 train_F1 Score: [4;35m0.9498[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4090
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9860],
        [0.9973],
        [1.0000],
        [0.0059],
        [0.9995],
        [0.0025],
        [0.0152],
        [0.0265],
        [0.9852],
        [0.8421],
        [0.0048],
        [0.0066]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [28/100], T_AUC: [4m0.9547[0m
Epoch [28/100], Loss: 24.8388
val_Accuracy: [92m0.7512[0m
val_Precision: [4;34m0.7845[0m,               val_Recall: [4;33m0.6901[0m,                 val_F1 Score: [4;35m0.7284[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  646
Epoch [28/100], V_AUC: [4m0.7496[0m
Epoch [29/100], Loss: 13.5373
train_Accuracy: [91m0.9660[0m
train_Precision: [4;34m0.9562[0m,               train_Recall: [4;33m0.9772[0m,                 train_F1 Score: [4;35m0.9650[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4154
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9976],
        [0.9989],
        [0.9996],
        [0.0019],
        [0.9982],
        [0.0068],
        [0.0057],
        [0.0482],
        [0.9898],
        [0.9917],
        [0.0052],
        [0.0032]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [29/100], T_AUC: [4m0.9691[0m
Epoch [29/100], Loss: 24.9898
val_Accuracy: [92m0.7581[0m
val_Precision: [4;34m0.7695[0m,               val_Recall: [4;33m0.7402[0m,                 val_F1 Score: [4;35m0.7495[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  652
Epoch [29/100], V_AUC: [4m0.7570[0m
Epoch [30/100], Loss: 11.0608
train_Accuracy: [91m0.9737[0m
train_Precision: [4;34m0.9616[0m,               train_Recall: [4;33m0.9867[0m,                 train_F1 Score: [4;35m0.9729[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4187
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9477e-01],
        [9.9975e-01],
        [9.9999e-01],
        [1.7781e-03],
        [9.9998e-01],
        [1.6981e-03],
        [5.1771e-03],
        [2.6361e-02],
        [9.7266e-01],
        [8.9884e-01],
        [1.5009e-04],
        [2.6096e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [30/100], T_AUC: [4m0.9757[0m
Epoch [30/100], Loss: 28.5401
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7941[0m,               val_Recall: [4;33m0.6741[0m,                 val_F1 Score: [4;35m0.7242[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [30/100], V_AUC: [4m0.7482[0m
Epoch [31/100], Loss: 9.4016
train_Accuracy: [91m0.9798[0m
train_Precision: [4;34m0.9700[0m,               train_Recall: [4;33m0.9893[0m,                 train_F1 Score: [4;35m0.9788[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4213
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9996e-01],
        [9.9980e-01],
        [9.8192e-01],
        [1.6637e-03],
        [9.9755e-01],
        [1.1865e-03],
        [7.1487e-03],
        [1.0128e-01],
        [9.9896e-01],
        [9.8286e-01],
        [3.4678e-04],
        [2.7124e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [31/100], T_AUC: [4m0.9813[0m
Epoch [31/100], Loss: 28.6305
val_Accuracy: [92m0.7465[0m
val_Precision: [4;34m0.7596[0m,               val_Recall: [4;33m0.7232[0m,                 val_F1 Score: [4;35m0.7360[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  642
Epoch [31/100], V_AUC: [4m0.7450[0m
Epoch [32/100], Loss: 8.5653
train_Accuracy: [91m0.9791[0m
train_Precision: [4;34m0.9699[0m,               train_Recall: [4;33m0.9882[0m,                 train_F1 Score: [4;35m0.9782[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4210
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9975e-01],
        [9.9998e-01],
        [9.9969e-01],
        [5.7070e-04],
        [9.9999e-01],
        [8.9099e-03],
        [7.8440e-04],
        [4.6634e-04],
        [9.9812e-01],
        [9.1456e-01],
        [3.1977e-05],
        [1.2509e-02]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [32/100], T_AUC: [4m0.9804[0m
Epoch [32/100], Loss: 31.6425
val_Accuracy: [92m0.7349[0m
val_Precision: [4;34m0.7538[0m,               val_Recall: [4;33m0.6928[0m,                 val_F1 Score: [4;35m0.7176[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  632
Epoch [32/100], V_AUC: [4m0.7304[0m
Epoch [33/100], Loss: 9.2581
train_Accuracy: [91m0.9770[0m
train_Precision: [4;34m0.9649[0m,               train_Recall: [4;33m0.9901[0m,                 train_F1 Score: [4;35m0.9764[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4201
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9906e-01],
        [1.0000e+00],
        [9.9985e-01],
        [2.2898e-04],
        [9.9999e-01],
        [2.8983e-04],
        [5.3225e-04],
        [3.0021e-04],
        [9.8051e-01],
        [9.9163e-01],
        [1.7199e-03],
        [5.4740e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [33/100], T_AUC: [4m0.9787[0m
Epoch [33/100], Loss: 36.2554
val_Accuracy: [92m0.7453[0m
val_Precision: [4;34m0.7833[0m,               val_Recall: [4;33m0.6644[0m,                 val_F1 Score: [4;35m0.7148[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  641
Epoch [33/100], V_AUC: [4m0.7411[0m
Epoch [34/100], Loss: 10.6707
train_Accuracy: [91m0.9707[0m
train_Precision: [4;34m0.9633[0m,               train_Recall: [4;33m0.9781[0m,                 train_F1 Score: [4;35m0.9694[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4174
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9973e-01],
        [1.0000e+00],
        [9.9999e-01],
        [2.4760e-04],
        [1.0000e+00],
        [3.4386e-04],
        [1.4779e-04],
        [1.0573e-02],
        [9.2833e-01],
        [3.1914e-01],
        [1.5239e-04],
        [1.5727e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [34/100], T_AUC: [4m0.9723[0m
Epoch [34/100], Loss: 32.3005
val_Accuracy: [92m0.7349[0m
val_Precision: [4;34m0.7543[0m,               val_Recall: [4;33m0.6910[0m,                 val_F1 Score: [4;35m0.7164[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  632
Epoch [34/100], V_AUC: [4m0.7314[0m
Epoch [35/100], Loss: 17.3168
train_Accuracy: [91m0.9484[0m
train_Precision: [4;34m0.9366[0m,               train_Recall: [4;33m0.9628[0m,                 train_F1 Score: [4;35m0.9473[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4078
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9993e-01],
        [9.9997e-01],
        [9.9937e-01],
        [8.9763e-06],
        [9.9944e-01],
        [1.5794e-03],
        [2.7654e-01],
        [1.5042e-01],
        [9.9126e-01],
        [9.9604e-01],
        [1.3907e-05],
        [1.1953e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [35/100], T_AUC: [4m0.9519[0m
Epoch [35/100], Loss: 45.1383
val_Accuracy: [92m0.7395[0m
val_Precision: [4;34m0.7882[0m,               val_Recall: [4;33m0.6451[0m,                 val_F1 Score: [4;35m0.7038[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  636
Epoch [35/100], V_AUC: [4m0.7361[0m
Epoch [36/100], Loss: 11.7831
train_Accuracy: [91m0.9665[0m
train_Precision: [4;34m0.9560[0m,               train_Recall: [4;33m0.9789[0m,                 train_F1 Score: [4;35m0.9660[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4156
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9996e-01],
        [9.9939e-01],
        [9.9396e-01],
        [2.5596e-04],
        [1.0000e+00],
        [8.5061e-04],
        [8.2655e-05],
        [5.1331e-04],
        [9.9851e-01],
        [9.9990e-01],
        [1.3815e-04],
        [5.2908e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [36/100], T_AUC: [4m0.9686[0m
Epoch [36/100], Loss: 36.2388
val_Accuracy: [92m0.7419[0m
val_Precision: [4;34m0.7773[0m,               val_Recall: [4;33m0.6712[0m,                 val_F1 Score: [4;35m0.7163[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  638
Epoch [36/100], V_AUC: [4m0.7388[0m
Epoch [37/100], Loss: 10.8532
train_Accuracy: [91m0.9728[0m
train_Precision: [4;34m0.9664[0m,               train_Recall: [4;33m0.9803[0m,                 train_F1 Score: [4;35m0.9723[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4183
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9997e-01],
        [9.9937e-01],
        [9.9970e-01],
        [2.1007e-03],
        [1.0000e+00],
        [4.1864e-04],
        [2.4362e-05],
        [1.6608e-03],
        [9.9544e-01],
        [9.9227e-01],
        [1.6182e-04],
        [5.1634e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [37/100], T_AUC: [4m0.9742[0m
Epoch [37/100], Loss: 40.0888
val_Accuracy: [92m0.7267[0m
val_Precision: [4;34m0.7977[0m,               val_Recall: [4;33m0.6072[0m,                 val_F1 Score: [4;35m0.6820[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  625
Epoch [37/100], V_AUC: [4m0.7239[0m
Epoch [38/100], Loss: 9.2693
train_Accuracy: [91m0.9753[0m
train_Precision: [4;34m0.9659[0m,               train_Recall: [4;33m0.9842[0m,                 train_F1 Score: [4;35m0.9741[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4194
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9999e-01],
        [9.8767e-01],
        [9.8805e-01],
        [1.3312e-03],
        [9.9999e-01],
        [8.2861e-04],
        [3.2267e-03],
        [7.0607e-04],
        [9.9966e-01],
        [9.9961e-01],
        [2.3971e-07],
        [4.1297e-01]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [38/100], T_AUC: [4m0.9765[0m
Epoch [38/100], Loss: 38.6480
val_Accuracy: [92m0.7279[0m
val_Precision: [4;34m0.7491[0m,               val_Recall: [4;33m0.6868[0m,                 val_F1 Score: [4;35m0.7120[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  626
Epoch [38/100], V_AUC: [4m0.7260[0m
Epoch [39/100], Loss: 4.8210
train_Accuracy: [91m0.9907[0m
train_Precision: [4;34m0.9863[0m,               train_Recall: [4;33m0.9941[0m,                 train_F1 Score: [4;35m0.9898[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4260
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9959e-01],
        [9.9977e-01],
        [9.9994e-01],
        [3.3625e-04],
        [1.0000e+00],
        [1.2412e-03],
        [3.8964e-04],
        [3.7611e-02],
        [9.9995e-01],
        [9.9749e-01],
        [1.5074e-06],
        [2.8100e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [39/100], T_AUC: [4m0.9914[0m
Epoch [39/100], Loss: 42.0506
val_Accuracy: [92m0.7279[0m
val_Precision: [4;34m0.7625[0m,               val_Recall: [4;33m0.6582[0m,                 val_F1 Score: [4;35m0.7026[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  626
Epoch [39/100], V_AUC: [4m0.7258[0m
Epoch [40/100], Loss: 3.1021
train_Accuracy: [91m0.9960[0m
train_Precision: [4;34m0.9932[0m,               train_Recall: [4;33m0.9981[0m,                 train_F1 Score: [4;35m0.9955[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4283
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9932e-01],
        [9.9976e-01],
        [1.0000e+00],
        [5.1468e-05],
        [1.0000e+00],
        [7.7336e-04],
        [4.9428e-04],
        [1.7316e-03],
        [9.9799e-01],
        [9.9925e-01],
        [7.5972e-06],
        [9.8809e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [40/100], T_AUC: [4m0.9964[0m
Epoch [40/100], Loss: 48.1598
val_Accuracy: [92m0.7419[0m
val_Precision: [4;34m0.7440[0m,               val_Recall: [4;33m0.7396[0m,                 val_F1 Score: [4;35m0.7381[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  638
Epoch [40/100], V_AUC: [4m0.7391[0m
Epoch [41/100], Loss: 1.7622
train_Accuracy: [91m0.9988[0m
train_Precision: [4;34m0.9987[0m,               train_Recall: [4;33m0.9991[0m,                 train_F1 Score: [4;35m0.9989[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4295
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9986e-01],
        [9.9998e-01],
        [9.9999e-01],
        [3.7978e-05],
        [1.0000e+00],
        [7.4128e-04],
        [3.3946e-04],
        [4.0239e-03],
        [9.9994e-01],
        [9.9987e-01],
        [6.1063e-07],
        [4.4932e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [41/100], T_AUC: [4m0.9988[0m
Epoch [41/100], Loss: 56.8802
val_Accuracy: [92m0.7453[0m
val_Precision: [4;34m0.7322[0m,               val_Recall: [4;33m0.7773[0m,                 val_F1 Score: [4;35m0.7496[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  641
Epoch [41/100], V_AUC: [4m0.7427[0m
Epoch [42/100], Loss: 1.0381
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9998e-01],
        [9.9998e-01],
        [1.0000e+00],
        [2.1032e-05],
        [1.0000e+00],
        [8.8740e-04],
        [5.2457e-04],
        [4.2279e-04],
        [9.9995e-01],
        [9.9993e-01],
        [5.9702e-07],
        [3.1937e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [42/100], T_AUC: [4m1.0000[0m
Epoch [42/100], Loss: 56.6066
val_Accuracy: [92m0.7581[0m
val_Precision: [4;34m0.7533[0m,               val_Recall: [4;33m0.7653[0m,                 val_F1 Score: [4;35m0.7551[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  652
Epoch [42/100], V_AUC: [4m0.7549[0m
Epoch [43/100], Loss: 0.9129
train_Accuracy: [91m0.9993[0m
train_Precision: [4;34m0.9990[0m,               train_Recall: [4;33m0.9995[0m,                 train_F1 Score: [4;35m0.9992[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4297
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9975e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.8257e-05],
        [1.0000e+00],
        [7.9861e-04],
        [1.5296e-03],
        [3.9376e-04],
        [9.9961e-01],
        [9.9986e-01],
        [3.2323e-07],
        [1.0266e-06]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [43/100], T_AUC: [4m0.9993[0m
Epoch [43/100], Loss: 58.8495
val_Accuracy: [92m0.7453[0m
val_Precision: [4;34m0.7367[0m,               val_Recall: [4;33m0.7686[0m,                 val_F1 Score: [4;35m0.7481[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  641
Epoch [43/100], V_AUC: [4m0.7434[0m
Epoch [44/100], Loss: 0.7382
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9999e-01],
        [1.0000e+00],
        [9.9995e-01],
        [1.4059e-05],
        [1.0000e+00],
        [1.2923e-03],
        [3.2623e-04],
        [3.3200e-04],
        [9.9974e-01],
        [9.9997e-01],
        [1.1138e-07],
        [2.8118e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [44/100], T_AUC: [4m1.0000[0m
Epoch [44/100], Loss: 55.7655
val_Accuracy: [92m0.7616[0m
val_Precision: [4;34m0.7659[0m,               val_Recall: [4;33m0.7578[0m,                 val_F1 Score: [4;35m0.7572[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  655
Epoch [44/100], V_AUC: [4m0.7586[0m
Epoch [45/100], Loss: 0.3987
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9994e-01],
        [8.5913e-06],
        [1.0000e+00],
        [7.6882e-04],
        [2.5175e-04],
        [3.5749e-04],
        [9.9996e-01],
        [9.9996e-01],
        [5.6676e-08],
        [2.4584e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [45/100], T_AUC: [4m1.0000[0m
Epoch [45/100], Loss: 55.8575
val_Accuracy: [92m0.7628[0m
val_Precision: [4;34m0.7664[0m,               val_Recall: [4;33m0.7596[0m,                 val_F1 Score: [4;35m0.7582[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  656
Epoch [45/100], V_AUC: [4m0.7597[0m
Epoch [46/100], Loss: 0.2916
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9990e-01],
        [5.9679e-06],
        [1.0000e+00],
        [5.2314e-04],
        [2.6586e-04],
        [2.8394e-04],
        [9.9998e-01],
        [9.9995e-01],
        [4.9321e-08],
        [2.0553e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [46/100], T_AUC: [4m1.0000[0m
Epoch [46/100], Loss: 56.2772
val_Accuracy: [92m0.7570[0m
val_Precision: [4;34m0.7612[0m,               val_Recall: [4;33m0.7532[0m,                 val_F1 Score: [4;35m0.7523[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  651
Epoch [46/100], V_AUC: [4m0.7543[0m
Epoch [47/100], Loss: 0.2353
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9988e-01],
        [4.9846e-06],
        [1.0000e+00],
        [3.7245e-04],
        [2.4785e-04],
        [2.6877e-04],
        [9.9998e-01],
        [9.9996e-01],
        [3.7079e-08],
        [1.6370e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [47/100], T_AUC: [4m1.0000[0m
Epoch [47/100], Loss: 56.6810
val_Accuracy: [92m0.7593[0m
val_Precision: [4;34m0.7624[0m,               val_Recall: [4;33m0.7575[0m,                 val_F1 Score: [4;35m0.7553[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  653
Epoch [47/100], V_AUC: [4m0.7567[0m
Epoch [48/100], Loss: 0.1982
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9987e-01],
        [4.0959e-06],
        [1.0000e+00],
        [3.0112e-04],
        [2.1645e-04],
        [2.2576e-04],
        [9.9999e-01],
        [9.9996e-01],
        [2.9808e-08],
        [1.4480e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [48/100], T_AUC: [4m1.0000[0m
Epoch [48/100], Loss: 57.1522
val_Accuracy: [92m0.7547[0m
val_Precision: [4;34m0.7523[0m,               val_Recall: [4;33m0.7590[0m,                 val_F1 Score: [4;35m0.7514[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  649
Epoch [48/100], V_AUC: [4m0.7514[0m
Epoch [49/100], Loss: 0.1719
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9985e-01],
        [3.5168e-06],
        [1.0000e+00],
        [2.4217e-04],
        [1.9944e-04],
        [1.8948e-04],
        [9.9999e-01],
        [9.9997e-01],
        [2.4624e-08],
        [1.3467e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [49/100], T_AUC: [4m1.0000[0m
Epoch [49/100], Loss: 57.5818
val_Accuracy: [92m0.7558[0m
val_Precision: [4;34m0.7528[0m,               val_Recall: [4;33m0.7610[0m,                 val_F1 Score: [4;35m0.7527[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  650
Epoch [49/100], V_AUC: [4m0.7524[0m
Epoch [50/100], Loss: 0.1502
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9988e-01],
        [3.0423e-06],
        [1.0000e+00],
        [1.9935e-04],
        [1.7853e-04],
        [1.6295e-04],
        [9.9999e-01],
        [9.9997e-01],
        [2.1826e-08],
        [1.1386e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [50/100], T_AUC: [4m1.0000[0m
Epoch [50/100], Loss: 58.0008
val_Accuracy: [92m0.7535[0m
val_Precision: [4;34m0.7493[0m,               val_Recall: [4;33m0.7610[0m,                 val_F1 Score: [4;35m0.7512[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  648
Epoch [50/100], V_AUC: [4m0.7499[0m
Epoch [51/100], Loss: 0.1323
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9989e-01],
        [2.6584e-06],
        [1.0000e+00],
        [1.7034e-04],
        [1.7565e-04],
        [1.4370e-04],
        [9.9999e-01],
        [9.9997e-01],
        [1.8880e-08],
        [6.8975e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [51/100], T_AUC: [4m1.0000[0m
Epoch [51/100], Loss: 58.2407
val_Accuracy: [92m0.7547[0m
val_Precision: [4;34m0.7511[0m,               val_Recall: [4;33m0.7610[0m,                 val_F1 Score: [4;35m0.7520[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  649
Epoch [51/100], V_AUC: [4m0.7512[0m
Epoch [52/100], Loss: 0.1176
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9990e-01],
        [2.5141e-06],
        [1.0000e+00],
        [1.3871e-04],
        [1.3943e-04],
        [1.2720e-04],
        [9.9999e-01],
        [9.9997e-01],
        [1.6408e-08],
        [5.4106e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [52/100], T_AUC: [4m1.0000[0m
Epoch [52/100], Loss: 58.5034
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7512[0m,               val_Recall: [4;33m0.7546[0m,                 val_F1 Score: [4;35m0.7485[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [52/100], V_AUC: [4m0.7492[0m
Epoch [53/100], Loss: 0.1045
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9990e-01],
        [2.4456e-06],
        [1.0000e+00],
        [1.1611e-04],
        [1.0987e-04],
        [1.3282e-04],
        [9.9999e-01],
        [9.9997e-01],
        [1.3396e-08],
        [3.9022e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [53/100], T_AUC: [4m1.0000[0m
Epoch [53/100], Loss: 59.0774
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7486[0m,               val_Recall: [4;33m0.7618[0m,                 val_F1 Score: [4;35m0.7505[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [53/100], V_AUC: [4m0.7492[0m
Epoch [54/100], Loss: 0.0942
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9991e-01],
        [2.2701e-06],
        [1.0000e+00],
        [8.9316e-05],
        [9.9397e-05],
        [1.0959e-04],
        [9.9999e-01],
        [9.9998e-01],
        [1.3612e-08],
        [2.5954e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [54/100], T_AUC: [4m1.0000[0m
Epoch [54/100], Loss: 59.5210
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7495[0m,               val_Recall: [4;33m0.7590[0m,                 val_F1 Score: [4;35m0.7496[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [54/100], V_AUC: [4m0.7488[0m
Epoch [55/100], Loss: 0.0852
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9991e-01],
        [2.1527e-06],
        [1.0000e+00],
        [7.7038e-05],
        [9.3032e-05],
        [9.6258e-05],
        [1.0000e+00],
        [9.9998e-01],
        [1.2635e-08],
        [2.1640e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [55/100], T_AUC: [4m1.0000[0m
Epoch [55/100], Loss: 65.4468
val_Accuracy: [92m0.7547[0m
val_Precision: [4;34m0.7510[0m,               val_Recall: [4;33m0.7640[0m,                 val_F1 Score: [4;35m0.7529[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  649
Epoch [55/100], V_AUC: [4m0.7513[0m
Epoch [56/100], Loss: 0.0771
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9993e-01],
        [1.9607e-06],
        [1.0000e+00],
        [6.4535e-05],
        [8.2663e-05],
        [1.0170e-04],
        [9.9999e-01],
        [9.9998e-01],
        [1.0332e-08],
        [1.9342e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [56/100], T_AUC: [4m1.0000[0m
Epoch [56/100], Loss: 63.0433
val_Accuracy: [92m0.7547[0m
val_Precision: [4;34m0.7515[0m,               val_Recall: [4;33m0.7611[0m,                 val_F1 Score: [4;35m0.7518[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  649
Epoch [56/100], V_AUC: [4m0.7512[0m
Epoch [57/100], Loss: 0.0704
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9993e-01],
        [1.7982e-06],
        [1.0000e+00],
        [4.4622e-05],
        [7.8056e-05],
        [8.4439e-05],
        [1.0000e+00],
        [9.9998e-01],
        [9.6666e-09],
        [1.7503e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [57/100], T_AUC: [4m1.0000[0m
Epoch [57/100], Loss: 63.8303
val_Accuracy: [92m0.7547[0m
val_Precision: [4;34m0.7521[0m,               val_Recall: [4;33m0.7618[0m,                 val_F1 Score: [4;35m0.7523[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  649
Epoch [57/100], V_AUC: [4m0.7516[0m
Epoch [58/100], Loss: 0.0640
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9994e-01],
        [1.7488e-06],
        [1.0000e+00],
        [3.0758e-05],
        [7.6079e-05],
        [8.0865e-05],
        [9.9999e-01],
        [9.9998e-01],
        [9.2858e-09],
        [1.8028e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [58/100], T_AUC: [4m1.0000[0m
Epoch [58/100], Loss: 67.0338
val_Accuracy: [92m0.7535[0m
val_Precision: [4;34m0.7502[0m,               val_Recall: [4;33m0.7618[0m,                 val_F1 Score: [4;35m0.7513[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  648
Epoch [58/100], V_AUC: [4m0.7502[0m
Epoch [59/100], Loss: 0.0582
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9995e-01],
        [1.7001e-06],
        [1.0000e+00],
        [2.9781e-05],
        [7.8473e-05],
        [7.3542e-05],
        [9.9999e-01],
        [9.9998e-01],
        [6.3316e-09],
        [1.4796e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [59/100], T_AUC: [4m1.0000[0m
Epoch [59/100], Loss: 67.2725
val_Accuracy: [92m0.7570[0m
val_Precision: [4;34m0.7536[0m,               val_Recall: [4;33m0.7639[0m,                 val_F1 Score: [4;35m0.7541[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  651
Epoch [59/100], V_AUC: [4m0.7537[0m
Epoch [60/100], Loss: 0.0534
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9996e-01],
        [1.4130e-06],
        [1.0000e+00],
        [2.4822e-05],
        [7.7551e-05],
        [6.4772e-05],
        [9.9999e-01],
        [9.9998e-01],
        [6.6333e-09],
        [1.1995e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [60/100], T_AUC: [4m1.0000[0m
Epoch [60/100], Loss: 72.4715
val_Accuracy: [92m0.7558[0m
val_Precision: [4;34m0.7511[0m,               val_Recall: [4;33m0.7661[0m,                 val_F1 Score: [4;35m0.7539[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  650
Epoch [60/100], V_AUC: [4m0.7522[0m
Epoch [61/100], Loss: 0.0484
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9997e-01],
        [1.3574e-06],
        [1.0000e+00],
        [2.0838e-05],
        [8.1294e-05],
        [4.5202e-05],
        [9.9999e-01],
        [9.9998e-01],
        [5.4178e-09],
        [1.1617e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [61/100], T_AUC: [4m1.0000[0m
Epoch [61/100], Loss: 73.0012
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7425[0m,               val_Recall: [4;33m0.7731[0m,                 val_F1 Score: [4;35m0.7531[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [61/100], V_AUC: [4m0.7491[0m
Epoch [62/100], Loss: 0.0453
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9998e-01],
        [1.2512e-06],
        [1.0000e+00],
        [1.3234e-05],
        [7.6679e-05],
        [4.5136e-05],
        [1.0000e+00],
        [9.9998e-01],
        [5.7182e-09],
        [8.4295e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [62/100], T_AUC: [4m1.0000[0m
Epoch [62/100], Loss: 72.7376
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7458[0m,               val_Recall: [4;33m0.7686[0m,                 val_F1 Score: [4;35m0.7524[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [62/100], V_AUC: [4m0.7490[0m
Epoch [63/100], Loss: 0.0410
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9998e-01],
        [1.0252e-06],
        [1.0000e+00],
        [1.1237e-05],
        [7.0778e-05],
        [3.5766e-05],
        [1.0000e+00],
        [9.9998e-01],
        [4.6526e-09],
        [8.0129e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [63/100], T_AUC: [4m1.0000[0m
Epoch [63/100], Loss: 76.3198
val_Accuracy: [92m0.7500[0m
val_Precision: [4;34m0.7411[0m,               val_Recall: [4;33m0.7686[0m,                 val_F1 Score: [4;35m0.7502[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  645
Epoch [63/100], V_AUC: [4m0.7471[0m
Epoch [64/100], Loss: 0.0381
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9997e-01],
        [9.1181e-07],
        [1.0000e+00],
        [1.0171e-05],
        [8.2716e-05],
        [3.7514e-05],
        [1.0000e+00],
        [9.9997e-01],
        [4.2435e-09],
        [7.8490e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [64/100], T_AUC: [4m1.0000[0m
Epoch [64/100], Loss: 73.5089
val_Accuracy: [92m0.7488[0m
val_Precision: [4;34m0.7398[0m,               val_Recall: [4;33m0.7679[0m,                 val_F1 Score: [4;35m0.7492[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  644
Epoch [64/100], V_AUC: [4m0.7451[0m
Epoch [65/100], Loss: 0.0359
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [7.1397e-07],
        [1.0000e+00],
        [9.9234e-06],
        [5.5338e-05],
        [5.6161e-05],
        [1.0000e+00],
        [9.9998e-01],
        [2.5649e-09],
        [7.3892e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [65/100], T_AUC: [4m1.0000[0m
Epoch [65/100], Loss: 78.6530
val_Accuracy: [92m0.7512[0m
val_Precision: [4;34m0.7429[0m,               val_Recall: [4;33m0.7682[0m,                 val_F1 Score: [4;35m0.7512[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  646
Epoch [65/100], V_AUC: [4m0.7468[0m
Epoch [66/100], Loss: 0.0327
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [5.8954e-07],
        [1.0000e+00],
        [8.5519e-06],
        [6.5947e-05],
        [3.3415e-05],
        [1.0000e+00],
        [9.9998e-01],
        [2.6807e-09],
        [6.9667e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [66/100], T_AUC: [4m1.0000[0m
Epoch [66/100], Loss: 73.5084
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7445[0m,               val_Recall: [4;33m0.7681[0m,                 val_F1 Score: [4;35m0.7520[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [66/100], V_AUC: [4m0.7483[0m
Epoch [67/100], Loss: 0.0300
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [5.1541e-07],
        [1.0000e+00],
        [5.4231e-06],
        [4.7719e-05],
        [4.1425e-05],
        [1.0000e+00],
        [9.9998e-01],
        [3.0069e-09],
        [4.6156e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [67/100], T_AUC: [4m1.0000[0m
Epoch [67/100], Loss: 77.4203
val_Accuracy: [92m0.7488[0m
val_Precision: [4;34m0.7367[0m,               val_Recall: [4;33m0.7729[0m,                 val_F1 Score: [4;35m0.7498[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  644
Epoch [67/100], V_AUC: [4m0.7455[0m
Epoch [68/100], Loss: 0.0281
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [4.7441e-07],
        [1.0000e+00],
        [5.8861e-06],
        [3.2237e-05],
        [4.2841e-05],
        [1.0000e+00],
        [9.9998e-01],
        [2.9013e-09],
        [4.2205e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [68/100], T_AUC: [4m1.0000[0m
Epoch [68/100], Loss: 77.2241
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.7370[0m,               val_Recall: [4;33m0.7686[0m,                 val_F1 Score: [4;35m0.7483[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [68/100], V_AUC: [4m0.7432[0m
Epoch [69/100], Loss: 0.0261
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [5.5395e-07],
        [1.0000e+00],
        [4.9286e-06],
        [2.9788e-05],
        [4.4441e-05],
        [1.0000e+00],
        [9.9999e-01],
        [2.8972e-09],
        [3.6357e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [69/100], T_AUC: [4m1.0000[0m
Epoch [69/100], Loss: 80.3623
val_Accuracy: [92m0.7442[0m
val_Precision: [4;34m0.7291[0m,               val_Recall: [4;33m0.7728[0m,                 val_F1 Score: [4;35m0.7462[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  640
Epoch [69/100], V_AUC: [4m0.7401[0m
Epoch [70/100], Loss: 0.0327
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [5.4918e-07],
        [1.0000e+00],
        [1.1272e-05],
        [1.5069e-05],
        [8.5836e-05],
        [1.0000e+00],
        [9.9998e-01],
        [8.3116e-10],
        [7.2187e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [70/100], T_AUC: [4m1.0000[0m
Epoch [70/100], Loss: 75.1721
val_Accuracy: [92m0.7453[0m
val_Precision: [4;34m0.7390[0m,               val_Recall: [4;33m0.7573[0m,                 val_F1 Score: [4;35m0.7435[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  641
Epoch [70/100], V_AUC: [4m0.7422[0m
Epoch [71/100], Loss: 0.0274
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [4.3253e-07],
        [1.0000e+00],
        [8.1899e-06],
        [1.7133e-05],
        [4.5499e-05],
        [1.0000e+00],
        [9.9998e-01],
        [9.0402e-10],
        [2.1780e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [71/100], T_AUC: [4m1.0000[0m
Epoch [71/100], Loss: 81.1444
val_Accuracy: [92m0.7500[0m
val_Precision: [4;34m0.7415[0m,               val_Recall: [4;33m0.7659[0m,                 val_F1 Score: [4;35m0.7491[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  645
Epoch [71/100], V_AUC: [4m0.7458[0m
Epoch [72/100], Loss: 25.6220
train_Accuracy: [91m0.9658[0m
train_Precision: [4;34m0.9648[0m,               train_Recall: [4;33m0.9639[0m,                 train_F1 Score: [4;35m0.9631[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4153
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.4488e-01],
        [8.2605e-02],
        [7.5333e-06],
        [9.1051e-01],
        [8.9951e-02],
        [3.7808e-01],
        [9.9413e-02],
        [8.3843e-01],
        [1.0000e+00],
        [3.0067e-05],
        [1.4359e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [72/100], T_AUC: [4m0.9660[0m
Epoch [72/100], Loss: 261.9217
val_Accuracy: [92m0.6047[0m
val_Precision: [4;34m0.5630[0m,               val_Recall: [4;33m0.9402[0m,                 val_F1 Score: [4;35m0.7010[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  520
Epoch [72/100], V_AUC: [4m0.6041[0m
Epoch [73/100], Loss: 97.1310
train_Accuracy: [91m0.7340[0m
train_Precision: [4;34m0.7223[0m,               train_Recall: [4;33m0.7739[0m,                 train_F1 Score: [4;35m0.7399[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3156
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8695],
        [0.8139],
        [0.9905],
        [0.0733],
        [0.9606],
        [0.2437],
        [0.1312],
        [0.5072],
        [0.5168],
        [0.9569],
        [0.0705],
        [0.0633]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [73/100], T_AUC: [4m0.7398[0m
Epoch [73/100], Loss: 15.7581
val_Accuracy: [92m0.7419[0m
val_Precision: [4;34m0.7117[0m,               val_Recall: [4;33m0.8153[0m,                 val_F1 Score: [4;35m0.7547[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  638
Epoch [73/100], V_AUC: [4m0.7409[0m
Epoch [74/100], Loss: 62.6886
train_Accuracy: [91m0.7886[0m
train_Precision: [4;34m0.7795[0m,               train_Recall: [4;33m0.8171[0m,                 train_F1 Score: [4;35m0.7917[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3391
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8800],
        [0.6267],
        [0.9659],
        [0.0420],
        [0.8162],
        [0.1791],
        [0.1582],
        [0.5368],
        [0.5443],
        [0.9909],
        [0.0703],
        [0.1782]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [74/100], T_AUC: [4m0.7941[0m
Epoch [74/100], Loss: 15.3957
val_Accuracy: [92m0.7767[0m
val_Precision: [4;34m0.7893[0m,               val_Recall: [4;33m0.7493[0m,                 val_F1 Score: [4;35m0.7641[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  668
Epoch [74/100], V_AUC: [4m0.7750[0m
Epoch [75/100], Loss: 54.9882
train_Accuracy: [91m0.8186[0m
train_Precision: [4;34m0.8125[0m,               train_Recall: [4;33m0.8428[0m,                 train_F1 Score: [4;35m0.8208[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3520
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9366],
        [0.7803],
        [0.9943],
        [0.0449],
        [0.6702],
        [0.1183],
        [0.0921],
        [0.4204],
        [0.6569],
        [0.9831],
        [0.0780],
        [0.1877]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [75/100], T_AUC: [4m0.8243[0m
Epoch [75/100], Loss: 15.4910
val_Accuracy: [92m0.7651[0m
val_Precision: [4;34m0.7689[0m,               val_Recall: [4;33m0.7531[0m,                 val_F1 Score: [4;35m0.7568[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  658
Epoch [75/100], V_AUC: [4m0.7651[0m
Epoch [76/100], Loss: 51.6613
train_Accuracy: [91m0.8293[0m
train_Precision: [4;34m0.8190[0m,               train_Recall: [4;33m0.8569[0m,                 train_F1 Score: [4;35m0.8314[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3566
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9307],
        [0.8546],
        [0.6176],
        [0.0711],
        [0.7438],
        [0.5015],
        [0.3080],
        [0.3280],
        [0.8659],
        [0.9937],
        [0.0559],
        [0.0557]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [76/100], T_AUC: [4m0.8346[0m
Epoch [76/100], Loss: 17.7758
val_Accuracy: [92m0.6988[0m
val_Precision: [4;34m0.7209[0m,               val_Recall: [4;33m0.6611[0m,                 val_F1 Score: [4;35m0.6837[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  601
Epoch [76/100], V_AUC: [4m0.6974[0m
Epoch [77/100], Loss: 48.9728
train_Accuracy: [91m0.8365[0m
train_Precision: [4;34m0.8287[0m,               train_Recall: [4;33m0.8580[0m,                 train_F1 Score: [4;35m0.8376[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3597
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8898],
        [0.8933],
        [0.9915],
        [0.0620],
        [0.6808],
        [0.0720],
        [0.2451],
        [0.2208],
        [0.6995],
        [0.9980],
        [0.0394],
        [0.0822]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [77/100], T_AUC: [4m0.8417[0m
Epoch [77/100], Loss: 16.5276
val_Accuracy: [92m0.7419[0m
val_Precision: [4;34m0.7256[0m,               val_Recall: [4;33m0.7729[0m,                 val_F1 Score: [4;35m0.7431[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  638
Epoch [77/100], V_AUC: [4m0.7389[0m
Epoch [78/100], Loss: 42.4255
train_Accuracy: [91m0.8565[0m
train_Precision: [4;34m0.8454[0m,               train_Recall: [4;33m0.8823[0m,                 train_F1 Score: [4;35m0.8576[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3683
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9472],
        [0.9312],
        [0.9943],
        [0.0285],
        [0.9051],
        [0.0422],
        [0.3466],
        [0.1386],
        [0.7931],
        [0.9980],
        [0.0202],
        [0.0503]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [78/100], T_AUC: [4m0.8627[0m
Epoch [78/100], Loss: 17.2908
val_Accuracy: [92m0.7453[0m
val_Precision: [4;34m0.7326[0m,               val_Recall: [4;33m0.7691[0m,                 val_F1 Score: [4;35m0.7431[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  641
Epoch [78/100], V_AUC: [4m0.7425[0m
Epoch [79/100], Loss: 36.9518
train_Accuracy: [91m0.8819[0m
train_Precision: [4;34m0.8716[0m,               train_Recall: [4;33m0.9024[0m,                 train_F1 Score: [4;35m0.8820[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3792
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9267],
        [0.9479],
        [0.9976],
        [0.0510],
        [0.9331],
        [0.0405],
        [0.0702],
        [0.1338],
        [0.7976],
        [0.9995],
        [0.0142],
        [0.0434]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [79/100], T_AUC: [4m0.8873[0m
Epoch [79/100], Loss: 18.8247
val_Accuracy: [92m0.7384[0m
val_Precision: [4;34m0.7402[0m,               val_Recall: [4;33m0.7389[0m,                 val_F1 Score: [4;35m0.7323[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  635
Epoch [79/100], V_AUC: [4m0.7367[0m
Epoch [80/100], Loss: 33.1157
train_Accuracy: [91m0.8967[0m
train_Precision: [4;34m0.8873[0m,               train_Recall: [4;33m0.9135[0m,                 train_F1 Score: [4;35m0.8963[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3856
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9748],
        [0.9828],
        [0.9993],
        [0.0362],
        [0.9200],
        [0.0133],
        [0.0769],
        [0.1042],
        [0.9000],
        [0.9997],
        [0.0073],
        [0.0116]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [80/100], T_AUC: [4m0.9015[0m
Epoch [80/100], Loss: 21.0607
val_Accuracy: [92m0.7407[0m
val_Precision: [4;34m0.7485[0m,               val_Recall: [4;33m0.7185[0m,                 val_F1 Score: [4;35m0.7286[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  637
Epoch [80/100], V_AUC: [4m0.7388[0m
Epoch [81/100], Loss: 28.4426
train_Accuracy: [91m0.9121[0m
train_Precision: [4;34m0.9017[0m,               train_Recall: [4;33m0.9296[0m,                 train_F1 Score: [4;35m0.9113[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3922
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9775],
        [0.9888],
        [0.9995],
        [0.0163],
        [0.9558],
        [0.0094],
        [0.0449],
        [0.0577],
        [0.9432],
        [0.9998],
        [0.0082],
        [0.0124]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [81/100], T_AUC: [4m0.9170[0m
Epoch [81/100], Loss: 21.8946
val_Accuracy: [92m0.7442[0m
val_Precision: [4;34m0.7595[0m,               val_Recall: [4;33m0.7177[0m,                 val_F1 Score: [4;35m0.7315[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  640
Epoch [81/100], V_AUC: [4m0.7418[0m
Epoch [82/100], Loss: 22.8735
train_Accuracy: [91m0.9344[0m
train_Precision: [4;34m0.9204[0m,               train_Recall: [4;33m0.9522[0m,                 train_F1 Score: [4;35m0.9333[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4018
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9911],
        [0.9921],
        [0.9998],
        [0.0323],
        [0.9920],
        [0.0062],
        [0.0505],
        [0.0248],
        [0.8674],
        [0.9998],
        [0.0091],
        [0.0023]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [82/100], T_AUC: [4m0.9385[0m
Epoch [82/100], Loss: 24.6021
val_Accuracy: [92m0.7326[0m
val_Precision: [4;34m0.7200[0m,               val_Recall: [4;33m0.7592[0m,                 val_F1 Score: [4;35m0.7342[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  630
Epoch [82/100], V_AUC: [4m0.7295[0m
Epoch [83/100], Loss: 20.6643
train_Accuracy: [91m0.9449[0m
train_Precision: [4;34m0.9353[0m,               train_Recall: [4;33m0.9577[0m,                 train_F1 Score: [4;35m0.9442[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4063
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[8.9388e-01],
        [9.9738e-01],
        [9.9997e-01],
        [1.2246e-02],
        [9.9546e-01],
        [5.7095e-04],
        [7.1245e-02],
        [2.0930e-02],
        [9.1035e-01],
        [9.9997e-01],
        [5.8898e-03],
        [6.8233e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [83/100], T_AUC: [4m0.9480[0m
Epoch [83/100], Loss: 25.2218
val_Accuracy: [92m0.7360[0m
val_Precision: [4;34m0.7529[0m,               val_Recall: [4;33m0.7034[0m,                 val_F1 Score: [4;35m0.7210[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  633
Epoch [83/100], V_AUC: [4m0.7339[0m
Epoch [84/100], Loss: 15.9867
train_Accuracy: [91m0.9602[0m
train_Precision: [4;34m0.9533[0m,               train_Recall: [4;33m0.9682[0m,                 train_F1 Score: [4;35m0.9588[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4129
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9951e-01],
        [9.9642e-01],
        [9.9994e-01],
        [1.2034e-02],
        [9.9879e-01],
        [3.7697e-04],
        [5.0660e-02],
        [8.7556e-03],
        [9.0662e-01],
        [9.9984e-01],
        [6.1743e-03],
        [9.1181e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [84/100], T_AUC: [4m0.9627[0m
Epoch [84/100], Loss: 26.4706
val_Accuracy: [92m0.7465[0m
val_Precision: [4;34m0.7584[0m,               val_Recall: [4;33m0.7164[0m,                 val_F1 Score: [4;35m0.7317[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  642
Epoch [84/100], V_AUC: [4m0.7420[0m
Epoch [85/100], Loss: 12.0325
train_Accuracy: [91m0.9756[0m
train_Precision: [4;34m0.9725[0m,               train_Recall: [4;33m0.9792[0m,                 train_F1 Score: [4;35m0.9749[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4195
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9665e-01],
        [9.9942e-01],
        [9.9992e-01],
        [6.5861e-03],
        [9.9929e-01],
        [6.2791e-04],
        [1.0533e-01],
        [7.7642e-03],
        [9.8640e-01],
        [9.9996e-01],
        [6.0958e-04],
        [4.8666e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [85/100], T_AUC: [4m0.9771[0m
Epoch [85/100], Loss: 29.2108
val_Accuracy: [92m0.7221[0m
val_Precision: [4;34m0.7420[0m,               val_Recall: [4;33m0.6750[0m,                 val_F1 Score: [4;35m0.7011[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  621
Epoch [85/100], V_AUC: [4m0.7181[0m
Epoch [86/100], Loss: 9.8957
train_Accuracy: [91m0.9802[0m
train_Precision: [4;34m0.9742[0m,               train_Recall: [4;33m0.9866[0m,                 train_F1 Score: [4;35m0.9796[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4215
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9650e-01],
        [9.9899e-01],
        [1.0000e+00],
        [1.9637e-03],
        [9.9940e-01],
        [1.0604e-03],
        [7.7757e-02],
        [7.6862e-03],
        [8.9727e-01],
        [9.9996e-01],
        [5.4439e-04],
        [1.7571e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [86/100], T_AUC: [4m0.9814[0m
Epoch [86/100], Loss: 29.5706
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7623[0m,               val_Recall: [4;33m0.7336[0m,                 val_F1 Score: [4;35m0.7431[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [86/100], V_AUC: [4m0.7490[0m
Epoch [87/100], Loss: 10.1723
train_Accuracy: [91m0.9770[0m
train_Precision: [4;34m0.9685[0m,               train_Recall: [4;33m0.9861[0m,                 train_F1 Score: [4;35m0.9765[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4201
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9395e-01],
        [9.9907e-01],
        [1.0000e+00],
        [1.4146e-03],
        [9.9921e-01],
        [6.0569e-05],
        [2.7415e-03],
        [1.4903e-02],
        [9.6390e-01],
        [9.9999e-01],
        [2.8440e-03],
        [4.9136e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [87/100], T_AUC: [4m0.9782[0m
Epoch [87/100], Loss: 30.7186
val_Accuracy: [92m0.7372[0m
val_Precision: [4;34m0.7332[0m,               val_Recall: [4;33m0.7387[0m,                 val_F1 Score: [4;35m0.7310[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  634
Epoch [87/100], V_AUC: [4m0.7327[0m
Epoch [88/100], Loss: 13.5865
train_Accuracy: [91m0.9630[0m
train_Precision: [4;34m0.9570[0m,               train_Recall: [4;33m0.9699[0m,                 train_F1 Score: [4;35m0.9619[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4141
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9962e-01],
        [9.9427e-01],
        [1.0000e+00],
        [1.1191e-03],
        [9.3275e-01],
        [9.2794e-03],
        [4.4810e-02],
        [3.3093e-03],
        [7.6767e-01],
        [1.0000e+00],
        [9.6221e-03],
        [1.5515e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [88/100], T_AUC: [4m0.9651[0m
Epoch [88/100], Loss: 36.1410
val_Accuracy: [92m0.7140[0m
val_Precision: [4;34m0.7533[0m,               val_Recall: [4;33m0.6393[0m,                 val_F1 Score: [4;35m0.6842[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  614
Epoch [88/100], V_AUC: [4m0.7132[0m
Epoch [89/100], Loss: 40.1893
train_Accuracy: [91m0.8884[0m
train_Precision: [4;34m0.8787[0m,               train_Recall: [4;33m0.9055[0m,                 train_F1 Score: [4;35m0.8879[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3820
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9747e-01],
        [9.9407e-01],
        [9.9858e-01],
        [6.0166e-04],
        [9.8477e-01],
        [7.1350e-02],
        [9.2086e-02],
        [1.3705e-01],
        [9.4488e-01],
        [9.9990e-01],
        [1.0433e-02],
        [1.2673e-02]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [89/100], T_AUC: [4m0.8925[0m
Epoch [89/100], Loss: 35.8855
val_Accuracy: [92m0.6988[0m
val_Precision: [4;34m0.6777[0m,               val_Recall: [4;33m0.7550[0m,                 val_F1 Score: [4;35m0.7070[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  601
Epoch [89/100], V_AUC: [4m0.6983[0m
Epoch [90/100], Loss: 16.1122
train_Accuracy: [91m0.9537[0m
train_Precision: [4;34m0.9431[0m,               train_Recall: [4;33m0.9674[0m,                 train_F1 Score: [4;35m0.9530[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4101
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9649e-01],
        [9.9546e-01],
        [1.0000e+00],
        [4.1698e-04],
        [9.9960e-01],
        [3.1380e-03],
        [5.5290e-03],
        [1.2813e-02],
        [9.9007e-01],
        [9.9999e-01],
        [2.9568e-04],
        [1.3538e-03]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [90/100], T_AUC: [4m0.9570[0m
Epoch [90/100], Loss: 30.7978
val_Accuracy: [92m0.7349[0m
val_Precision: [4;34m0.7326[0m,               val_Recall: [4;33m0.7314[0m,                 val_F1 Score: [4;35m0.7262[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  632
Epoch [90/100], V_AUC: [4m0.7323[0m
Epoch [91/100], Loss: 8.4999
train_Accuracy: [91m0.9858[0m
train_Precision: [4;34m0.9830[0m,               train_Recall: [4;33m0.9891[0m,                 train_F1 Score: [4;35m0.9854[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4239
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9155e-01],
        [9.6191e-01],
        [1.0000e+00],
        [1.0483e-03],
        [9.9985e-01],
        [1.7189e-03],
        [4.1526e-03],
        [6.3232e-03],
        [9.8375e-01],
        [1.0000e+00],
        [7.9527e-04],
        [6.2215e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [91/100], T_AUC: [4m0.9871[0m
Epoch [91/100], Loss: 32.7862
val_Accuracy: [92m0.7291[0m
val_Precision: [4;34m0.7288[0m,               val_Recall: [4;33m0.7266[0m,                 val_F1 Score: [4;35m0.7221[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  627
Epoch [91/100], V_AUC: [4m0.7271[0m
Epoch [92/100], Loss: 5.3240
train_Accuracy: [91m0.9940[0m
train_Precision: [4;34m0.9912[0m,               train_Recall: [4;33m0.9965[0m,                 train_F1 Score: [4;35m0.9936[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4274
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9942e-01],
        [9.9743e-01],
        [1.0000e+00],
        [3.6149e-04],
        [9.9725e-01],
        [1.8884e-03],
        [2.8090e-03],
        [4.3061e-03],
        [9.9783e-01],
        [1.0000e+00],
        [9.1037e-05],
        [3.4743e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [92/100], T_AUC: [4m0.9944[0m
Epoch [92/100], Loss: 35.8540
val_Accuracy: [92m0.7302[0m
val_Precision: [4;34m0.7326[0m,               val_Recall: [4;33m0.7191[0m,                 val_F1 Score: [4;35m0.7200[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  628
Epoch [92/100], V_AUC: [4m0.7287[0m
Epoch [93/100], Loss: 3.3033
train_Accuracy: [91m0.9972[0m
train_Precision: [4;34m0.9965[0m,               train_Recall: [4;33m0.9983[0m,                 train_F1 Score: [4;35m0.9973[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4288
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9953e-01],
        [9.9906e-01],
        [1.0000e+00],
        [8.4308e-05],
        [9.9717e-01],
        [3.1295e-03],
        [3.5766e-03],
        [1.0303e-03],
        [9.9891e-01],
        [1.0000e+00],
        [1.5137e-04],
        [1.7029e-04]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [93/100], T_AUC: [4m0.9973[0m
Epoch [93/100], Loss: 37.2194
val_Accuracy: [92m0.7233[0m
val_Precision: [4;34m0.7174[0m,               val_Recall: [4;33m0.7256[0m,                 val_F1 Score: [4;35m0.7178[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  622
Epoch [93/100], V_AUC: [4m0.7195[0m
Epoch [94/100], Loss: 2.2907
train_Accuracy: [91m0.9986[0m
train_Precision: [4;34m0.9986[0m,               train_Recall: [4;33m0.9987[0m,                 train_F1 Score: [4;35m0.9986[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4294
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9974e-01],
        [9.9958e-01],
        [1.0000e+00],
        [8.4262e-05],
        [9.9856e-01],
        [1.2008e-03],
        [3.8072e-03],
        [8.2739e-04],
        [9.9875e-01],
        [1.0000e+00],
        [7.4620e-05],
        [9.9611e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [94/100], T_AUC: [4m0.9987[0m
Epoch [94/100], Loss: 44.0867
val_Accuracy: [92m0.7326[0m
val_Precision: [4;34m0.7233[0m,               val_Recall: [4;33m0.7416[0m,                 val_F1 Score: [4;35m0.7285[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  630
Epoch [94/100], V_AUC: [4m0.7293[0m
Epoch [95/100], Loss: 1.5669
train_Accuracy: [91m0.9991[0m
train_Precision: [4;34m0.9995[0m,               train_Recall: [4;33m0.9987[0m,                 train_F1 Score: [4;35m0.9991[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4296
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9980e-01],
        [9.9964e-01],
        [1.0000e+00],
        [6.0342e-05],
        [9.9986e-01],
        [8.7669e-04],
        [3.1155e-03],
        [4.0087e-04],
        [9.9938e-01],
        [1.0000e+00],
        [2.2547e-05],
        [9.6529e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [95/100], T_AUC: [4m0.9991[0m
Epoch [95/100], Loss: 49.9462
val_Accuracy: [92m0.7302[0m
val_Precision: [4;34m0.7210[0m,               val_Recall: [4;33m0.7398[0m,                 val_F1 Score: [4;35m0.7267[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  628
Epoch [95/100], V_AUC: [4m0.7269[0m
Epoch [96/100], Loss: 1.1209
train_Accuracy: [91m0.9991[0m
train_Precision: [4;34m0.9995[0m,               train_Recall: [4;33m0.9987[0m,                 train_F1 Score: [4;35m0.9991[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4296
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9973e-01],
        [9.9961e-01],
        [1.0000e+00],
        [5.2092e-05],
        [9.9991e-01],
        [8.2872e-04],
        [2.8878e-03],
        [3.3845e-04],
        [9.9969e-01],
        [1.0000e+00],
        [1.0447e-05],
        [4.9729e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [96/100], T_AUC: [4m0.9991[0m
Epoch [96/100], Loss: 55.9400
val_Accuracy: [92m0.7244[0m
val_Precision: [4;34m0.7184[0m,               val_Recall: [4;33m0.7292[0m,                 val_F1 Score: [4;35m0.7195[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  623
Epoch [96/100], V_AUC: [4m0.7213[0m
Epoch [97/100], Loss: 0.8469
train_Accuracy: [91m0.9995[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m0.9990[0m,                 train_F1 Score: [4;35m0.9995[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4298
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9985e-01],
        [9.9970e-01],
        [1.0000e+00],
        [5.9472e-05],
        [9.9993e-01],
        [6.0628e-04],
        [2.6518e-03],
        [2.1419e-04],
        [9.9985e-01],
        [1.0000e+00],
        [4.6655e-06],
        [4.1638e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [97/100], T_AUC: [4m0.9995[0m
Epoch [97/100], Loss: 57.0177
val_Accuracy: [92m0.7291[0m
val_Precision: [4;34m0.7264[0m,               val_Recall: [4;33m0.7263[0m,                 val_F1 Score: [4;35m0.7220[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  627
Epoch [97/100], V_AUC: [4m0.7267[0m
Epoch [98/100], Loss: 0.7467
train_Accuracy: [91m0.9998[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m0.9995[0m,                 train_F1 Score: [4;35m0.9997[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4299
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9994e-01],
        [9.9960e-01],
        [1.0000e+00],
        [6.1123e-05],
        [9.9959e-01],
        [9.4038e-04],
        [2.7242e-03],
        [3.2505e-04],
        [9.9989e-01],
        [1.0000e+00],
        [5.3142e-06],
        [2.7001e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [98/100], T_AUC: [4m0.9998[0m
Epoch [98/100], Loss: 55.0403
val_Accuracy: [92m0.7314[0m
val_Precision: [4;34m0.7313[0m,               val_Recall: [4;33m0.7242[0m,                 val_F1 Score: [4;35m0.7236[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  629
Epoch [98/100], V_AUC: [4m0.7286[0m
Epoch [99/100], Loss: 0.6301
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9995e-01],
        [9.9966e-01],
        [1.0000e+00],
        [3.9901e-05],
        [9.9997e-01],
        [5.3540e-04],
        [1.6109e-03],
        [1.7565e-04],
        [9.9993e-01],
        [1.0000e+00],
        [2.6700e-06],
        [1.3392e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [99/100], T_AUC: [4m1.0000[0m
Epoch [99/100], Loss: 61.5484
val_Accuracy: [92m0.7233[0m
val_Precision: [4;34m0.7227[0m,               val_Recall: [4;33m0.7154[0m,                 val_F1 Score: [4;35m0.7149[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  622
Epoch [99/100], V_AUC: [4m0.7208[0m
Epoch [100/100], Loss: 0.4815
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m1.0000[0m,               train_Recall: [4;33m1.0000[0m,                 train_F1 Score: [4;35m1.0000[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  4300
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9997e-01],
        [9.9965e-01],
        [1.0000e+00],
        [3.6605e-05],
        [9.9998e-01],
        [2.4848e-04],
        [1.3396e-03],
        [1.5262e-04],
        [9.9996e-01],
        [1.0000e+00],
        [1.9237e-06],
        [1.0211e-05]], device='cuda:0', grad_fn=<SigmoidBackward0>)
Epoch [100/100], T_AUC: [4m1.0000[0m
Epoch [100/100], Loss: 62.2662
val_Accuracy: [92m0.7198[0m
val_Precision: [4;34m0.7182[0m,               val_Recall: [4;33m0.7151[0m,                 val_F1 Score: [4;35m0.7125[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  619
Epoch [100/100], V_AUC: [4m0.7170[0m
第0批第15个, 100
第1批第16个, 100
第1批第30个, 100
第3批第2个, 100
第3批第17个, 100
send email successfully
usage: GRU.py [-h] [-lr LR] [-weight_decay WEIGHT_DECAY]
              [-freeze_GRU FREEZE_GRU] [-threathhold THREATHHOLD]
              [-hidden_size2 HIDDEN_SIZE2] [-hidden_size3 HIDDEN_SIZE3]
              [-epoch EPOCH]
GRU.py: error: unrecognized arguments: ＞ 拟南芥训练log 2＞
2024-06-30-19:51:40
usage: GRU.py [-h] [-lr LR] [-weight_decay WEIGHT_DECAY]
              [-freeze_GRU FREEZE_GRU] [-threathhold THREATHHOLD]
              [-hidden_size2 HIDDEN_SIZE2] [-hidden_size3 HIDDEN_SIZE3]
              [-epoch EPOCH]
GRU.py: error: unrecognized arguments: ＞ 拟南芥训练log 2＞
2024-06-30-19:52:15
2024-06-30-19:53:07
0排序128-0.4
创建模型实例
模型实例创建完成
加载预训练参数
预训练参数加载完成
Epoch [1/100], Loss: 119.9343
train_Accuracy: [91m0.5583[0m
train_Precision: [4;34m0.5098[0m,               train_Recall: [4;33m0.8261[0m,                 train_F1 Score: [4;35m0.6254[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3037
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.4848],
        [0.5832],
        [0.5592],
        [0.4799],
        [0.5699],
        [0.5580],
        [0.4889],
        [0.5132],
        [0.5257],
        [0.5205],
        [0.5364],
        [0.5760],
        [0.5097],
        [0.6022],
        [0.6048],
        [0.5993],
        [0.5908],
        [0.5963],
        [0.5256],
        [0.5480],
        [0.5088],
        [0.5112],
        [0.4412],
        [0.4528],
        [0.5863],
        [0.6007],
        [0.4485],
        [0.6385],
        [0.5898],
        [0.5383],
        [0.5435],
        [0.5941]], grad_fn=<ToCopyBackward0>)
Epoch [1/100], T_AUC: [4m0.4473[0m
Epoch [1/100], Loss: 22.5738
val_Accuracy: [92m0.5765[0m
val_Precision: [4;34m0.7062[0m,               val_Recall: [4;33m1.2090[0m,                 val_F1 Score: [4;35m0.8873[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  599
Epoch [1/100], V_AUC: [4m0.6113[0m
Epoch [2/100], Loss: 116.7600
train_Accuracy: [91m0.5708[0m
train_Precision: [4;34m0.5107[0m,               train_Recall: [4;33m0.8886[0m,                 train_F1 Score: [4;35m0.6449[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3105
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.4721],
        [0.5722],
        [0.6031],
        [0.4595],
        [0.5408],
        [0.5924],
        [0.5561],
        [0.5587],
        [0.5792],
        [0.5484],
        [0.5558],
        [0.5712],
        [0.4921],
        [0.6577],
        [0.6525],
        [0.5548],
        [0.6699],
        [0.5671],
        [0.5117],
        [0.5547],
        [0.4776],
        [0.5335],
        [0.5028],
        [0.4726],
        [0.6446],
        [0.5715],
        [0.5488],
        [0.6314],
        [0.5581],
        [0.5541],
        [0.5357],
        [0.6080]], grad_fn=<ToCopyBackward0>)
Epoch [2/100], T_AUC: [4m0.4492[0m
Epoch [2/100], Loss: 22.4382
val_Accuracy: [92m0.5784[0m
val_Precision: [4;34m0.7061[0m,               val_Recall: [4;33m1.2222[0m,                 val_F1 Score: [4;35m0.8910[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  601
Epoch [2/100], V_AUC: [4m0.6111[0m
Epoch [3/100], Loss: 115.9537
train_Accuracy: [91m0.5699[0m
train_Precision: [4;34m0.5104[0m,               train_Recall: [4;33m0.8878[0m,                 train_F1 Score: [4;35m0.6444[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3100
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.4724],
        [0.5686],
        [0.5314],
        [0.4514],
        [0.5358],
        [0.5699],
        [0.6002],
        [0.5394],
        [0.5528],
        [0.6115],
        [0.5993],
        [0.5518],
        [0.5384],
        [0.6678],
        [0.6437],
        [0.5185],
        [0.6907],
        [0.5612],
        [0.5135],
        [0.5315],
        [0.5260],
        [0.5230],
        [0.5038],
        [0.4770],
        [0.6769],
        [0.5901],
        [0.5278],
        [0.6551],
        [0.5730],
        [0.5683],
        [0.5624],
        [0.5986]], grad_fn=<ToCopyBackward0>)
Epoch [3/100], T_AUC: [4m0.4485[0m
Epoch [3/100], Loss: 22.3764
val_Accuracy: [92m0.5784[0m
val_Precision: [4;34m0.7067[0m,               val_Recall: [4;33m1.2164[0m,                 val_F1 Score: [4;35m0.8898[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  601
Epoch [3/100], V_AUC: [4m0.6124[0m
Epoch [4/100], Loss: 115.4261
train_Accuracy: [91m0.5728[0m
train_Precision: [4;34m0.5119[0m,               train_Recall: [4;33m0.8880[0m,                 train_F1 Score: [4;35m0.6457[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3116
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5012],
        [0.5826],
        [0.6514],
        [0.4089],
        [0.6051],
        [0.5712],
        [0.5282],
        [0.5857],
        [0.6047],
        [0.5901],
        [0.6077],
        [0.4769],
        [0.4420],
        [0.6503],
        [0.6098],
        [0.4372],
        [0.6973],
        [0.5927],
        [0.4420],
        [0.5127],
        [0.5431],
        [0.4635],
        [0.5736],
        [0.4666],
        [0.7092],
        [0.5875],
        [0.5422],
        [0.6217],
        [0.6682],
        [0.5773],
        [0.6241],
        [0.5548]], grad_fn=<ToCopyBackward0>)
Epoch [4/100], T_AUC: [4m0.4517[0m
Epoch [4/100], Loss: 22.4146
val_Accuracy: [92m0.5756[0m
val_Precision: [4;34m0.7050[0m,               val_Recall: [4;33m1.2126[0m,                 val_F1 Score: [4;35m0.8874[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  598
Epoch [4/100], V_AUC: [4m0.6086[0m
Epoch [5/100], Loss: 115.5380
train_Accuracy: [91m0.5721[0m
train_Precision: [4;34m0.5118[0m,               train_Recall: [4;33m0.8871[0m,                 train_F1 Score: [4;35m0.6453[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3112
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5304],
        [0.5880],
        [0.5842],
        [0.5095],
        [0.6075],
        [0.6032],
        [0.5316],
        [0.4951],
        [0.5452],
        [0.5641],
        [0.5944],
        [0.4830],
        [0.5143],
        [0.6286],
        [0.5128],
        [0.4098],
        [0.6771],
        [0.5687],
        [0.5369],
        [0.5853],
        [0.5064],
        [0.5673],
        [0.5514],
        [0.4903],
        [0.6342],
        [0.6306],
        [0.5522],
        [0.6645],
        [0.6208],
        [0.5850],
        [0.5674],
        [0.5875]], grad_fn=<ToCopyBackward0>)
Epoch [5/100], T_AUC: [4m0.4513[0m
Epoch [5/100], Loss: 22.4067
val_Accuracy: [92m0.5794[0m
val_Precision: [4;34m0.7066[0m,               val_Recall: [4;33m1.2222[0m,                 val_F1 Score: [4;35m0.8914[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  602
Epoch [5/100], V_AUC: [4m0.6121[0m
Epoch [6/100], Loss: 112.9372
train_Accuracy: [91m0.5787[0m
train_Precision: [4;34m0.5180[0m,               train_Recall: [4;33m0.8650[0m,                 train_F1 Score: [4;35m0.6436[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3148
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.4016],
        [0.7617],
        [0.3676],
        [0.5356],
        [0.3886],
        [0.6314],
        [0.6846],
        [0.5592],
        [0.6776],
        [0.3178],
        [0.5543],
        [0.5093],
        [0.3877],
        [0.6602],
        [0.3012],
        [0.3295],
        [0.7508],
        [0.6743],
        [0.4451],
        [0.5375],
        [0.6642],
        [0.5440],
        [0.4858],
        [0.2410],
        [0.5254],
        [0.5590],
        [0.7491],
        [0.8843],
        [0.7286],
        [0.4657],
        [0.7539],
        [0.8509]], grad_fn=<ToCopyBackward0>)
Epoch [6/100], T_AUC: [4m0.4619[0m
Epoch [6/100], Loss: 30.1265
val_Accuracy: [92m0.4620[0m
val_Precision: [4;34m0.9111[0m,               val_Recall: [4;33m0.0881[0m,                 val_F1 Score: [4;35m0.1566[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  480
Epoch [6/100], V_AUC: [4m0.6499[0m
Epoch [7/100], Loss: 105.7454
train_Accuracy: [91m0.6296[0m
train_Precision: [4;34m0.5586[0m,               train_Recall: [4;33m0.7982[0m,                 train_F1 Score: [4;35m0.6522[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3425
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.3605],
        [0.9012],
        [0.4012],
        [0.5160],
        [0.2871],
        [0.6334],
        [0.8386],
        [0.4981],
        [0.8570],
        [0.2739],
        [0.4658],
        [0.3947],
        [0.2189],
        [0.6820],
        [0.4500],
        [0.2840],
        [0.8521],
        [0.7841],
        [0.4199],
        [0.5174],
        [0.4670],
        [0.3919],
        [0.4552],
        [0.2000],
        [0.7057],
        [0.4403],
        [0.7424],
        [0.9125],
        [0.6340],
        [0.4051],
        [0.8501],
        [0.8998]], grad_fn=<ToCopyBackward0>)
Epoch [7/100], T_AUC: [4m0.5277[0m
Epoch [7/100], Loss: 20.8209
val_Accuracy: [92m0.6564[0m
val_Precision: [4;34m0.8665[0m,               val_Recall: [4;33m0.8519[0m,                 val_F1 Score: [4;35m0.8530[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  682
Epoch [7/100], V_AUC: [4m0.7921[0m
Epoch [8/100], Loss: 102.3648
train_Accuracy: [91m0.6483[0m
train_Precision: [4;34m0.5739[0m,               train_Recall: [4;33m0.7856[0m,                 train_F1 Score: [4;35m0.6583[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3527
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.4731],
        [0.9628],
        [0.3944],
        [0.6618],
        [0.1994],
        [0.7945],
        [0.8282],
        [0.4794],
        [0.7970],
        [0.2473],
        [0.4539],
        [0.4659],
        [0.2170],
        [0.5336],
        [0.3484],
        [0.2578],
        [0.8390],
        [0.5487],
        [0.4455],
        [0.5092],
        [0.5608],
        [0.4061],
        [0.4902],
        [0.3085],
        [0.6734],
        [0.5031],
        [0.8242],
        [0.9225],
        [0.5738],
        [0.3678],
        [0.8966],
        [0.8469]], grad_fn=<ToCopyBackward0>)
Epoch [8/100], T_AUC: [4m0.5506[0m
Epoch [8/100], Loss: 22.5055
val_Accuracy: [92m0.6362[0m
val_Precision: [4;34m0.8989[0m,               val_Recall: [4;33m0.7098[0m,                 val_F1 Score: [4;35m0.7841[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  661
Epoch [8/100], V_AUC: [4m0.7921[0m
Epoch [9/100], Loss: 99.1961
train_Accuracy: [91m0.6590[0m
train_Precision: [4;34m0.5854[0m,               train_Recall: [4;33m0.7714[0m,                 train_F1 Score: [4;35m0.6607[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3585
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.4994],
        [0.9500],
        [0.3388],
        [0.7052],
        [0.2720],
        [0.7710],
        [0.7575],
        [0.4849],
        [0.8348],
        [0.1992],
        [0.4678],
        [0.4418],
        [0.2067],
        [0.5580],
        [0.4220],
        [0.4600],
        [0.8088],
        [0.5198],
        [0.4048],
        [0.5494],
        [0.5420],
        [0.4651],
        [0.3918],
        [0.2805],
        [0.6961],
        [0.5358],
        [0.7558],
        [0.9679],
        [0.6058],
        [0.3216],
        [0.8476],
        [0.9400]], grad_fn=<ToCopyBackward0>)
Epoch [9/100], T_AUC: [4m0.5644[0m
Epoch [9/100], Loss: 54.1557
val_Accuracy: [92m0.5784[0m
val_Precision: [4;34m0.7061[0m,               val_Recall: [4;33m1.2222[0m,                 val_F1 Score: [4;35m0.8910[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  601
Epoch [9/100], V_AUC: [4m0.6111[0m
Epoch [10/100], Loss: 95.7073
train_Accuracy: [91m0.6790[0m
train_Precision: [4;34m0.6045[0m,               train_Recall: [4;33m0.7625[0m,                 train_F1 Score: [4;35m0.6694[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3694
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7894],
        [0.9724],
        [0.3725],
        [0.6449],
        [0.1669],
        [0.9236],
        [0.5765],
        [0.5926],
        [0.7723],
        [0.2437],
        [0.4394],
        [0.3643],
        [0.1915],
        [0.5137],
        [0.4477],
        [0.2518],
        [0.9172],
        [0.5040],
        [0.3803],
        [0.4257],
        [0.3143],
        [0.3407],
        [0.3885],
        [0.2651],
        [0.9039],
        [0.8402],
        [0.7787],
        [0.9788],
        [0.4535],
        [0.3019],
        [0.9451],
        [0.7725]], grad_fn=<ToCopyBackward0>)
Epoch [10/100], T_AUC: [4m0.5862[0m
Epoch [10/100], Loss: 19.5610
val_Accuracy: [92m0.6352[0m
val_Precision: [4;34m0.7622[0m,               val_Recall: [4;33m1.1431[0m,                 val_F1 Score: [4;35m0.9112[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  660
Epoch [10/100], V_AUC: [4m0.7087[0m
Epoch [11/100], Loss: 92.2420
train_Accuracy: [91m0.6976[0m
train_Precision: [4;34m0.6241[0m,               train_Recall: [4;33m0.7532[0m,                 train_F1 Score: [4;35m0.6772[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3795
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7016],
        [0.9727],
        [0.3702],
        [0.7760],
        [0.1935],
        [0.9335],
        [0.7331],
        [0.4349],
        [0.8613],
        [0.2418],
        [0.4388],
        [0.4180],
        [0.2509],
        [0.5619],
        [0.4356],
        [0.2759],
        [0.9149],
        [0.4313],
        [0.3401],
        [0.4126],
        [0.3214],
        [0.3570],
        [0.3241],
        [0.2890],
        [0.9021],
        [0.8773],
        [0.8445],
        [0.9876],
        [0.4885],
        [0.2201],
        [0.8414],
        [0.7721]], grad_fn=<ToCopyBackward0>)
Epoch [11/100], T_AUC: [4m0.6087[0m
Epoch [11/100], Loss: 24.8392
val_Accuracy: [92m0.6092[0m
val_Precision: [4;34m0.7329[0m,               val_Recall: [4;33m1.1862[0m,                 val_F1 Score: [4;35m0.9024[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  633
Epoch [11/100], V_AUC: [4m0.6626[0m
Epoch [12/100], Loss: 89.0498
train_Accuracy: [91m0.7074[0m
train_Precision: [4;34m0.6338[0m,               train_Recall: [4;33m0.7540[0m,                 train_F1 Score: [4;35m0.6829[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3848
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6980],
        [0.9684],
        [0.3362],
        [0.7084],
        [0.2154],
        [0.9078],
        [0.7100],
        [0.4693],
        [0.9301],
        [0.2040],
        [0.4277],
        [0.4344],
        [0.1811],
        [0.6523],
        [0.5585],
        [0.2977],
        [0.9261],
        [0.5166],
        [0.2618],
        [0.4219],
        [0.4927],
        [0.3241],
        [0.2583],
        [0.2675],
        [0.8945],
        [0.8630],
        [0.8844],
        [0.9923],
        [0.4894],
        [0.1902],
        [0.8423],
        [0.8298]], grad_fn=<ToCopyBackward0>)
Epoch [12/100], T_AUC: [4m0.6201[0m
Epoch [12/100], Loss: 34.7915
val_Accuracy: [92m0.5833[0m
val_Precision: [4;34m0.7095[0m,               val_Recall: [4;33m1.2200[0m,                 val_F1 Score: [4;35m0.8932[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  606
Epoch [12/100], V_AUC: [4m0.6182[0m
Epoch [13/100], Loss: 87.5090
train_Accuracy: [91m0.7202[0m
train_Precision: [4;34m0.6457[0m,               train_Recall: [4;33m0.7548[0m,                 train_F1 Score: [4;35m0.6901[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3918
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7313],
        [0.9721],
        [0.4006],
        [0.6634],
        [0.1790],
        [0.9324],
        [0.5488],
        [0.4507],
        [0.9163],
        [0.2812],
        [0.4124],
        [0.4211],
        [0.2101],
        [0.7596],
        [0.4314],
        [0.2976],
        [0.9547],
        [0.3759],
        [0.2960],
        [0.4457],
        [0.3422],
        [0.2723],
        [0.3038],
        [0.2591],
        [0.9089],
        [0.9241],
        [0.9367],
        [0.9922],
        [0.4993],
        [0.1842],
        [0.8197],
        [0.8042]], grad_fn=<ToCopyBackward0>)
Epoch [13/100], T_AUC: [4m0.6339[0m
Epoch [13/100], Loss: 25.1115
val_Accuracy: [92m0.6227[0m
val_Precision: [4;34m0.7453[0m,               val_Recall: [4;33m1.1740[0m,                 val_F1 Score: [4;35m0.9084[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  647
Epoch [13/100], V_AUC: [4m0.6835[0m
Epoch [14/100], Loss: 85.9991
train_Accuracy: [91m0.7335[0m
train_Precision: [4;34m0.6572[0m,               train_Recall: [4;33m0.7583[0m,                 train_F1 Score: [4;35m0.6983[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3990
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6053],
        [0.9828],
        [0.4129],
        [0.6189],
        [0.2229],
        [0.9436],
        [0.5404],
        [0.4468],
        [0.9302],
        [0.2939],
        [0.3932],
        [0.3209],
        [0.1662],
        [0.7239],
        [0.4578],
        [0.3332],
        [0.9599],
        [0.4830],
        [0.2814],
        [0.4553],
        [0.3628],
        [0.3121],
        [0.2765],
        [0.2881],
        [0.9277],
        [0.9395],
        [0.8808],
        [0.9902],
        [0.5435],
        [0.1875],
        [0.7706],
        [0.8074]], grad_fn=<ToCopyBackward0>)
Epoch [14/100], T_AUC: [4m0.6472[0m
Epoch [14/100], Loss: 19.0190
val_Accuracy: [92m0.6795[0m
val_Precision: [4;34m0.8223[0m,               val_Recall: [4;33m1.0693[0m,                 val_F1 Score: [4;35m0.9250[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  706
Epoch [14/100], V_AUC: [4m0.7887[0m
Epoch [15/100], Loss: 83.9857
train_Accuracy: [91m0.7434[0m
train_Precision: [4;34m0.6660[0m,               train_Recall: [4;33m0.7596[0m,                 train_F1 Score: [4;35m0.7041[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4044
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5455],
        [0.9760],
        [0.3026],
        [0.5605],
        [0.1905],
        [0.9435],
        [0.6408],
        [0.4734],
        [0.9379],
        [0.2404],
        [0.3899],
        [0.3877],
        [0.3471],
        [0.7835],
        [0.3359],
        [0.2976],
        [0.9625],
        [0.3296],
        [0.2754],
        [0.4014],
        [0.4787],
        [0.3379],
        [0.3175],
        [0.2864],
        [0.8923],
        [0.9402],
        [0.9324],
        [0.9923],
        [0.5002],
        [0.1957],
        [0.8378],
        [0.8309]], grad_fn=<ToCopyBackward0>)
Epoch [15/100], T_AUC: [4m0.6567[0m
Epoch [15/100], Loss: 18.0002
val_Accuracy: [92m0.7190[0m
val_Precision: [4;34m0.8820[0m,               val_Recall: [4;33m1.0287[0m,                 val_F1 Score: [4;35m0.9464[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  747
Epoch [15/100], V_AUC: [4m0.8513[0m
Epoch [16/100], Loss: 81.4402
train_Accuracy: [91m0.7540[0m
train_Precision: [4;34m0.6734[0m,               train_Recall: [4;33m0.7679[0m,                 train_F1 Score: [4;35m0.7118[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4102
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5459],
        [0.9836],
        [0.3297],
        [0.5620],
        [0.1421],
        [0.9543],
        [0.7677],
        [0.4728],
        [0.9224],
        [0.2080],
        [0.4312],
        [0.2561],
        [0.1974],
        [0.6642],
        [0.3493],
        [0.2593],
        [0.9731],
        [0.2470],
        [0.2961],
        [0.4258],
        [0.3823],
        [0.3603],
        [0.3182],
        [0.3126],
        [0.9220],
        [0.9574],
        [0.9137],
        [0.9944],
        [0.4197],
        [0.1388],
        [0.9168],
        [0.9577]], grad_fn=<ToCopyBackward0>)
Epoch [16/100], T_AUC: [4m0.6667[0m
Epoch [16/100], Loss: 18.1388
val_Accuracy: [92m0.7103[0m
val_Precision: [4;34m0.8868[0m,               val_Recall: [4;33m0.9865[0m,                 val_F1 Score: [4;35m0.9300[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  738
Epoch [16/100], V_AUC: [4m0.8462[0m
Epoch [17/100], Loss: 78.9879
train_Accuracy: [91m0.7656[0m
train_Precision: [4;34m0.6847[0m,               train_Recall: [4;33m0.7705[0m,                 train_F1 Score: [4;35m0.7194[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4165
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5996],
        [0.9886],
        [0.2436],
        [0.6753],
        [0.1408],
        [0.9679],
        [0.8311],
        [0.5826],
        [0.8967],
        [0.3007],
        [0.3932],
        [0.2509],
        [0.2411],
        [0.3088],
        [0.3434],
        [0.2328],
        [0.9809],
        [0.2375],
        [0.3256],
        [0.4397],
        [0.3538],
        [0.3249],
        [0.2055],
        [0.3348],
        [0.9410],
        [0.9625],
        [0.8516],
        [0.9943],
        [0.3899],
        [0.1047],
        [0.9607],
        [0.9733]], grad_fn=<ToCopyBackward0>)
Epoch [17/100], T_AUC: [4m0.6784[0m
Epoch [17/100], Loss: 18.3678
val_Accuracy: [92m0.7093[0m
val_Precision: [4;34m0.8786[0m,               val_Recall: [4;33m1.0131[0m,                 val_F1 Score: [4;35m0.9362[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  737
Epoch [17/100], V_AUC: [4m0.8416[0m
Epoch [18/100], Loss: 76.2336
train_Accuracy: [91m0.7822[0m
train_Precision: [4;34m0.6953[0m,               train_Recall: [4;33m0.7839[0m,                 train_F1 Score: [4;35m0.7319[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4255
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6208],
        [0.9948],
        [0.1963],
        [0.7292],
        [0.1054],
        [0.9718],
        [0.8844],
        [0.6369],
        [0.9647],
        [0.2670],
        [0.3417],
        [0.1746],
        [0.1031],
        [0.5013],
        [0.3646],
        [0.2400],
        [0.9913],
        [0.2673],
        [0.3375],
        [0.4246],
        [0.3883],
        [0.2679],
        [0.1061],
        [0.2255],
        [0.9269],
        [0.9677],
        [0.8684],
        [0.9936],
        [0.4901],
        [0.0925],
        [0.9543],
        [0.9599]], grad_fn=<ToCopyBackward0>)
Epoch [18/100], T_AUC: [4m0.6932[0m
Epoch [18/100], Loss: 19.0658
val_Accuracy: [92m0.7132[0m
val_Precision: [4;34m0.9134[0m,               val_Recall: [4;33m0.9369[0m,                 val_F1 Score: [4;35m0.9201[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  741
Epoch [18/100], V_AUC: [4m0.8559[0m
Epoch [19/100], Loss: 73.1709
train_Accuracy: [91m0.7869[0m
train_Precision: [4;34m0.7014[0m,               train_Recall: [4;33m0.7833[0m,                 train_F1 Score: [4;35m0.7348[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4281
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6869],
        [0.9952],
        [0.5840],
        [0.4655],
        [0.1461],
        [0.9699],
        [0.8585],
        [0.6198],
        [0.9711],
        [0.1902],
        [0.3279],
        [0.1875],
        [0.1402],
        [0.5522],
        [0.3895],
        [0.1697],
        [0.9977],
        [0.3388],
        [0.3209],
        [0.3209],
        [0.2609],
        [0.2387],
        [0.0659],
        [0.2972],
        [0.9167],
        [0.9492],
        [0.9231],
        [0.9920],
        [0.3789],
        [0.1188],
        [0.9786],
        [0.9370]], grad_fn=<ToCopyBackward0>)
Epoch [19/100], T_AUC: [4m0.6978[0m
Epoch [19/100], Loss: 19.5998
val_Accuracy: [92m0.7180[0m
val_Precision: [4;34m0.9118[0m,               val_Recall: [4;33m0.9475[0m,                 val_F1 Score: [4;35m0.9256[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  746
Epoch [19/100], V_AUC: [4m0.8601[0m
Epoch [20/100], Loss: 68.5532
train_Accuracy: [91m0.8066[0m
train_Precision: [4;34m0.7158[0m,               train_Recall: [4;33m0.7951[0m,                 train_F1 Score: [4;35m0.7484[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4388
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7443],
        [0.9966],
        [0.1727],
        [0.5635],
        [0.1888],
        [0.9855],
        [0.8960],
        [0.6535],
        [0.9613],
        [0.0835],
        [0.3204],
        [0.1188],
        [0.1701],
        [0.7511],
        [0.4517],
        [0.1867],
        [0.9983],
        [0.2082],
        [0.4677],
        [0.3236],
        [0.3131],
        [0.3295],
        [0.0453],
        [0.2302],
        [0.9195],
        [0.9466],
        [0.8879],
        [0.9961],
        [0.3965],
        [0.0649],
        [0.9809],
        [0.9581]], grad_fn=<ToCopyBackward0>)
Epoch [20/100], T_AUC: [4m0.7169[0m
Epoch [20/100], Loss: 20.1514
val_Accuracy: [92m0.7180[0m
val_Precision: [4;34m0.8962[0m,               val_Recall: [4;33m0.9773[0m,                 val_F1 Score: [4;35m0.9317[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  746
Epoch [20/100], V_AUC: [4m0.8548[0m
Epoch [21/100], Loss: 65.9668
train_Accuracy: [91m0.8147[0m
train_Precision: [4;34m0.7236[0m,               train_Recall: [4;33m0.7981[0m,                 train_F1 Score: [4;35m0.7541[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4432
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.4322],
        [0.9997],
        [0.2038],
        [0.7943],
        [0.2829],
        [0.9649],
        [0.6411],
        [0.3777],
        [0.9499],
        [0.1245],
        [0.3484],
        [0.0953],
        [0.1885],
        [0.7800],
        [0.7149],
        [0.3369],
        [0.9878],
        [0.2780],
        [0.1116],
        [0.2761],
        [0.3240],
        [0.0314],
        [0.1186],
        [0.2140],
        [0.9385],
        [0.9341],
        [0.9890],
        [0.9926],
        [0.5490],
        [0.0727],
        [0.9937],
        [0.9771]], grad_fn=<ToCopyBackward0>)
Epoch [21/100], T_AUC: [4m0.7255[0m
Epoch [21/100], Loss: 27.9606
val_Accuracy: [92m0.5890[0m
val_Precision: [4;34m0.8824[0m,               val_Recall: [4;33m0.5682[0m,                 val_F1 Score: [4;35m0.6843[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  612
Epoch [21/100], V_AUC: [4m0.7439[0m
Epoch [22/100], Loss: 68.6233
train_Accuracy: [91m0.8061[0m
train_Precision: [4;34m0.7169[0m,               train_Recall: [4;33m0.7936[0m,                 train_F1 Score: [4;35m0.7482[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4385
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6521],
        [0.9977],
        [0.1692],
        [0.9317],
        [0.0737],
        [0.9508],
        [0.9115],
        [0.6552],
        [0.8142],
        [0.1120],
        [0.4070],
        [0.0774],
        [0.2760],
        [0.7641],
        [0.6583],
        [0.2385],
        [0.9971],
        [0.4002],
        [0.2915],
        [0.5943],
        [0.3992],
        [0.0925],
        [0.2174],
        [0.3549],
        [0.9593],
        [0.9146],
        [0.3623],
        [0.9975],
        [0.0581],
        [0.0415],
        [0.9992],
        [0.9334]], grad_fn=<ToCopyBackward0>)
Epoch [22/100], T_AUC: [4m0.7174[0m
Epoch [22/100], Loss: 20.9867
val_Accuracy: [92m0.6814[0m
val_Precision: [4;34m0.8820[0m,               val_Recall: [4;33m0.8787[0m,                 val_F1 Score: [4;35m0.8768[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  708
Epoch [22/100], V_AUC: [4m0.8199[0m
Epoch [23/100], Loss: 57.4017
train_Accuracy: [91m0.8454[0m
train_Precision: [4;34m0.7482[0m,               train_Recall: [4;33m0.8172[0m,                 train_F1 Score: [4;35m0.7767[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4599
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8557],
        [0.9956],
        [0.1042],
        [0.7681],
        [0.0740],
        [0.9799],
        [0.9635],
        [0.9430],
        [0.7948],
        [0.0611],
        [0.3403],
        [0.0797],
        [0.2734],
        [0.8678],
        [0.6991],
        [0.3055],
        [0.9997],
        [0.2872],
        [0.1840],
        [0.5307],
        [0.1128],
        [0.0856],
        [0.1238],
        [0.3196],
        [0.9818],
        [0.9371],
        [0.7383],
        [0.9972],
        [0.0881],
        [0.0117],
        [0.9983],
        [0.9286]], grad_fn=<ToCopyBackward0>)
Epoch [23/100], T_AUC: [4m0.7543[0m
Epoch [23/100], Loss: 23.4187
val_Accuracy: [92m0.6651[0m
val_Precision: [4;34m0.8717[0m,               val_Recall: [4;33m0.8419[0m,                 val_F1 Score: [4;35m0.8514[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  691
Epoch [23/100], V_AUC: [4m0.8065[0m
Epoch [24/100], Loss: 50.8939
train_Accuracy: [91m0.8647[0m
train_Precision: [4;34m0.7654[0m,               train_Recall: [4;33m0.8263[0m,                 train_F1 Score: [4;35m0.7905[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4704
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9032],
        [0.9993],
        [0.1312],
        [0.8502],
        [0.0432],
        [0.9795],
        [0.9055],
        [0.9694],
        [0.8193],
        [0.0110],
        [0.1848],
        [0.0470],
        [0.1807],
        [0.9458],
        [0.8874],
        [0.2430],
        [0.9964],
        [0.3267],
        [0.1170],
        [0.3907],
        [0.1707],
        [0.1566],
        [0.1651],
        [0.4136],
        [0.9597],
        [0.9836],
        [0.9643],
        [0.9994],
        [0.1132],
        [0.0084],
        [0.9986],
        [0.8820]], grad_fn=<ToCopyBackward0>)
Epoch [24/100], T_AUC: [4m0.7733[0m
Epoch [24/100], Loss: 28.3436
val_Accuracy: [92m0.6323[0m
val_Precision: [4;34m0.8397[0m,               val_Recall: [4;33m0.8055[0m,                 val_F1 Score: [4;35m0.8137[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  657
Epoch [24/100], V_AUC: [4m0.7649[0m
Epoch [25/100], Loss: 45.9551
train_Accuracy: [91m0.8783[0m
train_Precision: [4;34m0.7754[0m,               train_Recall: [4;33m0.8347[0m,                 train_F1 Score: [4;35m0.8003[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4778
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8797],
        [0.9993],
        [0.1953],
        [0.1628],
        [0.0412],
        [0.9964],
        [0.9747],
        [0.9914],
        [0.8114],
        [0.0154],
        [0.3024],
        [0.2307],
        [0.0482],
        [0.7278],
        [0.3362],
        [0.0875],
        [0.9999],
        [0.7154],
        [0.0939],
        [0.3274],
        [0.0894],
        [0.0864],
        [0.0107],
        [0.4202],
        [0.9800],
        [0.9901],
        [0.9984],
        [1.0000],
        [0.1104],
        [0.0079],
        [0.9989],
        [0.6181]], grad_fn=<ToCopyBackward0>)
Epoch [25/100], T_AUC: [4m0.7840[0m
Epoch [25/100], Loss: 28.6242
val_Accuracy: [92m0.6708[0m
val_Precision: [4;34m0.8943[0m,               val_Recall: [4;33m0.8227[0m,                 val_F1 Score: [4;35m0.8497[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  697
Epoch [25/100], V_AUC: [4m0.8162[0m
Epoch [26/100], Loss: 41.8804
train_Accuracy: [91m0.8915[0m
train_Precision: [4;34m0.7875[0m,               train_Recall: [4;33m0.8400[0m,                 train_F1 Score: [4;35m0.8102[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4850
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.3974],
        [0.9992],
        [0.0517],
        [0.0702],
        [0.0468],
        [0.9882],
        [0.9942],
        [0.9802],
        [0.6823],
        [0.0455],
        [0.2450],
        [0.0104],
        [0.4790],
        [0.9441],
        [0.8873],
        [0.1055],
        [0.9998],
        [0.8175],
        [0.0886],
        [0.2278],
        [0.1241],
        [0.1400],
        [0.0305],
        [0.1631],
        [0.9923],
        [0.9980],
        [0.9967],
        [0.9999],
        [0.0740],
        [0.0072],
        [0.9998],
        [0.8931]], grad_fn=<ToCopyBackward0>)
Epoch [26/100], T_AUC: [4m0.7958[0m
Epoch [26/100], Loss: 28.1721
val_Accuracy: [92m0.6891[0m
val_Precision: [4;34m0.9322[0m,               val_Recall: [4;33m0.8243[0m,                 val_F1 Score: [4;35m0.8686[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  716
Epoch [26/100], V_AUC: [4m0.8446[0m
Epoch [27/100], Loss: 35.9254
train_Accuracy: [91m0.9123[0m
train_Precision: [4;34m0.8064[0m,               train_Recall: [4;33m0.8512[0m,                 train_F1 Score: [4;35m0.8252[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4963
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9820],
        [0.9999],
        [0.0595],
        [0.1281],
        [0.0312],
        [0.9921],
        [0.9975],
        [0.9536],
        [0.9014],
        [0.0042],
        [0.3079],
        [0.0119],
        [0.3577],
        [0.9066],
        [0.7929],
        [0.0407],
        [0.9998],
        [0.5734],
        [0.0855],
        [0.4000],
        [0.0446],
        [0.3385],
        [0.0213],
        [0.2572],
        [0.9877],
        [0.9888],
        [0.9994],
        [0.9999],
        [0.0290],
        [0.0040],
        [0.9994],
        [0.9772]], grad_fn=<ToCopyBackward0>)
Epoch [27/100], T_AUC: [4m0.8162[0m
Epoch [27/100], Loss: 34.2970
val_Accuracy: [92m0.6968[0m
val_Precision: [4;34m0.8567[0m,               val_Recall: [4;33m0.9989[0m,                 val_F1 Score: [4;35m0.9178[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  724
Epoch [27/100], V_AUC: [4m0.8217[0m
Epoch [28/100], Loss: 33.4872
train_Accuracy: [91m0.9186[0m
train_Precision: [4;34m0.8122[0m,               train_Recall: [4;33m0.8556[0m,                 train_F1 Score: [4;35m0.8309[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  4997
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9858],
        [0.9928],
        [0.1212],
        [0.1971],
        [0.0056],
        [0.9944],
        [0.9980],
        [0.8458],
        [0.4981],
        [0.0019],
        [0.1171],
        [0.0054],
        [0.1604],
        [0.9863],
        [0.8170],
        [0.0365],
        [0.9996],
        [0.0786],
        [0.3330],
        [0.8070],
        [0.0784],
        [0.0888],
        [0.5157],
        [0.0502],
        [0.9997],
        [0.9974],
        [0.9984],
        [1.0000],
        [0.2158],
        [0.0084],
        [1.0000],
        [0.8998]], grad_fn=<ToCopyBackward0>)
Epoch [28/100], T_AUC: [4m0.8213[0m
Epoch [28/100], Loss: 36.4697
val_Accuracy: [92m0.6853[0m
val_Precision: [4;34m0.8350[0m,               val_Recall: [4;33m1.0239[0m,                 val_F1 Score: [4;35m0.9155[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  712
Epoch [28/100], V_AUC: [4m0.8020[0m
Epoch [29/100], Loss: 21.7644
train_Accuracy: [91m0.9528[0m
train_Precision: [4;34m0.8457[0m,               train_Recall: [4;33m0.8710[0m,                 train_F1 Score: [4;35m0.8566[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5183
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9427e-01],
        [9.9909e-01],
        [1.5941e-02],
        [8.7205e-02],
        [8.6387e-04],
        [9.9636e-01],
        [9.9971e-01],
        [7.6782e-01],
        [9.3922e-01],
        [1.0619e-03],
        [5.5577e-02],
        [2.4259e-03],
        [6.5609e-02],
        [9.8992e-01],
        [8.9792e-01],
        [5.3266e-02],
        [9.9983e-01],
        [1.5146e-02],
        [1.4713e-03],
        [8.3406e-01],
        [5.7657e-02],
        [1.1359e-01],
        [9.7610e-01],
        [1.7389e-01],
        [9.9909e-01],
        [9.9884e-01],
        [9.9971e-01],
        [9.9999e-01],
        [2.2768e-01],
        [3.0292e-03],
        [1.0000e+00],
        [9.8635e-01]], grad_fn=<ToCopyBackward0>)
Epoch [29/100], T_AUC: [4m0.8537[0m
Epoch [29/100], Loss: 33.0960
val_Accuracy: [92m0.6997[0m
val_Precision: [4;34m0.8708[0m,               val_Recall: [4;33m0.9801[0m,                 val_F1 Score: [4;35m0.9195[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  727
Epoch [29/100], V_AUC: [4m0.8312[0m
Epoch [30/100], Loss: 16.2006
train_Accuracy: [91m0.9662[0m
train_Precision: [4;34m0.8616[0m,               train_Recall: [4;33m0.8756[0m,                 train_F1 Score: [4;35m0.8676[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5256
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9962e-01],
        [9.9978e-01],
        [2.5230e-01],
        [3.2441e-02],
        [9.2469e-04],
        [9.9493e-01],
        [9.9880e-01],
        [9.9859e-01],
        [9.2539e-01],
        [2.8891e-03],
        [2.1068e-02],
        [1.7184e-03],
        [6.0511e-02],
        [9.7360e-01],
        [9.3442e-01],
        [5.8884e-02],
        [9.9989e-01],
        [2.0270e-01],
        [2.7198e-04],
        [6.2736e-01],
        [1.0768e-02],
        [6.4329e-03],
        [4.3492e-02],
        [1.2884e-01],
        [9.9998e-01],
        [9.9967e-01],
        [9.9993e-01],
        [1.0000e+00],
        [6.1309e-02],
        [1.2326e-03],
        [1.0000e+00],
        [9.4404e-01]], grad_fn=<ToCopyBackward0>)
Epoch [30/100], T_AUC: [4m0.8653[0m
Epoch [30/100], Loss: 55.5796
val_Accuracy: [92m0.6699[0m
val_Precision: [4;34m0.8102[0m,               val_Recall: [4;33m1.0563[0m,                 val_F1 Score: [4;35m0.9134[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  696
Epoch [30/100], V_AUC: [4m0.7730[0m
Epoch [31/100], Loss: 14.7845
train_Accuracy: [91m0.9691[0m
train_Precision: [4;34m0.8619[0m,               train_Recall: [4;33m0.8793[0m,                 train_F1 Score: [4;35m0.8696[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5272
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9840e-01],
        [9.9996e-01],
        [1.4919e-03],
        [7.1317e-03],
        [6.1994e-04],
        [9.9958e-01],
        [9.8932e-01],
        [9.9969e-01],
        [9.8223e-01],
        [4.3885e-04],
        [9.2772e-02],
        [7.0760e-04],
        [8.1964e-02],
        [9.9566e-01],
        [9.9138e-01],
        [1.0893e-01],
        [9.9999e-01],
        [1.2199e-03],
        [3.7639e-02],
        [9.0253e-01],
        [7.3134e-03],
        [1.2880e-02],
        [1.2858e-01],
        [2.2013e-02],
        [9.9998e-01],
        [9.9973e-01],
        [9.9970e-01],
        [9.9999e-01],
        [8.3420e-02],
        [9.4944e-03],
        [1.0000e+00],
        [9.9395e-01]], grad_fn=<ToCopyBackward0>)
Epoch [31/100], T_AUC: [4m0.8675[0m
Epoch [31/100], Loss: 51.8271
val_Accuracy: [92m0.6833[0m
val_Precision: [4;34m0.8236[0m,               val_Recall: [4;33m1.0682[0m,                 val_F1 Score: [4;35m0.9266[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  710
Epoch [31/100], V_AUC: [4m0.7911[0m
Epoch [32/100], Loss: 13.0219
train_Accuracy: [91m0.9730[0m
train_Precision: [4;34m0.8667[0m,               train_Recall: [4;33m0.8807[0m,                 train_F1 Score: [4;35m0.8729[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5293
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9995e-01],
        [9.9921e-01],
        [2.7927e-01],
        [3.1720e-02],
        [5.5065e-04],
        [9.9724e-01],
        [9.6816e-01],
        [9.9900e-01],
        [9.9579e-01],
        [2.0933e-06],
        [4.9044e-02],
        [2.5409e-02],
        [3.1647e-02],
        [9.9243e-01],
        [9.9902e-01],
        [5.7458e-01],
        [9.9998e-01],
        [1.0761e-02],
        [1.9492e-02],
        [9.9988e-01],
        [6.0282e-03],
        [3.0681e-03],
        [7.6993e-02],
        [1.4459e-02],
        [1.0000e+00],
        [9.6228e-01],
        [9.9965e-01],
        [1.0000e+00],
        [1.3653e-02],
        [1.6931e-03],
        [9.9999e-01],
        [9.7999e-01]], grad_fn=<ToCopyBackward0>)
Epoch [32/100], T_AUC: [4m0.8716[0m
Epoch [32/100], Loss: 52.1111
val_Accuracy: [92m0.6843[0m
val_Precision: [4;34m0.8325[0m,               val_Recall: [4;33m1.0317[0m,                 val_F1 Score: [4;35m0.9186[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  711
Epoch [32/100], V_AUC: [4m0.7967[0m
Epoch [33/100], Loss: 13.2108
train_Accuracy: [91m0.9732[0m
train_Precision: [4;34m0.8676[0m,               train_Recall: [4;33m0.8797[0m,                 train_F1 Score: [4;35m0.8729[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5294
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9989e-01],
        [9.9886e-01],
        [2.2119e-01],
        [5.0138e-01],
        [1.7742e-04],
        [9.9816e-01],
        [9.9929e-01],
        [9.9999e-01],
        [9.6926e-01],
        [1.1981e-02],
        [1.0949e-01],
        [1.7805e-02],
        [4.0013e-02],
        [6.2864e-01],
        [9.9440e-01],
        [3.4143e-03],
        [9.9998e-01],
        [1.7189e-02],
        [2.7502e-02],
        [9.9934e-01],
        [3.0580e-03],
        [6.7955e-02],
        [3.0820e-03],
        [8.4462e-03],
        [1.0000e+00],
        [9.8238e-01],
        [9.9997e-01],
        [9.9998e-01],
        [2.3428e-03],
        [6.7606e-03],
        [9.9995e-01],
        [9.9949e-01]], grad_fn=<ToCopyBackward0>)
Epoch [33/100], T_AUC: [4m0.8717[0m
Epoch [33/100], Loss: 111.8002
val_Accuracy: [92m0.6410[0m
val_Precision: [4;34m0.7746[0m,               val_Recall: [4;33m1.0944[0m,                 val_F1 Score: [4;35m0.9038[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  666
Epoch [33/100], V_AUC: [4m0.7241[0m
Epoch [34/100], Loss: 11.8633
train_Accuracy: [91m0.9735[0m
train_Precision: [4;34m0.8660[0m,               train_Recall: [4;33m0.8818[0m,                 train_F1 Score: [4;35m0.8730[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5296
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9997e-01],
        [9.9976e-01],
        [5.5909e-06],
        [5.2720e-03],
        [5.5368e-04],
        [9.8580e-01],
        [9.9745e-01],
        [3.7725e-01],
        [9.9992e-01],
        [2.2303e-03],
        [7.6366e-04],
        [1.4249e-02],
        [1.1049e-01],
        [9.7446e-01],
        [9.9969e-01],
        [6.6635e-03],
        [9.9999e-01],
        [9.7216e-02],
        [5.0731e-02],
        [9.9013e-01],
        [6.3941e-03],
        [8.1936e-03],
        [1.5379e-01],
        [9.2341e-03],
        [1.0000e+00],
        [9.9999e-01],
        [9.9980e-01],
        [1.0000e+00],
        [2.8367e-01],
        [1.7001e-03],
        [1.0000e+00],
        [9.9348e-01]], grad_fn=<ToCopyBackward0>)
Epoch [34/100], T_AUC: [4m0.8719[0m
Epoch [34/100], Loss: 62.8051
val_Accuracy: [92m0.6910[0m
val_Precision: [4;34m0.8449[0m,               val_Recall: [4;33m1.0149[0m,                 val_F1 Score: [4;35m0.9184[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  718
Epoch [34/100], V_AUC: [4m0.8079[0m
Epoch [35/100], Loss: 10.0281
train_Accuracy: [91m0.9779[0m
train_Precision: [4;34m0.8713[0m,               train_Recall: [4;33m0.8843[0m,                 train_F1 Score: [4;35m0.8772[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5320
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9967e-01],
        [9.9972e-01],
        [1.0863e-03],
        [5.4447e-05],
        [4.7984e-03],
        [9.9995e-01],
        [9.9998e-01],
        [9.9984e-01],
        [9.9927e-01],
        [2.5588e-04],
        [5.9978e-04],
        [9.1127e-03],
        [7.7172e-04],
        [9.8238e-01],
        [9.9931e-01],
        [6.6163e-03],
        [9.9995e-01],
        [1.1885e-01],
        [1.3208e-03],
        [9.9427e-01],
        [1.5568e-01],
        [3.5643e-03],
        [9.6691e-03],
        [3.4967e-01],
        [1.0000e+00],
        [9.9999e-01],
        [9.9699e-01],
        [1.0000e+00],
        [2.0650e-02],
        [1.8648e-03],
        [9.9997e-01],
        [9.9646e-01]], grad_fn=<ToCopyBackward0>)
Epoch [35/100], T_AUC: [4m0.8749[0m
Epoch [35/100], Loss: 52.2385
val_Accuracy: [92m0.7026[0m
val_Precision: [4;34m0.9074[0m,               val_Recall: [4;33m0.8985[0m,                 val_F1 Score: [4;35m0.8988[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  730
Epoch [35/100], V_AUC: [4m0.8461[0m
Epoch [36/100], Loss: 12.5579
train_Accuracy: [91m0.9715[0m
train_Precision: [4;34m0.8675[0m,               train_Recall: [4;33m0.8775[0m,                 train_F1 Score: [4;35m0.8717[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5285
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9980e-01],
        [9.9999e-01],
        [3.7343e-05],
        [4.9102e-03],
        [2.3574e-04],
        [9.9999e-01],
        [9.7068e-01],
        [9.9958e-01],
        [9.7867e-01],
        [1.8838e-03],
        [8.0973e-03],
        [7.3722e-04],
        [3.4107e-03],
        [9.9544e-01],
        [9.9957e-01],
        [9.9062e-02],
        [1.0000e+00],
        [2.2250e-05],
        [2.7231e-03],
        [9.9955e-01],
        [4.6750e-03],
        [1.5143e-01],
        [2.4548e-02],
        [1.4140e-02],
        [9.9999e-01],
        [1.0000e+00],
        [9.9996e-01],
        [1.0000e+00],
        [1.1979e-02],
        [1.7729e-02],
        [9.9999e-01],
        [9.9777e-01]], grad_fn=<ToCopyBackward0>)
Epoch [36/100], T_AUC: [4m0.8697[0m
Epoch [36/100], Loss: 77.3034
val_Accuracy: [92m0.6631[0m
val_Precision: [4;34m0.8103[0m,               val_Recall: [4;33m1.0250[0m,                 val_F1 Score: [4;35m0.9016[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  689
Epoch [36/100], V_AUC: [4m0.7636[0m
Epoch [37/100], Loss: 8.9023
train_Accuracy: [91m0.9846[0m
train_Precision: [4;34m0.8792[0m,               train_Recall: [4;33m0.8850[0m,                 train_F1 Score: [4;35m0.8817[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5356
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [9.9978e-01],
        [7.1934e-05],
        [3.2004e-05],
        [5.3957e-04],
        [9.9993e-01],
        [9.9825e-01],
        [9.8721e-01],
        [9.9338e-01],
        [1.4072e-02],
        [8.6797e-03],
        [1.5560e-03],
        [1.1512e-04],
        [9.9216e-01],
        [9.9645e-01],
        [1.5637e-02],
        [1.0000e+00],
        [1.1788e-01],
        [6.3897e-03],
        [9.9998e-01],
        [5.6287e-02],
        [7.5831e-03],
        [1.9917e-01],
        [7.1999e-02],
        [9.9999e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.5391e-03],
        [4.4244e-02],
        [1.0000e+00],
        [9.9498e-01]], grad_fn=<ToCopyBackward0>)
Epoch [37/100], T_AUC: [4m0.8817[0m
Epoch [37/100], Loss: 50.3028
val_Accuracy: [92m0.6997[0m
val_Precision: [4;34m0.8887[0m,               val_Recall: [4;33m0.9384[0m,                 val_F1 Score: [4;35m0.9092[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  727
Epoch [37/100], V_AUC: [4m0.8371[0m
Epoch [38/100], Loss: 7.9700
train_Accuracy: [91m0.9846[0m
train_Precision: [4;34m0.8796[0m,               train_Recall: [4;33m0.8855[0m,                 train_F1 Score: [4;35m0.8822[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5356
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9999e-01],
        [9.9994e-01],
        [1.4626e-04],
        [4.3325e-04],
        [1.2527e-03],
        [9.9998e-01],
        [9.9916e-01],
        [9.9959e-01],
        [9.9997e-01],
        [1.9619e-03],
        [1.0433e-02],
        [1.0189e-02],
        [1.3950e-03],
        [9.6483e-01],
        [9.9234e-01],
        [1.6738e-02],
        [9.9998e-01],
        [2.2544e-01],
        [4.4825e-04],
        [9.9999e-01],
        [1.2481e-01],
        [2.4381e-03],
        [5.4960e-04],
        [1.4393e-03],
        [9.9924e-01],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [6.3422e-03],
        [8.9370e-02],
        [1.0000e+00],
        [9.9859e-01]], grad_fn=<ToCopyBackward0>)
Epoch [38/100], T_AUC: [4m0.8817[0m
Epoch [38/100], Loss: 56.5517
val_Accuracy: [92m0.6968[0m
val_Precision: [4;34m0.8594[0m,               val_Recall: [4;33m0.9943[0m,                 val_F1 Score: [4;35m0.9189[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  724
Epoch [38/100], V_AUC: [4m0.8194[0m
Epoch [39/100], Loss: 5.5500
train_Accuracy: [91m0.9906[0m
train_Precision: [4;34m0.8835[0m,               train_Recall: [4;33m0.8905[0m,                 train_F1 Score: [4;35m0.8868[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5389
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [9.9994e-01],
        [7.3125e-06],
        [5.3942e-02],
        [8.2518e-04],
        [9.9986e-01],
        [9.9843e-01],
        [9.9987e-01],
        [9.9990e-01],
        [4.7144e-04],
        [7.1338e-02],
        [1.1288e-01],
        [4.6346e-03],
        [9.8897e-01],
        [9.9994e-01],
        [6.9552e-04],
        [1.0000e+00],
        [8.4129e-04],
        [1.0329e-02],
        [9.9222e-01],
        [5.2801e-03],
        [7.1981e-03],
        [3.0323e-04],
        [1.3655e-04],
        [9.9997e-01],
        [9.9999e-01],
        [9.9993e-01],
        [1.0000e+00],
        [1.0110e-02],
        [4.0718e-02],
        [1.0000e+00],
        [9.9510e-01]], grad_fn=<ToCopyBackward0>)
Epoch [39/100], T_AUC: [4m0.8868[0m
Epoch [39/100], Loss: 72.8706
val_Accuracy: [92m0.6670[0m
val_Precision: [4;34m0.8299[0m,               val_Recall: [4;33m0.9693[0m,                 val_F1 Score: [4;35m0.8907[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  693
Epoch [39/100], V_AUC: [4m0.7803[0m
Epoch [40/100], Loss: 4.5985
train_Accuracy: [91m0.9915[0m
train_Precision: [4;34m0.8871[0m,               train_Recall: [4;33m0.8892[0m,                 train_F1 Score: [4;35m0.8879[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5394
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [9.9999e-01],
        [5.5489e-07],
        [8.6306e-04],
        [2.1479e-03],
        [9.9990e-01],
        [9.9991e-01],
        [9.6639e-01],
        [1.0000e+00],
        [1.5300e-05],
        [2.5158e-02],
        [3.4673e-03],
        [5.1964e-03],
        [4.5314e-01],
        [9.9960e-01],
        [7.2711e-01],
        [1.0000e+00],
        [9.6952e-05],
        [2.3378e-02],
        [9.9809e-01],
        [3.0205e-03],
        [5.2338e-03],
        [9.4144e-04],
        [6.0288e-04],
        [9.9977e-01],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [5.6496e-03],
        [1.6369e-01],
        [1.0000e+00],
        [9.9065e-01]], grad_fn=<ToCopyBackward0>)
Epoch [40/100], T_AUC: [4m0.8876[0m
Epoch [40/100], Loss: 75.9568
val_Accuracy: [92m0.6853[0m
val_Precision: [4;34m0.8439[0m,               val_Recall: [4;33m1.0073[0m,                 val_F1 Score: [4;35m0.9144[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  712
Epoch [40/100], V_AUC: [4m0.8060[0m
Epoch [41/100], Loss: 2.9740
train_Accuracy: [91m0.9958[0m
train_Precision: [4;34m0.8884[0m,               train_Recall: [4;33m0.8939[0m,                 train_F1 Score: [4;35m0.8910[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5417
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [9.9999e-01],
        [1.0235e-06],
        [3.3463e-04],
        [5.7199e-04],
        [9.9995e-01],
        [9.9936e-01],
        [9.9997e-01],
        [9.9998e-01],
        [1.3801e-04],
        [6.1826e-02],
        [2.7865e-03],
        [1.9372e-02],
        [9.9989e-01],
        [9.9999e-01],
        [2.9548e-05],
        [1.0000e+00],
        [7.3291e-04],
        [1.2937e-03],
        [9.9946e-01],
        [1.0818e-03],
        [1.0096e-02],
        [2.5101e-02],
        [2.7985e-01],
        [9.9969e-01],
        [9.9999e-01],
        [9.9997e-01],
        [1.0000e+00],
        [8.1826e-03],
        [3.6593e-04],
        [1.0000e+00],
        [9.8696e-01]], grad_fn=<ToCopyBackward0>)
Epoch [41/100], T_AUC: [4m0.8910[0m
Epoch [41/100], Loss: 67.0293
val_Accuracy: [92m0.6833[0m
val_Precision: [4;34m0.8470[0m,               val_Recall: [4;33m0.9782[0m,                 val_F1 Score: [4;35m0.9047[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  710
Epoch [41/100], V_AUC: [4m0.8039[0m
Epoch [42/100], Loss: 1.7129
train_Accuracy: [91m0.9985[0m
train_Precision: [4;34m0.8936[0m,               train_Recall: [4;33m0.8938[0m,                 train_F1 Score: [4;35m0.8937[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5432
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [5.8804e-07],
        [1.6213e-01],
        [4.1909e-04],
        [1.0000e+00],
        [9.9995e-01],
        [9.9999e-01],
        [1.0000e+00],
        [2.7208e-05],
        [4.5399e-04],
        [2.4275e-04],
        [1.2698e-03],
        [9.9928e-01],
        [9.9999e-01],
        [1.5325e-05],
        [1.0000e+00],
        [1.7758e-02],
        [4.1385e-04],
        [9.9746e-01],
        [2.7974e-04],
        [2.0544e-02],
        [2.9153e-03],
        [1.9585e-05],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [3.4487e-02],
        [7.0913e-05],
        [1.0000e+00],
        [9.9557e-01]], grad_fn=<ToCopyBackward0>)
Epoch [42/100], T_AUC: [4m0.8934[0m
Epoch [42/100], Loss: 70.9637
val_Accuracy: [92m0.6910[0m
val_Precision: [4;34m0.8659[0m,               val_Recall: [4;33m0.9529[0m,                 val_F1 Score: [4;35m0.9039[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  718
Epoch [42/100], V_AUC: [4m0.8165[0m
Epoch [43/100], Loss: 1.8372
train_Accuracy: [91m0.9976[0m
train_Precision: [4;34m0.8923[0m,               train_Recall: [4;33m0.8934[0m,                 train_F1 Score: [4;35m0.8928[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5427
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [9.9996e-01],
        [7.7065e-07],
        [8.5506e-04],
        [3.1769e-04],
        [9.9997e-01],
        [9.9516e-01],
        [1.0000e+00],
        [1.0000e+00],
        [8.3625e-07],
        [1.9519e-02],
        [5.2636e-04],
        [3.0202e-05],
        [9.9997e-01],
        [1.0000e+00],
        [3.4566e-04],
        [1.0000e+00],
        [5.0248e-02],
        [1.6669e-03],
        [9.8574e-01],
        [2.8533e-04],
        [5.2443e-03],
        [1.1688e-03],
        [1.5958e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9997e-01],
        [1.0000e+00],
        [6.3753e-02],
        [5.3413e-05],
        [1.0000e+00],
        [9.9967e-01]], grad_fn=<ToCopyBackward0>)
Epoch [43/100], T_AUC: [4m0.8927[0m
Epoch [43/100], Loss: 81.3611
val_Accuracy: [92m0.6853[0m
val_Precision: [4;34m0.8510[0m,               val_Recall: [4;33m0.9694[0m,                 val_F1 Score: [4;35m0.9037[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  712
Epoch [43/100], V_AUC: [4m0.8096[0m
Epoch [44/100], Loss: 1.9545
train_Accuracy: [91m0.9963[0m
train_Precision: [4;34m0.8910[0m,               train_Recall: [4;33m0.8924[0m,                 train_F1 Score: [4;35m0.8916[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5420
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [9.9997e-01],
        [2.5651e-07],
        [1.0954e-05],
        [1.4244e-04],
        [9.9993e-01],
        [9.9693e-01],
        [9.9992e-01],
        [9.9997e-01],
        [4.4135e-04],
        [4.6023e-02],
        [2.3987e-03],
        [2.9604e-06],
        [9.9997e-01],
        [1.0000e+00],
        [3.0447e-04],
        [1.0000e+00],
        [2.9416e-03],
        [1.9851e-03],
        [9.9829e-01],
        [1.3573e-03],
        [5.9708e-03],
        [7.3577e-04],
        [8.1942e-04],
        [1.0000e+00],
        [1.0000e+00],
        [9.9993e-01],
        [1.0000e+00],
        [4.6048e-03],
        [1.3231e-04],
        [1.0000e+00],
        [9.9999e-01]], grad_fn=<ToCopyBackward0>)
Epoch [44/100], T_AUC: [4m0.8918[0m
Epoch [44/100], Loss: 80.0591
val_Accuracy: [92m0.6853[0m
val_Precision: [4;34m0.8422[0m,               val_Recall: [4;33m0.9999[0m,                 val_F1 Score: [4;35m0.9113[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  712
Epoch [44/100], V_AUC: [4m0.8007[0m
Epoch [45/100], Loss: 5.6366
train_Accuracy: [91m0.9892[0m
train_Precision: [4;34m0.8826[0m,               train_Recall: [4;33m0.8897[0m,                 train_F1 Score: [4;35m0.8858[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5381
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9967e-01],
        [1.0000e+00],
        [1.3737e-03],
        [3.2876e-05],
        [8.0098e-04],
        [9.9988e-01],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.3163e-05],
        [1.5550e-03],
        [2.0596e-05],
        [6.1475e-05],
        [9.9998e-01],
        [9.9938e-01],
        [2.2990e-02],
        [1.0000e+00],
        [2.2524e-04],
        [6.4409e-05],
        [9.4208e-01],
        [8.5229e-04],
        [2.5547e-03],
        [9.4085e-05],
        [2.4613e-04],
        [1.0000e+00],
        [9.9990e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.8178e-02],
        [2.3245e-04],
        [1.0000e+00],
        [9.9997e-01]], grad_fn=<ToCopyBackward0>)
Epoch [45/100], T_AUC: [4m0.8851[0m
Epoch [45/100], Loss: 107.8220
val_Accuracy: [92m0.7007[0m
val_Precision: [4;34m0.8688[0m,               val_Recall: [4;33m0.9762[0m,                 val_F1 Score: [4;35m0.9167[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  728
Epoch [45/100], V_AUC: [4m0.8270[0m
Epoch [46/100], Loss: 19.1953
train_Accuracy: [91m0.9585[0m
train_Precision: [4;34m0.8569[0m,               train_Recall: [4;33m0.8679[0m,                 train_F1 Score: [4;35m0.8614[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5214
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9997e-01],
        [1.0000e+00],
        [1.8745e-06],
        [6.4298e-02],
        [9.9306e-05],
        [9.9772e-01],
        [9.8284e-01],
        [9.7209e-01],
        [9.9158e-01],
        [2.0007e-02],
        [1.6658e-01],
        [9.6685e-03],
        [5.8113e-01],
        [3.1851e-02],
        [6.9069e-01],
        [1.9494e-05],
        [1.0000e+00],
        [6.8117e-01],
        [2.6780e-02],
        [3.0881e-01],
        [3.0666e-04],
        [2.9940e-01],
        [9.9707e-01],
        [1.5780e-01],
        [1.0000e+00],
        [1.0000e+00],
        [9.9912e-01],
        [1.0000e+00],
        [6.1216e-02],
        [1.3547e-04],
        [9.9997e-01],
        [9.9933e-01]], grad_fn=<ToCopyBackward0>)
Epoch [46/100], T_AUC: [4m0.8583[0m
Epoch [46/100], Loss: 60.1673
val_Accuracy: [92m0.6853[0m
val_Precision: [4;34m0.8592[0m,               val_Recall: [4;33m0.9615[0m,                 val_F1 Score: [4;35m0.9038[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  712
Epoch [46/100], V_AUC: [4m0.8099[0m
Epoch [47/100], Loss: 15.8552
train_Accuracy: [91m0.9658[0m
train_Precision: [4;34m0.8609[0m,               train_Recall: [4;33m0.8750[0m,                 train_F1 Score: [4;35m0.8670[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5254
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9999e-01],
        [9.9999e-01],
        [1.0206e-05],
        [3.6309e-01],
        [1.0967e-03],
        [9.9987e-01],
        [9.8796e-01],
        [9.9957e-01],
        [9.9962e-01],
        [1.9679e-05],
        [3.9113e-02],
        [7.7918e-03],
        [6.2599e-04],
        [9.9999e-01],
        [1.0000e+00],
        [4.5585e-04],
        [1.0000e+00],
        [1.3257e-02],
        [2.3580e-02],
        [9.9750e-01],
        [1.7524e-03],
        [1.3800e-03],
        [9.8021e-04],
        [8.9029e-04],
        [9.9999e-01],
        [9.9999e-01],
        [9.9964e-01],
        [1.0000e+00],
        [4.6761e-03],
        [2.1413e-02],
        [1.0000e+00],
        [9.9980e-01]], grad_fn=<ToCopyBackward0>)
Epoch [47/100], T_AUC: [4m0.8651[0m
Epoch [47/100], Loss: 65.1439
val_Accuracy: [92m0.6939[0m
val_Precision: [4;34m0.8864[0m,               val_Recall: [4;33m0.9282[0m,                 val_F1 Score: [4;35m0.9026[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  721
Epoch [47/100], V_AUC: [4m0.8324[0m
Epoch [48/100], Loss: 5.7988
train_Accuracy: [91m0.9892[0m
train_Precision: [4;34m0.8836[0m,               train_Recall: [4;33m0.8887[0m,                 train_F1 Score: [4;35m0.8858[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5381
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9998e-01],
        [1.0000e+00],
        [1.1055e-06],
        [1.0866e-03],
        [3.0339e-03],
        [9.9995e-01],
        [9.8238e-01],
        [9.4038e-01],
        [9.9979e-01],
        [3.2261e-06],
        [2.1586e-03],
        [1.3235e-02],
        [4.3366e-03],
        [9.9992e-01],
        [9.9999e-01],
        [3.0410e-03],
        [1.0000e+00],
        [2.8068e-04],
        [1.2771e-02],
        [9.9948e-01],
        [5.3405e-04],
        [2.9910e-03],
        [1.5002e-03],
        [1.9349e-03],
        [1.0000e+00],
        [9.9985e-01],
        [9.9995e-01],
        [1.0000e+00],
        [1.5369e-02],
        [1.8390e-02],
        [1.0000e+00],
        [9.9702e-01]], grad_fn=<ToCopyBackward0>)
Epoch [48/100], T_AUC: [4m0.8856[0m
Epoch [48/100], Loss: 86.7977
val_Accuracy: [92m0.6920[0m
val_Precision: [4;34m0.8588[0m,               val_Recall: [4;33m0.9787[0m,                 val_F1 Score: [4;35m0.9116[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  719
Epoch [48/100], V_AUC: [4m0.8162[0m
Epoch [49/100], Loss: 3.0001
train_Accuracy: [91m0.9950[0m
train_Precision: [4;34m0.8905[0m,               train_Recall: [4;33m0.8909[0m,                 train_F1 Score: [4;35m0.8906[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5413
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [4.7918e-08],
        [1.0209e-03],
        [4.6946e-05],
        [9.9998e-01],
        [9.9954e-01],
        [9.9974e-01],
        [9.9997e-01],
        [1.3942e-05],
        [1.7293e-04],
        [5.5564e-04],
        [9.9385e-04],
        [9.9999e-01],
        [1.0000e+00],
        [5.6617e-04],
        [1.0000e+00],
        [2.2248e-04],
        [3.1766e-02],
        [9.9167e-01],
        [1.6293e-04],
        [2.0697e-03],
        [1.9390e-04],
        [2.1460e-03],
        [1.0000e+00],
        [1.0000e+00],
        [9.9955e-01],
        [1.0000e+00],
        [4.6131e-02],
        [2.2018e-02],
        [1.0000e+00],
        [9.9975e-01]], grad_fn=<ToCopyBackward0>)
Epoch [49/100], T_AUC: [4m0.8907[0m
Epoch [49/100], Loss: 104.5119
val_Accuracy: [92m0.6978[0m
val_Precision: [4;34m0.8582[0m,               val_Recall: [4;33m1.0100[0m,                 val_F1 Score: [4;35m0.9247[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  725
Epoch [49/100], V_AUC: [4m0.8221[0m
Epoch [50/100], Loss: 1.7327
train_Accuracy: [91m0.9978[0m
train_Precision: [4;34m0.8919[0m,               train_Recall: [4;33m0.8940[0m,                 train_F1 Score: [4;35m0.8929[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5428
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [6.3913e-09],
        [1.1983e-03],
        [2.1713e-05],
        [9.9996e-01],
        [9.9989e-01],
        [9.9984e-01],
        [1.0000e+00],
        [6.3283e-06],
        [1.1861e-03],
        [1.6689e-03],
        [4.9805e-03],
        [9.9995e-01],
        [1.0000e+00],
        [4.0398e-04],
        [1.0000e+00],
        [4.9421e-04],
        [2.3738e-03],
        [9.9970e-01],
        [2.6673e-04],
        [8.9151e-04],
        [1.7298e-04],
        [4.7906e-04],
        [1.0000e+00],
        [9.9999e-01],
        [9.9941e-01],
        [1.0000e+00],
        [1.4045e-02],
        [2.1629e-03],
        [1.0000e+00],
        [9.9940e-01]], grad_fn=<ToCopyBackward0>)
Epoch [50/100], T_AUC: [4m0.8929[0m
Epoch [50/100], Loss: 78.2059
val_Accuracy: [92m0.7113[0m
val_Precision: [4;34m0.8883[0m,               val_Recall: [4;33m0.9758[0m,                 val_F1 Score: [4;35m0.9273[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  739
Epoch [50/100], V_AUC: [4m0.8482[0m
Epoch [51/100], Loss: 0.5322
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [5.1349e-09],
        [2.3429e-03],
        [4.2689e-05],
        [9.9983e-01],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.9205e-05],
        [8.0793e-04],
        [7.3737e-04],
        [1.6919e-03],
        [9.9998e-01],
        [1.0000e+00],
        [1.8097e-04],
        [1.0000e+00],
        [1.2512e-04],
        [1.0352e-03],
        [9.9991e-01],
        [3.4162e-04],
        [1.4047e-03],
        [1.2434e-04],
        [1.3812e-04],
        [1.0000e+00],
        [9.9999e-01],
        [9.9974e-01],
        [1.0000e+00],
        [3.5908e-03],
        [1.5887e-04],
        [1.0000e+00],
        [9.9931e-01]], grad_fn=<ToCopyBackward0>)
Epoch [51/100], T_AUC: [4m0.8947[0m
Epoch [51/100], Loss: 81.4218
val_Accuracy: [92m0.7190[0m
val_Precision: [4;34m0.8985[0m,               val_Recall: [4;33m0.9765[0m,                 val_F1 Score: [4;35m0.9336[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  747
Epoch [51/100], V_AUC: [4m0.8567[0m
Epoch [52/100], Loss: 0.2686
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [5.4659e-09],
        [6.4146e-04],
        [3.2660e-05],
        [9.9987e-01],
        [9.9997e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.2207e-05],
        [8.3404e-04],
        [6.6004e-04],
        [8.5786e-04],
        [9.9999e-01],
        [1.0000e+00],
        [1.6818e-04],
        [1.0000e+00],
        [1.2306e-04],
        [9.5527e-04],
        [9.9994e-01],
        [3.6824e-04],
        [1.1718e-03],
        [1.2809e-04],
        [1.7115e-04],
        [1.0000e+00],
        [9.9999e-01],
        [9.9990e-01],
        [1.0000e+00],
        [2.2190e-03],
        [1.0575e-04],
        [1.0000e+00],
        [9.9960e-01]], grad_fn=<ToCopyBackward0>)
Epoch [52/100], T_AUC: [4m0.8947[0m
Epoch [52/100], Loss: 85.0070
val_Accuracy: [92m0.7132[0m
val_Precision: [4;34m0.8913[0m,               val_Recall: [4;33m0.9789[0m,                 val_F1 Score: [4;35m0.9305[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  741
Epoch [52/100], V_AUC: [4m0.8490[0m
Epoch [53/100], Loss: 0.1653
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [4.3207e-09],
        [4.8085e-04],
        [3.0195e-05],
        [9.9992e-01],
        [9.9997e-01],
        [1.0000e+00],
        [1.0000e+00],
        [8.0791e-06],
        [6.7833e-04],
        [4.8613e-04],
        [7.2746e-04],
        [9.9999e-01],
        [1.0000e+00],
        [1.4007e-04],
        [1.0000e+00],
        [1.0231e-04],
        [7.3675e-04],
        [9.9996e-01],
        [3.2135e-04],
        [1.1419e-03],
        [1.1007e-04],
        [1.2965e-04],
        [1.0000e+00],
        [9.9999e-01],
        [9.9991e-01],
        [1.0000e+00],
        [1.7716e-03],
        [9.3918e-05],
        [1.0000e+00],
        [9.9967e-01]], grad_fn=<ToCopyBackward0>)
Epoch [53/100], T_AUC: [4m0.8947[0m
Epoch [53/100], Loss: 85.5888
val_Accuracy: [92m0.7161[0m
val_Precision: [4;34m0.8953[0m,               val_Recall: [4;33m0.9789[0m,                 val_F1 Score: [4;35m0.9326[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  744
Epoch [53/100], V_AUC: [4m0.8541[0m
Epoch [54/100], Loss: 0.1328
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [3.7778e-09],
        [3.7551e-04],
        [2.7300e-05],
        [9.9995e-01],
        [9.9997e-01],
        [1.0000e+00],
        [1.0000e+00],
        [5.9136e-06],
        [5.8933e-04],
        [3.7304e-04],
        [6.3393e-04],
        [9.9999e-01],
        [1.0000e+00],
        [1.2307e-04],
        [1.0000e+00],
        [8.6674e-05],
        [5.9380e-04],
        [9.9997e-01],
        [3.0477e-04],
        [1.0474e-03],
        [9.9769e-05],
        [1.0150e-04],
        [1.0000e+00],
        [1.0000e+00],
        [9.9991e-01],
        [1.0000e+00],
        [1.4740e-03],
        [8.4529e-05],
        [1.0000e+00],
        [9.9971e-01]], grad_fn=<ToCopyBackward0>)
Epoch [54/100], T_AUC: [4m0.8947[0m
Epoch [54/100], Loss: 86.1788
val_Accuracy: [92m0.7151[0m
val_Precision: [4;34m0.8955[0m,               val_Recall: [4;33m0.9772[0m,                 val_F1 Score: [4;35m0.9319[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  743
Epoch [54/100], V_AUC: [4m0.8533[0m
Epoch [55/100], Loss: 0.1117
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [3.3307e-09],
        [3.1069e-04],
        [2.4778e-05],
        [9.9996e-01],
        [9.9997e-01],
        [1.0000e+00],
        [1.0000e+00],
        [4.5362e-06],
        [5.1876e-04],
        [2.8689e-04],
        [5.7254e-04],
        [9.9999e-01],
        [1.0000e+00],
        [1.0791e-04],
        [1.0000e+00],
        [7.4187e-05],
        [4.8974e-04],
        [9.9998e-01],
        [2.7356e-04],
        [9.7023e-04],
        [9.2812e-05],
        [8.3392e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9992e-01],
        [1.0000e+00],
        [1.2588e-03],
        [7.6849e-05],
        [1.0000e+00],
        [9.9974e-01]], grad_fn=<ToCopyBackward0>)
Epoch [55/100], T_AUC: [4m0.8947[0m
Epoch [55/100], Loss: 89.3734
val_Accuracy: [92m0.7122[0m
val_Precision: [4;34m0.8934[0m,               val_Recall: [4;33m0.9704[0m,                 val_F1 Score: [4;35m0.9279[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  740
Epoch [55/100], V_AUC: [4m0.8499[0m
Epoch [56/100], Loss: 0.0962
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.9931e-09],
        [2.6873e-04],
        [2.2208e-05],
        [9.9997e-01],
        [9.9997e-01],
        [1.0000e+00],
        [1.0000e+00],
        [3.5122e-06],
        [4.6882e-04],
        [2.2501e-04],
        [5.0909e-04],
        [9.9999e-01],
        [1.0000e+00],
        [9.7211e-05],
        [1.0000e+00],
        [6.4913e-05],
        [4.0879e-04],
        [9.9998e-01],
        [2.4625e-04],
        [8.8984e-04],
        [8.7792e-05],
        [7.0528e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9992e-01],
        [1.0000e+00],
        [1.0908e-03],
        [6.9216e-05],
        [1.0000e+00],
        [9.9976e-01]], grad_fn=<ToCopyBackward0>)
Epoch [56/100], T_AUC: [4m0.8947[0m
Epoch [56/100], Loss: 89.9635
val_Accuracy: [92m0.7113[0m
val_Precision: [4;34m0.8919[0m,               val_Recall: [4;33m0.9704[0m,                 val_F1 Score: [4;35m0.9271[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  739
Epoch [56/100], V_AUC: [4m0.8486[0m
Epoch [57/100], Loss: 0.0841
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.6354e-09],
        [2.4012e-04],
        [2.0088e-05],
        [9.9997e-01],
        [9.9997e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.7516e-06],
        [4.3076e-04],
        [1.7905e-04],
        [4.4762e-04],
        [9.9999e-01],
        [1.0000e+00],
        [8.6875e-05],
        [1.0000e+00],
        [5.7804e-05],
        [3.3897e-04],
        [9.9998e-01],
        [2.2140e-04],
        [8.2402e-04],
        [8.3843e-05],
        [6.0985e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9993e-01],
        [1.0000e+00],
        [9.5247e-04],
        [6.3329e-05],
        [1.0000e+00],
        [9.9978e-01]], grad_fn=<ToCopyBackward0>)
Epoch [57/100], T_AUC: [4m0.8947[0m
Epoch [57/100], Loss: 90.5097
val_Accuracy: [92m0.7084[0m
val_Precision: [4;34m0.8893[0m,               val_Recall: [4;33m0.9638[0m,                 val_F1 Score: [4;35m0.9226[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  736
Epoch [57/100], V_AUC: [4m0.8442[0m
Epoch [58/100], Loss: 0.0743
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.3314e-09],
        [2.2150e-04],
        [1.7894e-05],
        [9.9998e-01],
        [9.9997e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.2062e-06],
        [3.9810e-04],
        [1.3989e-04],
        [4.0029e-04],
        [9.9999e-01],
        [1.0000e+00],
        [8.1025e-05],
        [1.0000e+00],
        [5.2124e-05],
        [2.8520e-04],
        [9.9999e-01],
        [1.9809e-04],
        [7.6905e-04],
        [7.9489e-05],
        [5.4131e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9993e-01],
        [1.0000e+00],
        [8.2409e-04],
        [5.8303e-05],
        [1.0000e+00],
        [9.9979e-01]], grad_fn=<ToCopyBackward0>)
Epoch [58/100], T_AUC: [4m0.8947[0m
Epoch [58/100], Loss: 91.0393
val_Accuracy: [92m0.7074[0m
val_Precision: [4;34m0.8892[0m,               val_Recall: [4;33m0.9594[0m,                 val_F1 Score: [4;35m0.9205[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  735
Epoch [58/100], V_AUC: [4m0.8436[0m
Epoch [59/100], Loss: 0.0660
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.0165e-09],
        [2.1248e-04],
        [1.5755e-05],
        [9.9998e-01],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.7690e-06],
        [3.7911e-04],
        [1.0974e-04],
        [3.5632e-04],
        [9.9999e-01],
        [1.0000e+00],
        [7.1847e-05],
        [1.0000e+00],
        [4.6320e-05],
        [2.4156e-04],
        [9.9999e-01],
        [1.7761e-04],
        [7.1415e-04],
        [7.5891e-05],
        [4.7702e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9993e-01],
        [1.0000e+00],
        [7.2948e-04],
        [5.3974e-05],
        [1.0000e+00],
        [9.9980e-01]], grad_fn=<ToCopyBackward0>)
Epoch [59/100], T_AUC: [4m0.8947[0m
Epoch [59/100], Loss: 91.5632
val_Accuracy: [92m0.7074[0m
val_Precision: [4;34m0.8892[0m,               val_Recall: [4;33m0.9594[0m,                 val_F1 Score: [4;35m0.9205[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  735
Epoch [59/100], V_AUC: [4m0.8436[0m
Epoch [60/100], Loss: 0.0591
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.7459e-09],
        [2.0369e-04],
        [1.3925e-05],
        [9.9999e-01],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.4379e-06],
        [3.7184e-04],
        [8.7512e-05],
        [3.1505e-04],
        [9.9999e-01],
        [1.0000e+00],
        [6.3699e-05],
        [1.0000e+00],
        [4.2017e-05],
        [2.0444e-04],
        [9.9999e-01],
        [1.5880e-04],
        [6.6600e-04],
        [7.3591e-05],
        [4.2499e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9994e-01],
        [1.0000e+00],
        [6.3465e-04],
        [4.9616e-05],
        [1.0000e+00],
        [9.9981e-01]], grad_fn=<ToCopyBackward0>)
Epoch [60/100], T_AUC: [4m0.8947[0m
Epoch [60/100], Loss: 92.0803
val_Accuracy: [92m0.7103[0m
val_Precision: [4;34m0.8909[0m,               val_Recall: [4;33m0.9631[0m,                 val_F1 Score: [4;35m0.9232[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  738
Epoch [60/100], V_AUC: [4m0.8466[0m
Epoch [61/100], Loss: 0.0532
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.4935e-09],
        [2.0156e-04],
        [1.2178e-05],
        [9.9999e-01],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.1586e-06],
        [3.5646e-04],
        [7.1468e-05],
        [2.7840e-04],
        [9.9999e-01],
        [1.0000e+00],
        [5.7601e-05],
        [1.0000e+00],
        [3.8653e-05],
        [1.7763e-04],
        [9.9999e-01],
        [1.4058e-04],
        [6.1924e-04],
        [7.1316e-05],
        [3.7092e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9994e-01],
        [1.0000e+00],
        [5.6043e-04],
        [4.5846e-05],
        [1.0000e+00],
        [9.9982e-01]], grad_fn=<ToCopyBackward0>)
Epoch [61/100], T_AUC: [4m0.8947[0m
Epoch [61/100], Loss: 92.5975
val_Accuracy: [92m0.7103[0m
val_Precision: [4;34m0.8916[0m,               val_Recall: [4;33m0.9608[0m,                 val_F1 Score: [4;35m0.9226[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  738
Epoch [61/100], V_AUC: [4m0.8466[0m
Epoch [62/100], Loss: 0.0482
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.2931e-09],
        [1.9517e-04],
        [1.0750e-05],
        [9.9999e-01],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [9.5124e-07],
        [3.4121e-04],
        [5.7747e-05],
        [2.5099e-04],
        [9.9999e-01],
        [1.0000e+00],
        [5.2356e-05],
        [1.0000e+00],
        [3.6488e-05],
        [1.5445e-04],
        [9.9999e-01],
        [1.2867e-04],
        [5.7203e-04],
        [6.9437e-05],
        [3.2835e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9995e-01],
        [1.0000e+00],
        [4.8699e-04],
        [4.2488e-05],
        [1.0000e+00],
        [9.9982e-01]], grad_fn=<ToCopyBackward0>)
Epoch [62/100], T_AUC: [4m0.8947[0m
Epoch [62/100], Loss: 93.0766
val_Accuracy: [92m0.7084[0m
val_Precision: [4;34m0.8889[0m,               val_Recall: [4;33m0.9608[0m,                 val_F1 Score: [4;35m0.9211[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  736
Epoch [62/100], V_AUC: [4m0.8442[0m
Epoch [63/100], Loss: 0.0438
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.0146e-09],
        [1.9807e-04],
        [9.6647e-06],
        [9.9999e-01],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [7.7382e-07],
        [3.2600e-04],
        [4.6708e-05],
        [2.2201e-04],
        [9.9999e-01],
        [1.0000e+00],
        [4.8520e-05],
        [1.0000e+00],
        [3.5360e-05],
        [1.3980e-04],
        [9.9999e-01],
        [1.1375e-04],
        [5.3429e-04],
        [6.6052e-05],
        [2.9283e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9995e-01],
        [1.0000e+00],
        [4.1457e-04],
        [3.9680e-05],
        [1.0000e+00],
        [9.9982e-01]], grad_fn=<ToCopyBackward0>)
Epoch [63/100], T_AUC: [4m0.8947[0m
Epoch [63/100], Loss: 93.5749
val_Accuracy: [92m0.7074[0m
val_Precision: [4;34m0.8878[0m,               val_Recall: [4;33m0.9608[0m,                 val_F1 Score: [4;35m0.9205[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  735
Epoch [63/100], V_AUC: [4m0.8422[0m
Epoch [64/100], Loss: 0.0400
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [8.4045e-10],
        [2.0225e-04],
        [8.4002e-06],
        [9.9999e-01],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [6.1382e-07],
        [3.1285e-04],
        [3.7640e-05],
        [1.9797e-04],
        [9.9999e-01],
        [1.0000e+00],
        [4.4373e-05],
        [1.0000e+00],
        [3.4695e-05],
        [1.2610e-04],
        [9.9999e-01],
        [1.0424e-04],
        [4.8919e-04],
        [6.3162e-05],
        [2.6948e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9995e-01],
        [1.0000e+00],
        [3.7190e-04],
        [3.6812e-05],
        [1.0000e+00],
        [9.9982e-01]], grad_fn=<ToCopyBackward0>)
Epoch [64/100], T_AUC: [4m0.8947[0m
Epoch [64/100], Loss: 94.0419
val_Accuracy: [92m0.7064[0m
val_Precision: [4;34m0.8866[0m,               val_Recall: [4;33m0.9608[0m,                 val_F1 Score: [4;35m0.9198[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  734
Epoch [64/100], V_AUC: [4m0.8408[0m
Epoch [65/100], Loss: 0.0368
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [6.7872e-10],
        [2.1039e-04],
        [7.2491e-06],
        [9.9999e-01],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [4.8126e-07],
        [3.0473e-04],
        [3.0436e-05],
        [1.7638e-04],
        [9.9999e-01],
        [1.0000e+00],
        [4.0929e-05],
        [1.0000e+00],
        [3.5434e-05],
        [1.1502e-04],
        [9.9999e-01],
        [9.5022e-05],
        [4.5524e-04],
        [6.0038e-05],
        [2.4683e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9996e-01],
        [1.0000e+00],
        [3.2810e-04],
        [3.4095e-05],
        [1.0000e+00],
        [9.9982e-01]], grad_fn=<ToCopyBackward0>)
Epoch [65/100], T_AUC: [4m0.8947[0m
Epoch [65/100], Loss: 94.5391
val_Accuracy: [92m0.7064[0m
val_Precision: [4;34m0.8866[0m,               val_Recall: [4;33m0.9608[0m,                 val_F1 Score: [4;35m0.9197[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  734
Epoch [65/100], V_AUC: [4m0.8408[0m
Epoch [66/100], Loss: 0.0339
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [5.7371e-10],
        [2.1725e-04],
        [5.9293e-06],
        [1.0000e+00],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [3.7173e-07],
        [3.0308e-04],
        [2.3880e-05],
        [1.6297e-04],
        [9.9999e-01],
        [1.0000e+00],
        [3.7772e-05],
        [1.0000e+00],
        [3.7227e-05],
        [1.0763e-04],
        [9.9999e-01],
        [8.5493e-05],
        [4.1792e-04],
        [5.6788e-05],
        [2.3080e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9996e-01],
        [1.0000e+00],
        [2.8812e-04],
        [3.1914e-05],
        [1.0000e+00],
        [9.9981e-01]], grad_fn=<ToCopyBackward0>)
Epoch [66/100], T_AUC: [4m0.8947[0m
Epoch [66/100], Loss: 97.6476
val_Accuracy: [92m0.7084[0m
val_Precision: [4;34m0.8888[0m,               val_Recall: [4;33m0.9608[0m,                 val_F1 Score: [4;35m0.9210[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  736
Epoch [66/100], V_AUC: [4m0.8432[0m
Epoch [67/100], Loss: 0.0315
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [4.9191e-10],
        [2.3175e-04],
        [4.8451e-06],
        [1.0000e+00],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.8325e-07],
        [2.9510e-04],
        [1.8928e-05],
        [1.5093e-04],
        [9.9999e-01],
        [1.0000e+00],
        [3.4695e-05],
        [1.0000e+00],
        [3.9813e-05],
        [1.0086e-04],
        [9.9999e-01],
        [7.9264e-05],
        [3.8668e-04],
        [5.3667e-05],
        [2.1452e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9997e-01],
        [1.0000e+00],
        [2.6813e-04],
        [2.9443e-05],
        [1.0000e+00],
        [9.9980e-01]], grad_fn=<ToCopyBackward0>)
Epoch [67/100], T_AUC: [4m0.8947[0m
Epoch [67/100], Loss: 100.7820
val_Accuracy: [92m0.7093[0m
val_Precision: [4;34m0.8904[0m,               val_Recall: [4;33m0.9608[0m,                 val_F1 Score: [4;35m0.9217[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  737
Epoch [67/100], V_AUC: [4m0.8451[0m
Epoch [68/100], Loss: 0.0294
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [4.1641e-10],
        [2.5236e-04],
        [3.9847e-06],
        [1.0000e+00],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.0941e-07],
        [2.9723e-04],
        [1.4745e-05],
        [1.3494e-04],
        [9.9999e-01],
        [1.0000e+00],
        [3.2925e-05],
        [1.0000e+00],
        [4.3158e-05],
        [9.5764e-05],
        [9.9999e-01],
        [7.3889e-05],
        [3.6086e-04],
        [5.0161e-05],
        [2.1476e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9997e-01],
        [1.0000e+00],
        [2.3206e-04],
        [2.7672e-05],
        [1.0000e+00],
        [9.9979e-01]], grad_fn=<ToCopyBackward0>)
Epoch [68/100], T_AUC: [4m0.8947[0m
Epoch [68/100], Loss: 101.2942
val_Accuracy: [92m0.7103[0m
val_Precision: [4;34m0.8924[0m,               val_Recall: [4;33m0.9591[0m,                 val_F1 Score: [4;35m0.9222[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  738
Epoch [68/100], V_AUC: [4m0.8466[0m
Epoch [69/100], Loss: 0.0275
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [3.9010e-10],
        [2.6721e-04],
        [3.1920e-06],
        [1.0000e+00],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.5589e-07],
        [2.8456e-04],
        [1.2062e-05],
        [1.2256e-04],
        [9.9999e-01],
        [1.0000e+00],
        [3.0863e-05],
        [1.0000e+00],
        [4.6063e-05],
        [8.9098e-05],
        [9.9999e-01],
        [7.1297e-05],
        [3.4236e-04],
        [4.6968e-05],
        [2.1131e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9997e-01],
        [1.0000e+00],
        [2.1090e-04],
        [2.5428e-05],
        [1.0000e+00],
        [9.9978e-01]], grad_fn=<ToCopyBackward0>)
Epoch [69/100], T_AUC: [4m0.8947[0m
Epoch [69/100], Loss: 101.8738
val_Accuracy: [92m0.7093[0m
val_Precision: [4;34m0.8900[0m,               val_Recall: [4;33m0.9567[0m,                 val_F1 Score: [4;35m0.9198[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  737
Epoch [69/100], V_AUC: [4m0.8442[0m
Epoch [70/100], Loss: 0.0259
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [3.5076e-10],
        [2.8574e-04],
        [2.5889e-06],
        [1.0000e+00],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.1403e-07],
        [2.7622e-04],
        [9.1449e-06],
        [1.0979e-04],
        [9.9999e-01],
        [1.0000e+00],
        [3.1466e-05],
        [1.0000e+00],
        [5.0020e-05],
        [8.2213e-05],
        [9.9999e-01],
        [6.8368e-05],
        [3.2326e-04],
        [4.4464e-05],
        [2.3702e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9997e-01],
        [1.0000e+00],
        [1.9907e-04],
        [2.3836e-05],
        [1.0000e+00],
        [9.9976e-01]], grad_fn=<ToCopyBackward0>)
Epoch [70/100], T_AUC: [4m0.8947[0m
Epoch [70/100], Loss: 105.0304
val_Accuracy: [92m0.7084[0m
val_Precision: [4;34m0.8888[0m,               val_Recall: [4;33m0.9520[0m,                 val_F1 Score: [4;35m0.9171[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  736
Epoch [70/100], V_AUC: [4m0.8418[0m
Epoch [71/100], Loss: 0.0246
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [3.1586e-10],
        [3.0058e-04],
        [1.9822e-06],
        [1.0000e+00],
        [9.9998e-01],
        [1.0000e+00],
        [1.0000e+00],
        [8.6172e-08],
        [2.7228e-04],
        [7.3877e-06],
        [1.0225e-04],
        [9.9999e-01],
        [1.0000e+00],
        [3.0415e-05],
        [1.0000e+00],
        [5.3946e-05],
        [7.7824e-05],
        [9.9999e-01],
        [6.2662e-05],
        [3.1186e-04],
        [4.3403e-05],
        [2.7354e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9998e-01],
        [1.0000e+00],
        [1.7672e-04],
        [2.4030e-05],
        [1.0000e+00],
        [9.9975e-01]], grad_fn=<ToCopyBackward0>)
Epoch [71/100], T_AUC: [4m0.8947[0m
Epoch [71/100], Loss: 108.2365
val_Accuracy: [92m0.7084[0m
val_Precision: [4;34m0.8873[0m,               val_Recall: [4;33m0.9538[0m,                 val_F1 Score: [4;35m0.9169[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  736
Epoch [71/100], V_AUC: [4m0.8426[0m
Epoch [72/100], Loss: 0.0234
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.9802e-10],
        [3.1904e-04],
        [1.5195e-06],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.0000e+00],
        [6.2725e-08],
        [2.6921e-04],
        [5.7349e-06],
        [1.0262e-04],
        [9.9999e-01],
        [1.0000e+00],
        [3.2885e-05],
        [1.0000e+00],
        [5.9117e-05],
        [7.0213e-05],
        [9.9999e-01],
        [5.9920e-05],
        [3.0165e-04],
        [3.9903e-05],
        [3.2572e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9998e-01],
        [1.0000e+00],
        [1.6669e-04],
        [2.2791e-05],
        [1.0000e+00],
        [9.9972e-01]], grad_fn=<ToCopyBackward0>)
Epoch [72/100], T_AUC: [4m0.8947[0m
Epoch [72/100], Loss: 111.4822
val_Accuracy: [92m0.7084[0m
val_Precision: [4;34m0.8873[0m,               val_Recall: [4;33m0.9538[0m,                 val_F1 Score: [4;35m0.9169[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  736
Epoch [72/100], V_AUC: [4m0.8426[0m
Epoch [73/100], Loss: 0.0224
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.8055e-10],
        [3.2833e-04],
        [1.2343e-06],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.0000e+00],
        [4.4226e-08],
        [2.7344e-04],
        [4.5232e-06],
        [1.0355e-04],
        [9.9999e-01],
        [1.0000e+00],
        [3.4139e-05],
        [1.0000e+00],
        [6.2704e-05],
        [6.4276e-05],
        [9.9999e-01],
        [5.5659e-05],
        [2.9161e-04],
        [4.0250e-05],
        [4.3302e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.5198e-04],
        [2.3042e-05],
        [1.0000e+00],
        [9.9967e-01]], grad_fn=<ToCopyBackward0>)
Epoch [73/100], T_AUC: [4m0.8947[0m
Epoch [73/100], Loss: 114.7455
val_Accuracy: [92m0.7093[0m
val_Precision: [4;34m0.8892[0m,               val_Recall: [4;33m0.9513[0m,                 val_F1 Score: [4;35m0.9168[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  737
Epoch [73/100], V_AUC: [4m0.8441[0m
Epoch [74/100], Loss: 0.0216
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.6546e-10],
        [3.2635e-04],
        [1.0110e-06],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.0000e+00],
        [3.5761e-08],
        [2.8299e-04],
        [3.4228e-06],
        [1.0653e-04],
        [1.0000e+00],
        [1.0000e+00],
        [3.3952e-05],
        [1.0000e+00],
        [6.5846e-05],
        [6.0656e-05],
        [9.9999e-01],
        [5.2273e-05],
        [2.9298e-04],
        [3.9081e-05],
        [5.4418e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.3483e-04],
        [2.3167e-05],
        [1.0000e+00],
        [9.9966e-01]], grad_fn=<ToCopyBackward0>)
Epoch [74/100], T_AUC: [4m0.8947[0m
Epoch [74/100], Loss: 118.0695
val_Accuracy: [92m0.7064[0m
val_Precision: [4;34m0.8860[0m,               val_Recall: [4;33m0.9520[0m,                 val_F1 Score: [4;35m0.9152[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  734
Epoch [74/100], V_AUC: [4m0.8410[0m
Epoch [75/100], Loss: 0.0208
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.4227e-10],
        [3.1770e-04],
        [7.7957e-07],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.8114e-08],
        [3.0217e-04],
        [2.7566e-06],
        [1.3387e-04],
        [1.0000e+00],
        [1.0000e+00],
        [3.2998e-05],
        [1.0000e+00],
        [6.7859e-05],
        [5.4569e-05],
        [9.9998e-01],
        [4.6938e-05],
        [2.6772e-04],
        [3.8561e-05],
        [7.6090e-05],
        [1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.2229e-04],
        [2.2985e-05],
        [1.0000e+00],
        [9.9961e-01]], grad_fn=<ToCopyBackward0>)
Epoch [75/100], T_AUC: [4m0.8947[0m
Epoch [75/100], Loss: 121.3697
val_Accuracy: [92m0.7093[0m
val_Precision: [4;34m0.8895[0m,               val_Recall: [4;33m0.9538[0m,                 val_F1 Score: [4;35m0.9178[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  737
Epoch [75/100], V_AUC: [4m0.8447[0m
Epoch [76/100], Loss: 0.0203
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.4686e-10],
        [3.1421e-04],
        [6.2674e-07],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.0000e+00],
        [2.0507e-08],
        [2.8918e-04],
        [1.9396e-06],
        [1.4729e-04],
        [1.0000e+00],
        [1.0000e+00],
        [3.2789e-05],
        [1.0000e+00],
        [6.8734e-05],
        [5.0733e-05],
        [9.9998e-01],
        [4.4712e-05],
        [2.6285e-04],
        [3.9626e-05],
        [1.3832e-04],
        [1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.1080e-04],
        [2.2740e-05],
        [1.0000e+00],
        [9.9957e-01]], grad_fn=<ToCopyBackward0>)
Epoch [76/100], T_AUC: [4m0.8947[0m
Epoch [76/100], Loss: 122.1414
val_Accuracy: [92m0.7064[0m
val_Precision: [4;34m0.8863[0m,               val_Recall: [4;33m0.9492[0m,                 val_F1 Score: [4;35m0.9140[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  734
Epoch [76/100], V_AUC: [4m0.8413[0m
Epoch [77/100], Loss: 0.0199
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.2828e-10],
        [3.2395e-04],
        [4.3293e-07],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.5453e-08],
        [2.9263e-04],
        [1.5532e-06],
        [1.7777e-04],
        [1.0000e+00],
        [1.0000e+00],
        [3.1135e-05],
        [1.0000e+00],
        [7.4951e-05],
        [5.0585e-05],
        [9.9997e-01],
        [4.0346e-05],
        [2.4429e-04],
        [3.6508e-05],
        [2.1281e-04],
        [1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [9.2927e-05],
        [2.1677e-05],
        [1.0000e+00],
        [9.9948e-01]], grad_fn=<ToCopyBackward0>)
Epoch [77/100], T_AUC: [4m0.8947[0m
Epoch [77/100], Loss: 125.6056
val_Accuracy: [92m0.7055[0m
val_Precision: [4;34m0.8849[0m,               val_Recall: [4;33m0.9492[0m,                 val_F1 Score: [4;35m0.9131[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  733
Epoch [77/100], V_AUC: [4m0.8402[0m
Epoch [78/100], Loss: 0.0193
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [2.1872e-10],
        [3.2600e-04],
        [3.6538e-07],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [1.0000e+00],
        [1.0629e-08],
        [2.9368e-04],
        [1.0542e-06],
        [1.5070e-04],
        [1.0000e+00],
        [1.0000e+00],
        [2.9830e-05],
        [1.0000e+00],
        [7.4607e-05],
        [4.3677e-05],
        [9.9995e-01],
        [3.6724e-05],
        [2.4690e-04],
        [3.7629e-05],
        [4.0334e-04],
        [1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [9.0434e-05],
        [1.9528e-05],
        [1.0000e+00],
        [9.9953e-01]], grad_fn=<ToCopyBackward0>)
Epoch [78/100], T_AUC: [4m0.8947[0m
Epoch [78/100], Loss: 123.8143
val_Accuracy: [92m0.7064[0m
val_Precision: [4;34m0.8871[0m,               val_Recall: [4;33m0.9473[0m,                 val_F1 Score: [4;35m0.9134[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  734
Epoch [78/100], V_AUC: [4m0.8422[0m
Epoch [79/100], Loss: 0.0191
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.9375e-10],
        [3.6825e-04],
        [2.8739e-07],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [6.5811e-09],
        [2.9748e-04],
        [9.0668e-07],
        [1.3973e-04],
        [1.0000e+00],
        [1.0000e+00],
        [3.0815e-05],
        [1.0000e+00],
        [7.4993e-05],
        [4.9291e-05],
        [9.9993e-01],
        [2.9229e-05],
        [2.1744e-04],
        [3.6027e-05],
        [3.0299e-04],
        [1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [9.0065e-05],
        [1.7510e-05],
        [1.0000e+00],
        [9.9950e-01]], grad_fn=<ToCopyBackward0>)
Epoch [79/100], T_AUC: [4m0.8947[0m
Epoch [79/100], Loss: 124.7178
val_Accuracy: [92m0.7113[0m
val_Precision: [4;34m0.8909[0m,               val_Recall: [4;33m0.9577[0m,                 val_F1 Score: [4;35m0.9202[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  739
Epoch [79/100], V_AUC: [4m0.8477[0m
Epoch [80/100], Loss: 0.0189
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.7765e-10],
        [4.3863e-04],
        [2.1436e-07],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [4.3646e-09],
        [2.7427e-04],
        [6.5630e-07],
        [1.0462e-04],
        [1.0000e+00],
        [1.0000e+00],
        [2.6236e-05],
        [1.0000e+00],
        [6.8081e-05],
        [4.3069e-05],
        [9.9991e-01],
        [2.3136e-05],
        [2.1699e-04],
        [3.5443e-05],
        [6.5367e-04],
        [1.0000e+00],
        [1.0000e+00],
        [9.9999e-01],
        [1.0000e+00],
        [9.5739e-05],
        [1.4058e-05],
        [1.0000e+00],
        [9.9949e-01]], grad_fn=<ToCopyBackward0>)
Epoch [80/100], T_AUC: [4m0.8947[0m
Epoch [80/100], Loss: 128.0838
val_Accuracy: [92m0.7074[0m
val_Precision: [4;34m0.8893[0m,               val_Recall: [4;33m0.9478[0m,                 val_F1 Score: [4;35m0.9146[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  735
Epoch [80/100], V_AUC: [4m0.8439[0m
Epoch [81/100], Loss: 0.0193
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [1.9819e-10],
        [4.4984e-04],
        [1.7074e-07],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.6652e-09],
        [4.2806e-04],
        [3.6409e-07],
        [1.0308e-04],
        [1.0000e+00],
        [1.0000e+00],
        [2.7483e-05],
        [1.0000e+00],
        [7.0458e-05],
        [1.8528e-05],
        [9.9988e-01],
        [6.6302e-05],
        [2.6832e-04],
        [5.4842e-05],
        [9.0247e-04],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [4.4486e-05],
        [1.6479e-05],
        [1.0000e+00],
        [9.9954e-01]], grad_fn=<ToCopyBackward0>)
Epoch [81/100], T_AUC: [4m0.8947[0m
Epoch [81/100], Loss: 129.8231
val_Accuracy: [92m0.7026[0m
val_Precision: [4;34m0.8822[0m,               val_Recall: [4;33m0.9502[0m,                 val_F1 Score: [4;35m0.9118[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  730
Epoch [81/100], V_AUC: [4m0.8374[0m
Epoch [82/100], Loss: 0.0223
train_Accuracy: [91m1.0000[0m
train_Precision: [4;34m0.8947[0m,               train_Recall: [4;33m0.8947[0m,                 train_F1 Score: [4;35m0.8947[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5440
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[1.0000e+00],
        [1.0000e+00],
        [3.6145e-10],
        [1.9631e-04],
        [1.8758e-07],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [2.0486e-09],
        [3.3159e-04],
        [1.6979e-07],
        [7.6006e-05],
        [1.0000e+00],
        [1.0000e+00],
        [1.8026e-05],
        [1.0000e+00],
        [3.0551e-04],
        [2.9188e-05],
        [9.9991e-01],
        [2.6014e-05],
        [1.1104e-04],
        [4.6888e-05],
        [1.9458e-04],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.0000e+00],
        [1.1666e-04],
        [1.0152e-05],
        [1.0000e+00],
        [9.9946e-01]], grad_fn=<ToCopyBackward0>)
Epoch [82/100], T_AUC: [4m0.8947[0m
Epoch [82/100], Loss: 130.2775
val_Accuracy: [92m0.7064[0m
val_Precision: [4;34m0.8918[0m,               val_Recall: [4;33m0.9464[0m,                 val_F1 Score: [4;35m0.9148[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  734
Epoch [82/100], V_AUC: [4m0.8453[0m
Epoch [83/100], Loss: 33.8117
train_Accuracy: [91m0.9807[0m
train_Precision: [4;34m0.8789[0m,               train_Recall: [4;33m0.8817[0m,                 train_F1 Score: [4;35m0.8801[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  5335
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[9.9883e-01],
        [9.7893e-01],
        [3.0792e-05],
        [1.3260e-01],
        [9.3957e-01],
        [9.9961e-01],
        [9.9994e-01],
        [4.7452e-03],
        [6.0545e-01],
        [1.4840e-07],
        [2.3450e-02],
        [7.2046e-02],
        [7.8381e-01],
        [1.0000e+00],
        [9.8851e-01],
        [9.3891e-01],
        [8.8626e-01],
        [9.8187e-01],
        [1.7322e-03],
        [9.0954e-01],
        [1.0000e+00],
        [9.3614e-01],
        [5.4498e-02],
        [3.6196e-02],
        [9.9999e-01],
        [1.6521e-07],
        [1.0000e+00],
        [1.0000e+00],
        [1.4401e-06],
        [3.1955e-01],
        [1.0000e+00],
        [1.0000e+00]], grad_fn=<ToCopyBackward0>)
Epoch [83/100], T_AUC: [4m0.8768[0m
Epoch [83/100], Loss: 238.7981
val_Accuracy: [92m0.4832[0m
val_Precision: [4;34m0.7730[0m,               val_Recall: [4;33m0.2464[0m,                 val_F1 Score: [4;35m0.3643[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  502
Epoch [83/100], V_AUC: [4m0.6488[0m
Epoch [84/100], Loss: 181.2987
train_Accuracy: [91m0.6017[0m
train_Precision: [4;34m0.5585[0m,               train_Recall: [4;33m0.6946[0m,                 train_F1 Score: [4;35m0.6137[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3273
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5754],
        [0.9312],
        [0.6655],
        [0.8335],
        [0.2503],
        [0.8566],
        [0.7555],
        [0.7191],
        [0.9144],
        [0.1730],
        [0.1095],
        [0.1848],
        [0.2925],
        [0.9268],
        [0.6321],
        [0.1003],
        [0.9913],
        [0.7757],
        [0.4737],
        [0.2864],
        [0.3695],
        [0.8056],
        [0.2701],
        [0.0818],
        [0.8913],
        [0.4991],
        [0.8597],
        [0.8645],
        [0.3115],
        [0.2102],
        [0.9343],
        [0.7607]], grad_fn=<ToCopyBackward0>)
Epoch [84/100], T_AUC: [4m0.5154[0m
Epoch [84/100], Loss: 31.4734
val_Accuracy: [92m0.5977[0m
val_Precision: [4;34m0.9969[0m,               val_Recall: [4;33m0.4745[0m,                 val_F1 Score: [4;35m0.6323[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  621
Epoch [84/100], V_AUC: [4m0.7747[0m
Epoch [85/100], Loss: 103.1829
train_Accuracy: [91m0.6542[0m
train_Precision: [4;34m0.5924[0m,               train_Recall: [4;33m0.7372[0m,                 train_F1 Score: [4;35m0.6506[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3559
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5689],
        [0.7005],
        [0.4070],
        [0.6070],
        [0.2702],
        [0.7777],
        [0.7602],
        [0.3499],
        [0.7549],
        [0.2491],
        [0.4257],
        [0.2640],
        [0.4605],
        [0.9091],
        [0.6137],
        [0.2713],
        [0.9060],
        [0.5944],
        [0.3994],
        [0.4537],
        [0.6757],
        [0.6657],
        [0.6210],
        [0.4615],
        [0.6516],
        [0.5695],
        [0.8351],
        [0.9631],
        [0.5144],
        [0.2329],
        [0.9579],
        [0.8587]], grad_fn=<ToCopyBackward0>)
Epoch [85/100], T_AUC: [4m0.5650[0m
Epoch [85/100], Loss: 19.6689
val_Accuracy: [92m0.6400[0m
val_Precision: [4;34m0.7708[0m,               val_Recall: [4;33m1.1114[0m,                 val_F1 Score: [4;35m0.9062[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  665
Epoch [85/100], V_AUC: [4m0.7241[0m
Epoch [86/100], Loss: 97.4814
train_Accuracy: [91m0.6792[0m
train_Precision: [4;34m0.6133[0m,               train_Recall: [4;33m0.7396[0m,                 train_F1 Score: [4;35m0.6644[0m
标签里1的个数:  3100
标签里0的个数:  2340
总数:  5440
正确的个数:  3695
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.2878],
        [0.9493],
        [0.3885],
        [0.7547],
        [0.2765],
        [0.6293],
        [0.8301],
        [0.6672],
        [0.8314],
        [0.2630],
        [0.3979],
        [0.1429],
        [0.6064],
        [0.5024],
        [0.3283],
        [0.2142],
        [0.8749],
        [0.3265],
        [0.3869],
        [0.3361],
        [0.4230],
        [0.5451],
        [0.6256],
        [0.3824],
        [0.9049],
        [0.7118],
        [0.6550],
        [0.9416],
        [0.7072],
        [0.4461],
        [0.9739],
        [0.8345]], grad_fn=<ToCopyBackward0>)
Epoch [86/100], T_AUC: [4m0.5925[0m
Epoch [86/100], Loss: 19.9783
val_Accuracy: [92m0.6410[0m
val_Precision: [4;34m0.7738[0m,               val_Recall: [4;33m1.1023[0m,                 val_F1 Score: [4;35m0.9052[0m
标签里1的个数:  601
标签里0的个数:  438
总数:  1039
正确的个数:  666
