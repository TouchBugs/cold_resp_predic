{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one = pd.read_csv('one_rows.csv', header=None)\n",
    "zero = pd.read_csv('zero_rows.csv', header=None)\n",
    "\n",
    "print(one.shape)\n",
    "print(zero.shape)\n",
    "# 把zero随机删除951行\n",
    "zero = zero.drop(zero.sample(n=951).index)\n",
    "zero.reset_index(drop=True, inplace=True)\n",
    "print(zero.shape)\n",
    "# save csv\n",
    "zero.to_csv('zero_rows_del.csv', index=False, header=False)\n",
    "print('zero')\n",
    "# 从zero随机取2150行\n",
    "zero_t = zero.sample(n=2150)\n",
    "# 获取这些抽取行的索引\n",
    "zero_t_indices = zero_t.index\n",
    "# 删除这些行\n",
    "zero_v = zero.drop(zero_t_indices)\n",
    "print('one')\n",
    "# 从one随机取430行\n",
    "one_t = one.sample(n=2150)\n",
    "# 获取这些抽取行的索引\n",
    "one_t_indices = one_t.index\n",
    "# 删除这些行\n",
    "one_v = one.drop(one_t_indices)\n",
    "print('combine_t')\n",
    "# 交叉合并 zero_t 和 one_t\n",
    "# 创建一个新的 DataFrame，用于交叉合并 zero_t 和 one_t\n",
    "combined_t = pd.DataFrame()\n",
    "\n",
    "# 交替添加 zero_t 和 one_t 的行\n",
    "for i in range(2150):\n",
    "    # print(i)\n",
    "    combined_t = pd.concat([combined_t, zero_t.iloc[[i]]])\n",
    "    combined_t = pd.concat([combined_t, one_t.iloc[[i]]])\n",
    "\n",
    "# 重置索引\n",
    "combined_t = combined_t.reset_index(drop=True)\n",
    "combined_t.to_csv('train.csv', index=False, header=False)\n",
    "print(combined_t.shape)\n",
    "\n",
    "print('combine_v')\n",
    "combined_v = pd.DataFrame()\n",
    "\n",
    "# 交替添加 zero_t 和 one_t 的行\n",
    "for i in range(430):\n",
    "    combined_v = pd.concat([combined_v, zero_v.iloc[[i]]])\n",
    "    combined_v = pd.concat([combined_v, one_v.iloc[[i]]])\n",
    "\n",
    "# 重置索引\n",
    "combined_v = combined_v.reset_index(drop=True)\n",
    "combined_v.to_csv('valid.csv', index=False, header=False)\n",
    "print(combined_v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     2580.000000\n",
      "mean      2771.193023\n",
      "std       2241.240118\n",
      "min        133.000000\n",
      "25%       1254.750000\n",
      "50%       2086.000000\n",
      "75%       3706.000000\n",
      "max      20688.000000\n",
      "Name: 1, dtype: float64\n",
      "count     3531.000000\n",
      "mean      4815.411781\n",
      "std       3124.972060\n",
      "min        139.000000\n",
      "25%       2924.000000\n",
      "50%       4093.000000\n",
      "75%       5745.500000\n",
      "max      46398.000000\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "one = pd.read_csv('one_rows.csv', header=None)\n",
    "zero = pd.read_csv('zero_rows.csv', header=None)\n",
    "\n",
    "print(one[1].apply(str).apply(len).describe())\n",
    "print(zero[1].apply(str).apply(len).describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "排序后的数据已保存到 /Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/sorted_train.csv\n"
     ]
    }
   ],
   "source": [
    "# 对数据从小到大排序\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 读取CSV文件\n",
    "csv_file_path = '/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/train.csv'  # 替换为你的CSV文件路径\n",
    "data = pd.read_csv(csv_file_path, header=None)\n",
    "\n",
    "# 添加一列，计算第二列基因序列的长度\n",
    "data['Sequence_Length'] = data.iloc[:, 1].apply(len)\n",
    "\n",
    "# 按照序列长度排序\n",
    "sorted_data = data.sort_values(by='Sequence_Length')\n",
    "\n",
    "# 删除临时的长度列（可选）\n",
    "sorted_data = sorted_data.drop(columns=['Sequence_Length'])\n",
    "\n",
    "# 保存排序后的数据到一个新的CSV文件\n",
    "sorted_csv_file_path = '/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/sorted_train.csv'  # 替换为你想要保存的文件路径\n",
    "sorted_data.to_csv(sorted_csv_file_path, index=False, header=False)\n",
    "\n",
    "print(f\"排序后的数据已保存到 {sorted_csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Run\tLibraryName\n",
    "SRR22250991\tAt-L0h_rep3\n",
    "SRR22250994\tAt-L0h_rep2\n",
    "SRR22250995\tAt-L0h_rep1\n",
    "SRR22250992\tAt-L168h_rep3\n",
    "SRR22250993\tAt-L168h_rep2\n",
    "SRR22250984\tAt-L168h_rep1\n",
    "SRR22250985\tAt-L24h_rep3\n",
    "SRR22250986\tAt-L24h_rep2\n",
    "SRR22250987\tAt-L24h_rep1\n",
    "SRR22250988\tAt-L2h_rep3\n",
    "SRR22250989\tAt-L2h_rep2\n",
    "SRR22250990\tAt-L2h_rep1\n",
    "SRR17234919\tGm-L0h_rep3\n",
    "SRR17234920\tGm-L0h_rep2\n",
    "SRR17234921\tGm-L0h_rep1\n",
    "SRR17200395\tGm-L168h_rep3\n",
    "SRR17200396\tGm-L168h_rep2\n",
    "SRR17200397\tGm-L168h_rep1\n",
    "SRR17200398\tGm-L24h_rep3\n",
    "SRR17200399\tGm-L24h_rep2\n",
    "SRR17200400\tGm-L24h_rep1\n",
    "SRR17200401\tGm-L2h_rep3\n",
    "SRR17200402\tGm-L2h_rep2\n",
    "SRR17200342\tGm-L2h_rep1\n",
    "SRR17151213\tOs-L0h_rep3\n",
    "SRR17151216\tOs-L0h_rep2\n",
    "SRR17151217\tOs-L0h_rep1\n",
    "SRR17151214\tOs-L168h_rep3\n",
    "SRR17151215\tOs-L168h_rep2\n",
    "SRR17151206\tOs-L168h_rep1\n",
    "SRR17151207\tOs-L24h_rep3\n",
    "SRR17151208\tOs-L24h_rep2\n",
    "SRR17151209\tOs-L24h_rep1\n",
    "SRR17151210\tOs-L2h_rep3\n",
    "SRR17151211\tOs-L2h_rep2\n",
    "SRR17151212\tOs-L2h_rep1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLpy3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
