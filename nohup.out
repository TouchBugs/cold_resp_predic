nohup: ignoring input
2024-06-21-22:46:25
不冻排序残差
创建模型实例
模型实例创建完成
加载预训练参数
预训练参数加载完成
Epoch [1/100], Loss: 62.6865
train_Accuracy: [91m0.7930[0m
train_Precision: [4;34m0.8051[0m,               train_Recall: [4;33m0.7850[0m,                 train_F1 Score: [4;35m0.7885[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3410
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8476],
        [0.9406],
        [0.9452],
        [0.0759],
        [0.8654],
        [0.3584],
        [0.2914],
        [0.3669],
        [0.4122],
        [0.8463],
        [0.0695],
        [0.0379]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 29), 1)
((1, 30), 1)
((2, 20), 1)
((3, 28), 1)
((4, 31), 1)
((5, 29), 1)
((6, 28), 1)
((7, 27), 1)
((8, 30), 1)
((9, 23), 1)
((10, 24), 1)
((11, 23), 1)
((12, 25), 1)
((13, 30), 1)
((14, 19), 1)
((15, 23), 1)
((16, 28), 1)
((17, 29), 1)
((18, 8), 1)
((19, 29), 1)
((20, 31), 1)
((21, 27), 1)
((22, 31), 1)
((23, 30), 1)
((24, 27), 1)
((25, 29), 1)
((26, 22), 1)
Epoch [1/100], Loss: 16.8167
val_Accuracy: [92m0.7767[0m
val_Precision: [4;34m0.8605[0m,               val_Recall: [4;33m0.6521[0m,                 val_F1 Score: [4;35m0.7363[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  668
Epoch [2/100], Loss: 60.5679
train_Accuracy: [91m0.8026[0m
train_Precision: [4;34m0.8155[0m,               train_Recall: [4;33m0.7925[0m,                 train_F1 Score: [4;35m0.7976[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3451
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8577],
        [0.9608],
        [0.9009],
        [0.0573],
        [0.8268],
        [0.3384],
        [0.4130],
        [0.2522],
        [0.5863],
        [0.8157],
        [0.0795],
        [0.0481]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 31), 1)
((1, 31), 1)
((2, 29), 1)
((3, 31), 1)
((4, 3), 1)
((5, 31), 1)
((6, 30), 1)
((7, 30), 1)
((8, 9), 1)
((9, 24), 1)
((10, 14), 1)
((11, 30), 1)
((12, 30), 1)
((13, 24), 1)
((14, 30), 1)
((15, 31), 1)
((16, 31), 1)
((17, 31), 1)
((18, 28), 1)
((19, 28), 1)
((20, 29), 1)
((21, 28), 1)
((22, 19), 1)
((23, 28), 1)
((24, 31), 1)
((25, 2), 1)
((26, 24), 1)
Epoch [2/100], Loss: 25.6020
val_Accuracy: [92m0.6500[0m
val_Precision: [4;34m0.8829[0m,               val_Recall: [4;33m0.3420[0m,                 val_F1 Score: [4;35m0.4804[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  559
Epoch [3/100], Loss: 59.7152
train_Accuracy: [91m0.8074[0m
train_Precision: [4;34m0.8255[0m,               train_Recall: [4;33m0.7914[0m,                 train_F1 Score: [4;35m0.8020[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3472
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8338],
        [0.9546],
        [0.8729],
        [0.0655],
        [0.8618],
        [0.3948],
        [0.3617],
        [0.1694],
        [0.6134],
        [0.8638],
        [0.0866],
        [0.0644]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 24), 1)
((1, 16), 1)
((2, 18), 1)
((2, 18), 1)
((4, 1), 1)
((5, 9), 1)
((6, 27), 1)
((7, 22), 1)
((7, 22), 1)
((9, 31), 1)
((9, 31), 1)
((11, 0), 1)
((11, 0), 1)
((13, 4), 1)
((13, 4), 1)
((15, 11), 1)
((16, 13), 1)
((16, 13), 1)
((18, 29), 1)
((18, 29), 1)
((20, 25), 1)
((21, 26), 1)
((22, 25), 1)
((23, 31), 1)
((24, 24), 1)
((25, 11), 1)
((26, 3), 1)
Epoch [3/100], Loss: 13.4105
val_Accuracy: [92m0.7942[0m
val_Precision: [4;34m0.8216[0m,               val_Recall: [4;33m0.7368[0m,                 val_F1 Score: [4;35m0.7705[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  683
Epoch [4/100], Loss: 60.7023
train_Accuracy: [91m0.8040[0m
train_Precision: [4;34m0.8242[0m,               train_Recall: [4;33m0.7842[0m,                 train_F1 Score: [4;35m0.7976[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3457
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7729],
        [0.9547],
        [0.9182],
        [0.1157],
        [0.8559],
        [0.2474],
        [0.2887],
        [0.2280],
        [0.4978],
        [0.8722],
        [0.1257],
        [0.0565]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((26, 3), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
((15, 9), 1)
Epoch [4/100], Loss: 19.4004
val_Accuracy: [92m0.7256[0m
val_Precision: [4;34m0.8812[0m,               val_Recall: [4;33m0.5255[0m,                 val_F1 Score: [4;35m0.6478[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  624
Epoch [5/100], Loss: 59.3838
train_Accuracy: [91m0.8088[0m
train_Precision: [4;34m0.8259[0m,               train_Recall: [4;33m0.7934[0m,                 train_F1 Score: [4;35m0.8035[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3478
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8547],
        [0.9575],
        [0.9462],
        [0.0878],
        [0.8519],
        [0.2448],
        [0.3459],
        [0.2553],
        [0.4789],
        [0.8019],
        [0.1161],
        [0.0406]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 0), 1)
((0, 0), 1)
((0, 0), 1)
((0, 0), 1)
((0, 0), 1)
((0, 0), 1)
((0, 0), 1)
((0, 0), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
((8, 31), 1)
Epoch [5/100], Loss: 14.4351
val_Accuracy: [92m0.7965[0m
val_Precision: [4;34m0.8375[0m,               val_Recall: [4;33m0.7306[0m,                 val_F1 Score: [4;35m0.7753[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  685
Epoch [6/100], Loss: 58.6008
train_Accuracy: [91m0.8093[0m
train_Precision: [4;34m0.8228[0m,               train_Recall: [4;33m0.7997[0m,                 train_F1 Score: [4;35m0.8051[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3480
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8742],
        [0.9422],
        [0.9087],
        [0.0723],
        [0.8635],
        [0.2195],
        [0.5237],
        [0.1598],
        [0.5775],
        [0.8715],
        [0.1302],
        [0.0342]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 8), 1)
((0, 8), 1)
((2, 22), 1)
((2, 22), 1)
((4, 11), 1)
((4, 11), 1)
((4, 11), 1)
((4, 11), 1)
((4, 11), 1)
((4, 11), 1)
((4, 11), 1)
((4, 11), 1)
((12, 26), 1)
((13, 27), 1)
((13, 27), 1)
((13, 27), 1)
((13, 27), 1)
((13, 27), 1)
((18, 18), 1)
((18, 18), 1)
((18, 18), 1)
((18, 18), 1)
((22, 27), 1)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
Epoch [6/100], Loss: 13.3778
val_Accuracy: [92m0.7919[0m
val_Precision: [4;34m0.8207[0m,               val_Recall: [4;33m0.7359[0m,                 val_F1 Score: [4;35m0.7707[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  681
Epoch [7/100], Loss: 58.8157
train_Accuracy: [91m0.8100[0m
train_Precision: [4;34m0.8231[0m,               train_Recall: [4;33m0.7997[0m,                 train_F1 Score: [4;35m0.8054[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3483
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8329],
        [0.9519],
        [0.9159],
        [0.0919],
        [0.8543],
        [0.2305],
        [0.4208],
        [0.1131],
        [0.4750],
        [0.9051],
        [0.1049],
        [0.0723]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
((23, 12), 1)
((8, 19), 1)
((8, 19), 1)
((8, 19), 1)
((8, 19), 1)
((8, 19), 1)
((8, 19), 1)
((8, 19), 1)
((8, 19), 1)
((8, 19), 1)
((8, 19), 1)
((8, 19), 1)
((19, 26), 1)
((19, 26), 1)
((19, 26), 1)
((19, 26), 1)
((19, 26), 1)
((19, 26), 1)
((19, 26), 1)
((19, 26), 1)
Epoch [7/100], Loss: 13.7674
val_Accuracy: [92m0.7826[0m
val_Precision: [4;34m0.8444[0m,               val_Recall: [4;33m0.6853[0m,                 val_F1 Score: [4;35m0.7499[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  673
Epoch [8/100], Loss: 59.1957
train_Accuracy: [91m0.8086[0m
train_Precision: [4;34m0.8225[0m,               train_Recall: [4;33m0.7971[0m,                 train_F1 Score: [4;35m0.8040[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3477
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7659],
        [0.9621],
        [0.9214],
        [0.0723],
        [0.7879],
        [0.3148],
        [0.3936],
        [0.1974],
        [0.4040],
        [0.8856],
        [0.1190],
        [0.0785]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((19, 26), 1)
((19, 26), 1)
((19, 26), 1)
((19, 26), 1)
((19, 26), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
((5, 13), 1)
Epoch [8/100], Loss: 14.3607
val_Accuracy: [92m0.7860[0m
val_Precision: [4;34m0.8594[0m,               val_Recall: [4;33m0.6817[0m,                 val_F1 Score: [4;35m0.7536[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  676
Epoch [9/100], Loss: 58.2852
train_Accuracy: [91m0.8121[0m
train_Precision: [4;34m0.8238[0m,               train_Recall: [4;33m0.8040[0m,                 train_F1 Score: [4;35m0.8085[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3492
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7161],
        [0.9618],
        [0.9059],
        [0.0657],
        [0.8388],
        [0.2172],
        [0.6399],
        [0.1722],
        [0.5485],
        [0.9028],
        [0.0615],
        [0.0610]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 26), 1)
((1, 26), 1)
((2, 26), 1)
((3, 29), 1)
((4, 28), 1)
((5, 27), 1)
((6, 31), 1)
((7, 25), 1)
((8, 28), 1)
((9, 28), 1)
((10, 31), 1)
((11, 31), 1)
((12, 31), 1)
((13, 31), 1)
((14, 28), 1)
((15, 30), 1)
((16, 30), 1)
((17, 27), 1)
((18, 26), 1)
((19, 25), 1)
((20, 30), 1)
((21, 30), 1)
((22, 30), 1)
((23, 26), 1)
((24, 30), 1)
((25, 30), 1)
((26, 13), 1)
Epoch [9/100], Loss: 35.4404
val_Accuracy: [92m0.6174[0m
val_Precision: [4;34m0.5717[0m,               val_Recall: [4;33m0.9496[0m,                 val_F1 Score: [4;35m0.7097[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  531
Epoch [10/100], Loss: 57.7779
train_Accuracy: [91m0.8186[0m
train_Precision: [4;34m0.8266[0m,               train_Recall: [4;33m0.8146[0m,                 train_F1 Score: [4;35m0.8154[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3520
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7156],
        [0.9536],
        [0.9012],
        [0.0712],
        [0.7349],
        [0.3867],
        [0.5210],
        [0.1553],
        [0.6875],
        [0.8687],
        [0.0646],
        [0.0784]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 13), 1)
((26, 13), 1)
((26, 13), 1)
((26, 13), 1)
((4, 2), 1)
((4, 2), 1)
((4, 2), 1)
((4, 2), 1)
((4, 2), 1)
((4, 2), 1)
((4, 2), 1)
((4, 2), 1)
((4, 2), 1)
((4, 2), 1)
((4, 2), 1)
((15, 4), 1)
((15, 4), 1)
((15, 4), 1)
((15, 4), 1)
((15, 4), 1)
((15, 4), 1)
((15, 4), 1)
((15, 4), 1)
((23, 2), 1)
((23, 2), 1)
((23, 2), 1)
((23, 2), 1)
Epoch [10/100], Loss: 17.6565
val_Accuracy: [92m0.7337[0m
val_Precision: [4;34m0.9016[0m,               val_Recall: [4;33m0.5319[0m,                 val_F1 Score: [4;35m0.6608[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  631
Epoch [11/100], Loss: 57.3245
train_Accuracy: [91m0.8228[0m
train_Precision: [4;34m0.8366[0m,               train_Recall: [4;33m0.8109[0m,                 train_F1 Score: [4;35m0.8187[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3538
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7722],
        [0.9328],
        [0.8170],
        [0.0722],
        [0.8094],
        [0.1702],
        [0.7124],
        [0.2619],
        [0.6139],
        [0.9166],
        [0.0771],
        [0.0662]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((23, 2), 1)
((23, 2), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
Epoch [11/100], Loss: 14.9397
val_Accuracy: [92m0.7744[0m
val_Precision: [4;34m0.8673[0m,               val_Recall: [4;33m0.6427[0m,                 val_F1 Score: [4;35m0.7304[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  666
Epoch [12/100], Loss: 57.5179
train_Accuracy: [91m0.8226[0m
train_Precision: [4;34m0.8412[0m,               train_Recall: [4;33m0.8072[0m,                 train_F1 Score: [4;35m0.8184[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3537
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6999],
        [0.9461],
        [0.9314],
        [0.0548],
        [0.6920],
        [0.3513],
        [0.5916],
        [0.1616],
        [0.6701],
        [0.9009],
        [0.0681],
        [0.0754]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
Epoch [12/100], Loss: 14.9678
val_Accuracy: [92m0.7791[0m
val_Precision: [4;34m0.8682[0m,               val_Recall: [4;33m0.6552[0m,                 val_F1 Score: [4;35m0.7391[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  670
Epoch [13/100], Loss: 57.2780
train_Accuracy: [91m0.8177[0m
train_Precision: [4;34m0.8288[0m,               train_Recall: [4;33m0.8158[0m,                 train_F1 Score: [4;35m0.8160[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3516
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6546],
        [0.9624],
        [0.9268],
        [0.0607],
        [0.8198],
        [0.1622],
        [0.6331],
        [0.1905],
        [0.5609],
        [0.8663],
        [0.0610],
        [0.1019]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
Epoch [13/100], Loss: 15.3342
val_Accuracy: [92m0.7756[0m
val_Precision: [4;34m0.8759[0m,               val_Recall: [4;33m0.6382[0m,                 val_F1 Score: [4;35m0.7310[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  667
Epoch [14/100], Loss: 56.5298
train_Accuracy: [91m0.8188[0m
train_Precision: [4;34m0.8333[0m,               train_Recall: [4;33m0.8069[0m,                 train_F1 Score: [4;35m0.8143[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3521
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6598],
        [0.9437],
        [0.8857],
        [0.1006],
        [0.7946],
        [0.1058],
        [0.5505],
        [0.1149],
        [0.5199],
        [0.9458],
        [0.2539],
        [0.0733]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((2, 19), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
Epoch [14/100], Loss: 15.4285
val_Accuracy: [92m0.7802[0m
val_Precision: [4;34m0.8787[0m,               val_Recall: [4;33m0.6472[0m,                 val_F1 Score: [4;35m0.7358[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  671
Epoch [15/100], Loss: 56.7148
train_Accuracy: [91m0.8191[0m
train_Precision: [4;34m0.8313[0m,               train_Recall: [4;33m0.8110[0m,                 train_F1 Score: [4;35m0.8154[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3522
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8045],
        [0.9572],
        [0.9184],
        [0.1068],
        [0.8177],
        [0.1353],
        [0.4446],
        [0.2540],
        [0.3913],
        [0.9300],
        [0.0525],
        [0.0774]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 1)
((9, 29), 2)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
((10, 16), 1)
Epoch [15/100], Loss: 19.1680
val_Accuracy: [92m0.7593[0m
val_Precision: [4;34m0.8905[0m,               val_Recall: [4;33m0.5956[0m,                 val_F1 Score: [4;35m0.7041[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  653
Epoch [16/100], Loss: 58.4065
train_Accuracy: [91m0.8105[0m
train_Precision: [4;34m0.8191[0m,               train_Recall: [4;33m0.8085[0m,                 train_F1 Score: [4;35m0.8073[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3485
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7359],
        [0.9258],
        [0.4960],
        [0.2274],
        [0.7091],
        [0.3333],
        [0.6083],
        [0.2253],
        [0.4578],
        [0.7081],
        [0.2567],
        [0.1093]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 28), 1)
((1, 9), 1)
((2, 31), 1)
((3, 30), 1)
((4, 30), 1)
((5, 18), 1)
((5, 18), 1)
((7, 28), 1)
((8, 21), 1)
((9, 25), 1)
((10, 17), 1)
((11, 28), 1)
((12, 19), 1)
((13, 23), 1)
((14, 29), 1)
((15, 25), 1)
((16, 29), 1)
((17, 5), 1)
((18, 31), 1)
((19, 31), 1)
((20, 16), 1)
((21, 20), 1)
((22, 18), 1)
((23, 19), 1)
((24, 23), 1)
((25, 21), 1)
((26, 23), 1)
Epoch [16/100], Loss: 56.6469
val_Accuracy: [92m0.5535[0m
val_Precision: [4;34m0.8302[0m,               val_Recall: [4;33m0.1260[0m,                 val_F1 Score: [4;35m0.2131[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  476
Epoch [17/100], Loss: 65.2773
train_Accuracy: [91m0.7812[0m
train_Precision: [4;34m0.7998[0m,               train_Recall: [4;33m0.7617[0m,                 train_F1 Score: [4;35m0.7734[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3359
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8209],
        [0.9418],
        [0.8314],
        [0.0635],
        [0.7573],
        [0.3869],
        [0.6401],
        [0.1998],
        [0.4933],
        [0.8645],
        [0.0828],
        [0.1391]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
Epoch [17/100], Loss: 15.4106
val_Accuracy: [92m0.7779[0m
val_Precision: [4;34m0.8810[0m,               val_Recall: [4;33m0.6432[0m,                 val_F1 Score: [4;35m0.7352[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  669
Epoch [18/100], Loss: 61.8408
train_Accuracy: [91m0.8007[0m
train_Precision: [4;34m0.8209[0m,               train_Recall: [4;33m0.7802[0m,                 train_F1 Score: [4;35m0.7937[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3443
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6190],
        [0.9398],
        [0.9645],
        [0.2310],
        [0.8341],
        [0.2645],
        [0.4376],
        [0.2810],
        [0.1133],
        [0.8759],
        [0.1592],
        [0.0603]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
Epoch [18/100], Loss: 18.0508
val_Accuracy: [92m0.7326[0m
val_Precision: [4;34m0.8844[0m,               val_Recall: [4;33m0.5387[0m,                 val_F1 Score: [4;35m0.6611[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  630
Epoch [19/100], Loss: 62.9906
train_Accuracy: [91m0.7865[0m
train_Precision: [4;34m0.8083[0m,               train_Recall: [4;33m0.7659[0m,                 train_F1 Score: [4;35m0.7796[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3382
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7470],
        [0.9713],
        [0.9078],
        [0.1166],
        [0.7871],
        [0.3511],
        [0.4083],
        [0.2238],
        [0.1225],
        [0.8814],
        [0.1755],
        [0.1195]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
((26, 23), 1)
Epoch [19/100], Loss: 15.8150
val_Accuracy: [92m0.7651[0m
val_Precision: [4;34m0.8606[0m,               val_Recall: [4;33m0.6414[0m,                 val_F1 Score: [4;35m0.7247[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  658
Epoch [20/100], Loss: 62.7922
train_Accuracy: [91m0.7905[0m
train_Precision: [4;34m0.8134[0m,               train_Recall: [4;33m0.7683[0m,                 train_F1 Score: [4;35m0.7831[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3399
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7769],
        [0.9190],
        [0.8880],
        [0.0827],
        [0.8895],
        [0.4819],
        [0.5498],
        [0.1499],
        [0.3304],
        [0.8650],
        [0.1738],
        [0.0628]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 23), 1)
((1, 15), 1)
((2, 28), 1)
((3, 11), 1)
((4, 24), 1)
((5, 22), 1)
((6, 29), 1)
((7, 29), 1)
((8, 27), 1)
((9, 30), 1)
((10, 30), 1)
((11, 29), 1)
((12, 28), 1)
((13, 26), 1)
((14, 26), 1)
((15, 14), 1)
((16, 20), 1)
((17, 19), 1)
((18, 22), 1)
((19, 30), 1)
((20, 27), 1)
((21, 31), 1)
((22, 16), 1)
((23, 29), 1)
((24, 29), 1)
((25, 31), 1)
((26, 27), 1)
Epoch [20/100], Loss: 41.7906
val_Accuracy: [92m0.5000[0m
val_Precision: [4;34m0.5005[0m,               val_Recall: [4;33m1.0000[0m,                 val_F1 Score: [4;35m0.6637[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  430
Epoch [21/100], Loss: 62.2181
train_Accuracy: [91m0.7981[0m
train_Precision: [4;34m0.8209[0m,               train_Recall: [4;33m0.7749[0m,                 train_F1 Score: [4;35m0.7905[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3432
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8801],
        [0.8965],
        [0.8853],
        [0.0778],
        [0.8681],
        [0.3277],
        [0.4291],
        [0.2175],
        [0.4765],
        [0.8073],
        [0.2398],
        [0.0609]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
((26, 27), 1)
Epoch [21/100], Loss: 13.9521
val_Accuracy: [92m0.7884[0m
val_Precision: [4;34m0.8461[0m,               val_Recall: [4;33m0.6986[0m,                 val_F1 Score: [4;35m0.7583[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  678
Epoch [22/100], Loss: 60.9801
train_Accuracy: [91m0.8012[0m
train_Precision: [4;34m0.8194[0m,               train_Recall: [4;33m0.7827[0m,                 train_F1 Score: [4;35m0.7951[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3445
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8127],
        [0.9653],
        [0.8565],
        [0.0836],
        [0.8654],
        [0.2342],
        [0.6051],
        [0.1991],
        [0.4485],
        [0.8412],
        [0.1420],
        [0.0600]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((0, 24), 1)
((1, 18), 1)
((2, 21), 1)
((3, 19), 1)
((3, 19), 1)
((5, 25), 1)
((6, 11), 1)
((7, 31), 1)
((8, 29), 1)
((9, 16), 1)
((10, 29), 1)
((11, 4), 1)
((11, 4), 1)
((13, 19), 1)
((14, 31), 1)
((15, 24), 1)
((16, 9), 1)
((17, 21), 1)
((18, 30), 1)
((19, 15), 1)
((20, 17), 1)
((21, 6), 1)
((22, 21), 1)
((23, 21), 1)
((24, 5), 1)
((25, 10), 1)
((26, 26), 1)
Epoch [22/100], Loss: 159.5403
val_Accuracy: [92m0.6012[0m
val_Precision: [4;34m0.7174[0m,               val_Recall: [4;33m0.3244[0m,                 val_F1 Score: [4;35m0.4382[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  517
Epoch [23/100], Loss: 59.1926
train_Accuracy: [91m0.8098[0m
train_Precision: [4;34m0.8257[0m,               train_Recall: [4;33m0.7959[0m,                 train_F1 Score: [4;35m0.8047[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3482
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7455],
        [0.9721],
        [0.8850],
        [0.0786],
        [0.8200],
        [0.1663],
        [0.6091],
        [0.1723],
        [0.4132],
        [0.8352],
        [0.1986],
        [0.0885]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [23/100], Loss: 18.4523
val_Accuracy: [92m0.7221[0m
val_Precision: [4;34m0.8972[0m,               val_Recall: [4;33m0.5022[0m,                 val_F1 Score: [4;35m0.6342[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  621
Epoch [24/100], Loss: 58.5899
train_Accuracy: [91m0.8151[0m
train_Precision: [4;34m0.8277[0m,               train_Recall: [4;33m0.8068[0m,                 train_F1 Score: [4;35m0.8116[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3505
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8626],
        [0.9236],
        [0.8638],
        [0.0209],
        [0.7277],
        [0.2405],
        [0.7497],
        [0.1896],
        [0.5282],
        [0.8553],
        [0.1159],
        [0.2134]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [24/100], Loss: 14.0699
val_Accuracy: [92m0.7663[0m
val_Precision: [4;34m0.7461[0m,               val_Recall: [4;33m0.7948[0m,                 val_F1 Score: [4;35m0.7647[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  659
Epoch [25/100], Loss: 58.2806
train_Accuracy: [91m0.8114[0m
train_Precision: [4;34m0.8244[0m,               train_Recall: [4;33m0.8016[0m,                 train_F1 Score: [4;35m0.8073[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3489
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8059],
        [0.9686],
        [0.8833],
        [0.1109],
        [0.7573],
        [0.2027],
        [0.7268],
        [0.1576],
        [0.3277],
        [0.8937],
        [0.1779],
        [0.0290]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [25/100], Loss: 15.5610
val_Accuracy: [92m0.7721[0m
val_Precision: [4;34m0.8783[0m,               val_Recall: [4;33m0.6285[0m,                 val_F1 Score: [4;35m0.7244[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  664
Epoch [26/100], Loss: 57.1285
train_Accuracy: [91m0.8149[0m
train_Precision: [4;34m0.8325[0m,               train_Recall: [4;33m0.7992[0m,                 train_F1 Score: [4;35m0.8099[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3504
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8876],
        [0.9423],
        [0.9103],
        [0.0875],
        [0.8756],
        [0.1419],
        [0.4678],
        [0.1980],
        [0.3285],
        [0.8471],
        [0.1082],
        [0.1294]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [26/100], Loss: 14.8622
val_Accuracy: [92m0.7407[0m
val_Precision: [4;34m0.7033[0m,               val_Recall: [4;33m0.8143[0m,                 val_F1 Score: [4;35m0.7510[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  637
Epoch [27/100], Loss: 57.6339
train_Accuracy: [91m0.8142[0m
train_Precision: [4;34m0.8276[0m,               train_Recall: [4;33m0.8020[0m,                 train_F1 Score: [4;35m0.8092[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3501
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8059],
        [0.9584],
        [0.8891],
        [0.0556],
        [0.7357],
        [0.1306],
        [0.6265],
        [0.1721],
        [0.5129],
        [0.8999],
        [0.1172],
        [0.1669]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [27/100], Loss: 13.6129
val_Accuracy: [92m0.7744[0m
val_Precision: [4;34m0.7626[0m,               val_Recall: [4;33m0.7853[0m,                 val_F1 Score: [4;35m0.7687[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  666
Epoch [28/100], Loss: 55.5866
train_Accuracy: [91m0.8226[0m
train_Precision: [4;34m0.8326[0m,               train_Recall: [4;33m0.8151[0m,                 train_F1 Score: [4;35m0.8188[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3537
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8924],
        [0.9635],
        [0.8552],
        [0.0212],
        [0.8305],
        [0.1098],
        [0.8455],
        [0.1454],
        [0.6053],
        [0.7538],
        [0.1582],
        [0.1223]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [28/100], Loss: 13.6952
val_Accuracy: [92m0.7802[0m
val_Precision: [4;34m0.7827[0m,               val_Recall: [4;33m0.7659[0m,                 val_F1 Score: [4;35m0.7687[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  671
Epoch [29/100], Loss: 56.1815
train_Accuracy: [91m0.8165[0m
train_Precision: [4;34m0.8298[0m,               train_Recall: [4;33m0.8048[0m,                 train_F1 Score: [4;35m0.8119[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3511
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8755],
        [0.9555],
        [0.7897],
        [0.0277],
        [0.8238],
        [0.1268],
        [0.7151],
        [0.1155],
        [0.6834],
        [0.8167],
        [0.1393],
        [0.1780]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [29/100], Loss: 14.1557
val_Accuracy: [92m0.7837[0m
val_Precision: [4;34m0.8305[0m,               val_Recall: [4;33m0.7088[0m,                 val_F1 Score: [4;35m0.7596[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  674
Epoch [30/100], Loss: 56.3237
train_Accuracy: [91m0.8191[0m
train_Precision: [4;34m0.8324[0m,               train_Recall: [4;33m0.8058[0m,                 train_F1 Score: [4;35m0.8134[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3522
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8690],
        [0.9631],
        [0.8246],
        [0.0137],
        [0.7691],
        [0.5333],
        [0.6747],
        [0.0897],
        [0.5139],
        [0.8067],
        [0.1570],
        [0.1799]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [30/100], Loss: 13.9288
val_Accuracy: [92m0.7895[0m
val_Precision: [4;34m0.8423[0m,               val_Recall: [4;33m0.7073[0m,                 val_F1 Score: [4;35m0.7640[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  679
Epoch [31/100], Loss: 55.4261
train_Accuracy: [91m0.8242[0m
train_Precision: [4;34m0.8363[0m,               train_Recall: [4;33m0.8137[0m,                 train_F1 Score: [4;35m0.8195[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3544
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8278],
        [0.9578],
        [0.9210],
        [0.0133],
        [0.8448],
        [0.1465],
        [0.7238],
        [0.1282],
        [0.4055],
        [0.8657],
        [0.1710],
        [0.1875]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [31/100], Loss: 14.5617
val_Accuracy: [92m0.7535[0m
val_Precision: [4;34m0.7243[0m,               val_Recall: [4;33m0.8058[0m,                 val_F1 Score: [4;35m0.7593[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  648
Epoch [32/100], Loss: 56.7223
train_Accuracy: [91m0.8198[0m
train_Precision: [4;34m0.8322[0m,               train_Recall: [4;33m0.8101[0m,                 train_F1 Score: [4;35m0.8158[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3525
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8215],
        [0.9468],
        [0.8782],
        [0.0389],
        [0.6031],
        [0.3370],
        [0.7032],
        [0.2643],
        [0.2733],
        [0.8654],
        [0.4020],
        [0.0417]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [32/100], Loss: 13.8957
val_Accuracy: [92m0.7837[0m
val_Precision: [4;34m0.7814[0m,               val_Recall: [4;33m0.7804[0m,                 val_F1 Score: [4;35m0.7754[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  674
Epoch [33/100], Loss: 56.3386
train_Accuracy: [91m0.8188[0m
train_Precision: [4;34m0.8363[0m,               train_Recall: [4;33m0.8036[0m,                 train_F1 Score: [4;35m0.8142[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3521
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9084],
        [0.9618],
        [0.9016],
        [0.0288],
        [0.8690],
        [0.1686],
        [0.4752],
        [0.2034],
        [0.2478],
        [0.8609],
        [0.1366],
        [0.1842]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [33/100], Loss: 13.8729
val_Accuracy: [92m0.7686[0m
val_Precision: [4;34m0.7769[0m,               val_Recall: [4;33m0.7496[0m,                 val_F1 Score: [4;35m0.7563[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  661
Epoch [34/100], Loss: 55.3660
train_Accuracy: [91m0.8212[0m
train_Precision: [4;34m0.8338[0m,               train_Recall: [4;33m0.8111[0m,                 train_F1 Score: [4;35m0.8170[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3531
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8288],
        [0.9666],
        [0.8395],
        [0.0207],
        [0.8036],
        [0.1019],
        [0.4600],
        [0.1940],
        [0.4292],
        [0.9210],
        [0.2046],
        [0.2213]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [34/100], Loss: 13.9923
val_Accuracy: [92m0.7826[0m
val_Precision: [4;34m0.8250[0m,               val_Recall: [4;33m0.7085[0m,                 val_F1 Score: [4;35m0.7569[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  673
Epoch [35/100], Loss: 55.9707
train_Accuracy: [91m0.8209[0m
train_Precision: [4;34m0.8371[0m,               train_Recall: [4;33m0.8043[0m,                 train_F1 Score: [4;35m0.8156[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3530
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8790],
        [0.9785],
        [0.8982],
        [0.0444],
        [0.6575],
        [0.0801],
        [0.6322],
        [0.3248],
        [0.6162],
        [0.8492],
        [0.1045],
        [0.1592]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
Epoch [35/100], Loss: 14.8472
val_Accuracy: [92m0.7930[0m
val_Precision: [4;34m0.8550[0m,               val_Recall: [4;33m0.7013[0m,                 val_F1 Score: [4;35m0.7658[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  682
Epoch [36/100], Loss: 54.8246
train_Accuracy: [91m0.8235[0m
train_Precision: [4;34m0.8359[0m,               train_Recall: [4;33m0.8119[0m,                 train_F1 Score: [4;35m0.8189[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3541
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9545],
        [0.9765],
        [0.8367],
        [0.0345],
        [0.8267],
        [0.1449],
        [0.4552],
        [0.1120],
        [0.5345],
        [0.8037],
        [0.1360],
        [0.1199]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((26, 26), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((11, 25), 1)
((26, 25), 1)
Epoch [36/100], Loss: 183.9409
val_Accuracy: [92m0.5209[0m
val_Precision: [4;34m0.5370[0m,               val_Recall: [4;33m0.0457[0m,                 val_F1 Score: [4;35m0.0832[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  448
Epoch [37/100], Loss: 55.3549
train_Accuracy: [91m0.8216[0m
train_Precision: [4;34m0.8393[0m,               train_Recall: [4;33m0.8052[0m,                 train_F1 Score: [4;35m0.8159[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3533
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8706],
        [0.9640],
        [0.9614],
        [0.0453],
        [0.7161],
        [0.2615],
        [0.4334],
        [0.3064],
        [0.4449],
        [0.8363],
        [0.0863],
        [0.0643]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [37/100], Loss: 14.6389
val_Accuracy: [92m0.7849[0m
val_Precision: [4;34m0.8131[0m,               val_Recall: [4;33m0.7406[0m,                 val_F1 Score: [4;35m0.7672[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  675
Epoch [38/100], Loss: 55.9374
train_Accuracy: [91m0.8160[0m
train_Precision: [4;34m0.8258[0m,               train_Recall: [4;33m0.8107[0m,                 train_F1 Score: [4;35m0.8124[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3509
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6531],
        [0.9645],
        [0.9484],
        [0.0175],
        [0.5819],
        [0.1489],
        [0.6791],
        [0.2767],
        [0.6349],
        [0.8801],
        [0.1431],
        [0.1259]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [38/100], Loss: 17.4396
val_Accuracy: [92m0.7477[0m
val_Precision: [4;34m0.8643[0m,               val_Recall: [4;33m0.5846[0m,                 val_F1 Score: [4;35m0.6894[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  643
Epoch [39/100], Loss: 54.7072
train_Accuracy: [91m0.8258[0m
train_Precision: [4;34m0.8390[0m,               train_Recall: [4;33m0.8136[0m,                 train_F1 Score: [4;35m0.8209[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3551
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8484],
        [0.9870],
        [0.9134],
        [0.0909],
        [0.7391],
        [0.1352],
        [0.5444],
        [0.2372],
        [0.2179],
        [0.8380],
        [0.0796],
        [0.1092]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [39/100], Loss: 14.9800
val_Accuracy: [92m0.7802[0m
val_Precision: [4;34m0.8265[0m,               val_Recall: [4;33m0.7042[0m,                 val_F1 Score: [4;35m0.7537[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  671
Epoch [40/100], Loss: 54.2056
train_Accuracy: [91m0.8330[0m
train_Precision: [4;34m0.8438[0m,               train_Recall: [4;33m0.8254[0m,                 train_F1 Score: [4;35m0.8288[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3582
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7864],
        [0.9581],
        [0.7633],
        [0.0213],
        [0.9097],
        [0.3098],
        [0.5674],
        [0.3207],
        [0.5067],
        [0.9067],
        [0.0775],
        [0.0833]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [40/100], Loss: 15.1764
val_Accuracy: [92m0.7721[0m
val_Precision: [4;34m0.8095[0m,               val_Recall: [4;33m0.7011[0m,                 val_F1 Score: [4;35m0.7453[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  664
Epoch [41/100], Loss: 55.5770
train_Accuracy: [91m0.8202[0m
train_Precision: [4;34m0.8338[0m,               train_Recall: [4;33m0.8091[0m,                 train_F1 Score: [4;35m0.8157[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3527
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8209],
        [0.9802],
        [0.7790],
        [0.0212],
        [0.8976],
        [0.1290],
        [0.6500],
        [0.1909],
        [0.6781],
        [0.7582],
        [0.0685],
        [0.2638]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [41/100], Loss: 13.8317
val_Accuracy: [92m0.7709[0m
val_Precision: [4;34m0.8002[0m,               val_Recall: [4;33m0.7171[0m,                 val_F1 Score: [4;35m0.7504[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  663
Epoch [42/100], Loss: 53.5261
train_Accuracy: [91m0.8291[0m
train_Precision: [4;34m0.8414[0m,               train_Recall: [4;33m0.8213[0m,                 train_F1 Score: [4;35m0.8253[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3565
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8557],
        [0.9864],
        [0.6288],
        [0.0236],
        [0.9371],
        [0.1310],
        [0.5900],
        [0.1553],
        [0.5943],
        [0.8156],
        [0.1307],
        [0.1270]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [42/100], Loss: 14.7215
val_Accuracy: [92m0.7709[0m
val_Precision: [4;34m0.8396[0m,               val_Recall: [4;33m0.6705[0m,                 val_F1 Score: [4;35m0.7374[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  663
Epoch [43/100], Loss: 58.0754
train_Accuracy: [91m0.8163[0m
train_Precision: [4;34m0.8336[0m,               train_Recall: [4;33m0.8018[0m,                 train_F1 Score: [4;35m0.8111[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3510
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7153],
        [0.9745],
        [0.9041],
        [0.0723],
        [0.8502],
        [0.2751],
        [0.5512],
        [0.2670],
        [0.3600],
        [0.9262],
        [0.0822],
        [0.0513]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [43/100], Loss: 14.9695
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.7341[0m,               val_Recall: [4;33m0.7751[0m,                 val_F1 Score: [4;35m0.7490[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [44/100], Loss: 58.3615
train_Accuracy: [91m0.8093[0m
train_Precision: [4;34m0.8239[0m,               train_Recall: [4;33m0.7983[0m,                 train_F1 Score: [4;35m0.8046[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3480
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8119],
        [0.9654],
        [0.9527],
        [0.0303],
        [0.7916],
        [0.2535],
        [0.5106],
        [0.1596],
        [0.4468],
        [0.8191],
        [0.1503],
        [0.1590]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [44/100], Loss: 14.5798
val_Accuracy: [92m0.7698[0m
val_Precision: [4;34m0.7595[0m,               val_Recall: [4;33m0.7879[0m,                 val_F1 Score: [4;35m0.7678[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  662
Epoch [45/100], Loss: 57.1003
train_Accuracy: [91m0.8149[0m
train_Precision: [4;34m0.8283[0m,               train_Recall: [4;33m0.8028[0m,                 train_F1 Score: [4;35m0.8098[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3504
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7646],
        [0.9685],
        [0.9166],
        [0.0702],
        [0.8433],
        [0.3156],
        [0.4011],
        [0.3417],
        [0.2990],
        [0.8375],
        [0.0284],
        [0.2703]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [45/100], Loss: 15.5976
val_Accuracy: [92m0.7709[0m
val_Precision: [4;34m0.8612[0m,               val_Recall: [4;33m0.6483[0m,                 val_F1 Score: [4;35m0.7288[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  663
Epoch [46/100], Loss: 60.0200
train_Accuracy: [91m0.8009[0m
train_Precision: [4;34m0.8158[0m,               train_Recall: [4;33m0.7894[0m,                 train_F1 Score: [4;35m0.7959[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3444
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9016],
        [0.9396],
        [0.9584],
        [0.0748],
        [0.8613],
        [0.1072],
        [0.4826],
        [0.2848],
        [0.4135],
        [0.7864],
        [0.0893],
        [0.1037]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [46/100], Loss: 15.9809
val_Accuracy: [92m0.7616[0m
val_Precision: [4;34m0.8817[0m,               val_Recall: [4;33m0.6126[0m,                 val_F1 Score: [4;35m0.7120[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  655
Epoch [47/100], Loss: 59.4644
train_Accuracy: [91m0.8047[0m
train_Precision: [4;34m0.8223[0m,               train_Recall: [4;33m0.7885[0m,                 train_F1 Score: [4;35m0.7993[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3460
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8916],
        [0.9562],
        [0.8682],
        [0.1070],
        [0.8947],
        [0.2137],
        [0.4348],
        [0.3141],
        [0.4096],
        [0.7629],
        [0.0926],
        [0.0805]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [47/100], Loss: 15.2447
val_Accuracy: [92m0.7488[0m
val_Precision: [4;34m0.8421[0m,               val_Recall: [4;33m0.6146[0m,                 val_F1 Score: [4;35m0.7025[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  644
Epoch [48/100], Loss: 57.1627
train_Accuracy: [91m0.8109[0m
train_Precision: [4;34m0.8221[0m,               train_Recall: [4;33m0.8043[0m,                 train_F1 Score: [4;35m0.8070[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3487
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9553],
        [0.9698],
        [0.9032],
        [0.0429],
        [0.6025],
        [0.0788],
        [0.4095],
        [0.2064],
        [0.4148],
        [0.8836],
        [0.1243],
        [0.2480]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [48/100], Loss: 14.5015
val_Accuracy: [92m0.7744[0m
val_Precision: [4;34m0.8186[0m,               val_Recall: [4;33m0.6961[0m,                 val_F1 Score: [4;35m0.7457[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  666
Epoch [49/100], Loss: 57.6933
train_Accuracy: [91m0.8130[0m
train_Precision: [4;34m0.8251[0m,               train_Recall: [4;33m0.8032[0m,                 train_F1 Score: [4;35m0.8084[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3496
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8578],
        [0.9691],
        [0.9253],
        [0.1117],
        [0.7740],
        [0.4822],
        [0.4920],
        [0.3271],
        [0.3523],
        [0.6570],
        [0.0287],
        [0.1214]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [49/100], Loss: 14.4137
val_Accuracy: [92m0.7465[0m
val_Precision: [4;34m0.7119[0m,               val_Recall: [4;33m0.8140[0m,                 val_F1 Score: [4;35m0.7562[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  642
Epoch [50/100], Loss: 59.6283
train_Accuracy: [91m0.8105[0m
train_Precision: [4;34m0.8267[0m,               train_Recall: [4;33m0.7953[0m,                 train_F1 Score: [4;35m0.8050[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3485
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9582],
        [0.9336],
        [0.8740],
        [0.0672],
        [0.9341],
        [0.2273],
        [0.4872],
        [0.3097],
        [0.3599],
        [0.5661],
        [0.1578],
        [0.0704]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [50/100], Loss: 14.6920
val_Accuracy: [92m0.7733[0m
val_Precision: [4;34m0.8361[0m,               val_Recall: [4;33m0.6796[0m,                 val_F1 Score: [4;35m0.7408[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  665
Epoch [51/100], Loss: 56.0802
train_Accuracy: [91m0.8205[0m
train_Precision: [4;34m0.8264[0m,               train_Recall: [4;33m0.8164[0m,                 train_F1 Score: [4;35m0.8159[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3528
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9452],
        [0.9522],
        [0.9572],
        [0.0339],
        [0.8060],
        [0.1275],
        [0.5120],
        [0.1685],
        [0.4560],
        [0.7219],
        [0.0598],
        [0.2451]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [51/100], Loss: 15.0375
val_Accuracy: [92m0.7767[0m
val_Precision: [4;34m0.8531[0m,               val_Recall: [4;33m0.6737[0m,                 val_F1 Score: [4;35m0.7451[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  668
Epoch [52/100], Loss: 58.1830
train_Accuracy: [91m0.8121[0m
train_Precision: [4;34m0.8246[0m,               train_Recall: [4;33m0.8015[0m,                 train_F1 Score: [4;35m0.8072[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3492
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9672],
        [0.8876],
        [0.9411],
        [0.0240],
        [0.9047],
        [0.2470],
        [0.5526],
        [0.3175],
        [0.3002],
        [0.7315],
        [0.1187],
        [0.0796]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [52/100], Loss: 14.4802
val_Accuracy: [92m0.7709[0m
val_Precision: [4;34m0.7839[0m,               val_Recall: [4;33m0.7369[0m,                 val_F1 Score: [4;35m0.7547[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  663
Epoch [53/100], Loss: 56.4357
train_Accuracy: [91m0.8188[0m
train_Precision: [4;34m0.8262[0m,               train_Recall: [4;33m0.8126[0m,                 train_F1 Score: [4;35m0.8142[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3521
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8677],
        [0.9338],
        [0.9461],
        [0.1170],
        [0.8581],
        [0.1991],
        [0.5591],
        [0.3411],
        [0.3409],
        [0.6710],
        [0.0910],
        [0.0515]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [53/100], Loss: 15.6332
val_Accuracy: [92m0.7558[0m
val_Precision: [4;34m0.8612[0m,               val_Recall: [4;33m0.6092[0m,                 val_F1 Score: [4;35m0.7066[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  650
Epoch [54/100], Loss: 56.7278
train_Accuracy: [91m0.8186[0m
train_Precision: [4;34m0.8360[0m,               train_Recall: [4;33m0.8044[0m,                 train_F1 Score: [4;35m0.8143[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3520
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8718],
        [0.9505],
        [0.9088],
        [0.0300],
        [0.7022],
        [0.3476],
        [0.1722],
        [0.2482],
        [0.6289],
        [0.9390],
        [0.1541],
        [0.1015]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [54/100], Loss: 13.2485
val_Accuracy: [92m0.7686[0m
val_Precision: [4;34m0.7782[0m,               val_Recall: [4;33m0.7404[0m,                 val_F1 Score: [4;35m0.7535[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  661
Epoch [55/100], Loss: 56.9527
train_Accuracy: [91m0.8179[0m
train_Precision: [4;34m0.8270[0m,               train_Recall: [4;33m0.8105[0m,                 train_F1 Score: [4;35m0.8138[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3517
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7705],
        [0.9838],
        [0.9223],
        [0.0530],
        [0.8443],
        [0.2047],
        [0.5468],
        [0.1529],
        [0.2589],
        [0.8945],
        [0.1350],
        [0.0834]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [55/100], Loss: 14.5210
val_Accuracy: [92m0.7826[0m
val_Precision: [4;34m0.8559[0m,               val_Recall: [4;33m0.6780[0m,                 val_F1 Score: [4;35m0.7474[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  673
Epoch [56/100], Loss: 55.4019
train_Accuracy: [91m0.8270[0m
train_Precision: [4;34m0.8369[0m,               train_Recall: [4;33m0.8234[0m,                 train_F1 Score: [4;35m0.8241[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3556
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9369],
        [0.9457],
        [0.9014],
        [0.0434],
        [0.8753],
        [0.1233],
        [0.3923],
        [0.1947],
        [0.5317],
        [0.8653],
        [0.2071],
        [0.0641]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [56/100], Loss: 13.7191
val_Accuracy: [92m0.7942[0m
val_Precision: [4;34m0.7953[0m,               val_Recall: [4;33m0.7838[0m,                 val_F1 Score: [4;35m0.7837[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  683
Epoch [57/100], Loss: 55.3688
train_Accuracy: [91m0.8230[0m
train_Precision: [4;34m0.8325[0m,               train_Recall: [4;33m0.8171[0m,                 train_F1 Score: [4;35m0.8197[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3539
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9065],
        [0.9814],
        [0.8618],
        [0.2471],
        [0.7358],
        [0.0887],
        [0.2916],
        [0.2197],
        [0.6119],
        [0.8255],
        [0.0723],
        [0.0971]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [57/100], Loss: 15.4242
val_Accuracy: [92m0.7523[0m
val_Precision: [4;34m0.8865[0m,               val_Recall: [4;33m0.5844[0m,                 val_F1 Score: [4;35m0.6937[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  647
Epoch [58/100], Loss: 58.7494
train_Accuracy: [91m0.8109[0m
train_Precision: [4;34m0.8258[0m,               train_Recall: [4;33m0.7988[0m,                 train_F1 Score: [4;35m0.8063[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3487
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7550],
        [0.8917],
        [0.9403],
        [0.0643],
        [0.8946],
        [0.2796],
        [0.5816],
        [0.3107],
        [0.3996],
        [0.9134],
        [0.0552],
        [0.0998]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [58/100], Loss: 15.6786
val_Accuracy: [92m0.7407[0m
val_Precision: [4;34m0.8676[0m,               val_Recall: [4;33m0.5708[0m,                 val_F1 Score: [4;35m0.6807[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  637
Epoch [59/100], Loss: 57.9804
train_Accuracy: [91m0.8158[0m
train_Precision: [4;34m0.8292[0m,               train_Recall: [4;33m0.8026[0m,                 train_F1 Score: [4;35m0.8106[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3508
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9145],
        [0.9150],
        [0.9310],
        [0.1107],
        [0.6702],
        [0.1376],
        [0.3601],
        [0.2351],
        [0.5774],
        [0.9049],
        [0.0554],
        [0.2322]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [59/100], Loss: 13.9372
val_Accuracy: [92m0.7709[0m
val_Precision: [4;34m0.7567[0m,               val_Recall: [4;33m0.7887[0m,                 val_F1 Score: [4;35m0.7692[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  663
Epoch [60/100], Loss: 56.9887
train_Accuracy: [91m0.8128[0m
train_Precision: [4;34m0.8250[0m,               train_Recall: [4;33m0.8025[0m,                 train_F1 Score: [4;35m0.8077[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3495
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8969],
        [0.8673],
        [0.9277],
        [0.0861],
        [0.8968],
        [0.0976],
        [0.5088],
        [0.2598],
        [0.4233],
        [0.8180],
        [0.0822],
        [0.1807]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [60/100], Loss: 13.6656
val_Accuracy: [92m0.7733[0m
val_Precision: [4;34m0.7728[0m,               val_Recall: [4;33m0.7640[0m,                 val_F1 Score: [4;35m0.7629[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  665
Epoch [61/100], Loss: 58.3463
train_Accuracy: [91m0.8077[0m
train_Precision: [4;34m0.8242[0m,               train_Recall: [4;33m0.7922[0m,                 train_F1 Score: [4;35m0.8021[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3473
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8020],
        [0.9337],
        [0.9499],
        [0.1349],
        [0.9248],
        [0.2266],
        [0.3668],
        [0.3527],
        [0.2624],
        [0.7857],
        [0.0498],
        [0.1468]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [61/100], Loss: 17.6181
val_Accuracy: [92m0.7349[0m
val_Precision: [4;34m0.8829[0m,               val_Recall: [4;33m0.5412[0m,                 val_F1 Score: [4;35m0.6638[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  632
Epoch [62/100], Loss: 59.3270
train_Accuracy: [91m0.8084[0m
train_Precision: [4;34m0.8257[0m,               train_Recall: [4;33m0.7920[0m,                 train_F1 Score: [4;35m0.8030[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3476
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8084],
        [0.8964],
        [0.9519],
        [0.0915],
        [0.8778],
        [0.1500],
        [0.5144],
        [0.2034],
        [0.4250],
        [0.9080],
        [0.0660],
        [0.1538]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [62/100], Loss: 14.7139
val_Accuracy: [92m0.7547[0m
val_Precision: [4;34m0.7191[0m,               val_Recall: [4;33m0.8235[0m,                 val_F1 Score: [4;35m0.7633[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  649
Epoch [63/100], Loss: 57.8659
train_Accuracy: [91m0.8177[0m
train_Precision: [4;34m0.8368[0m,               train_Recall: [4;33m0.8002[0m,                 train_F1 Score: [4;35m0.8127[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3516
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7495],
        [0.9101],
        [0.9383],
        [0.0822],
        [0.9017],
        [0.3018],
        [0.4744],
        [0.2206],
        [0.4330],
        [0.8939],
        [0.0368],
        [0.1875]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [63/100], Loss: 15.5217
val_Accuracy: [92m0.7302[0m
val_Precision: [4;34m0.6896[0m,               val_Recall: [4;33m0.8366[0m,                 val_F1 Score: [4;35m0.7506[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  628
Epoch [64/100], Loss: 57.9177
train_Accuracy: [91m0.8177[0m
train_Precision: [4;34m0.8343[0m,               train_Recall: [4;33m0.8024[0m,                 train_F1 Score: [4;35m0.8126[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3516
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.4623],
        [0.9580],
        [0.9328],
        [0.1675],
        [0.9008],
        [0.3581],
        [0.4862],
        [0.1588],
        [0.3155],
        [0.9098],
        [0.0734],
        [0.1136]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [64/100], Loss: 13.7082
val_Accuracy: [92m0.7651[0m
val_Precision: [4;34m0.7472[0m,               val_Recall: [4;33m0.7972[0m,                 val_F1 Score: [4;35m0.7672[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  658
Epoch [65/100], Loss: 56.9781
train_Accuracy: [91m0.8151[0m
train_Precision: [4;34m0.8255[0m,               train_Recall: [4;33m0.8068[0m,                 train_F1 Score: [4;35m0.8108[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3505
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8040],
        [0.9711],
        [0.8869],
        [0.0301],
        [0.8325],
        [0.2108],
        [0.6437],
        [0.3787],
        [0.4388],
        [0.9145],
        [0.0751],
        [0.0726]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [65/100], Loss: 14.1388
val_Accuracy: [92m0.7744[0m
val_Precision: [4;34m0.7764[0m,               val_Recall: [4;33m0.7628[0m,                 val_F1 Score: [4;35m0.7652[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  666
Epoch [66/100], Loss: 57.3066
train_Accuracy: [91m0.8151[0m
train_Precision: [4;34m0.8302[0m,               train_Recall: [4;33m0.8001[0m,                 train_F1 Score: [4;35m0.8101[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3505
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6190],
        [0.9738],
        [0.9219],
        [0.0482],
        [0.8159],
        [0.2960],
        [0.4620],
        [0.1646],
        [0.3962],
        [0.9202],
        [0.1544],
        [0.1406]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [66/100], Loss: 13.5566
val_Accuracy: [92m0.7860[0m
val_Precision: [4;34m0.8076[0m,               val_Recall: [4;33m0.7433[0m,                 val_F1 Score: [4;35m0.7691[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  676
Epoch [67/100], Loss: 57.3363
train_Accuracy: [91m0.8179[0m
train_Precision: [4;34m0.8311[0m,               train_Recall: [4;33m0.8059[0m,                 train_F1 Score: [4;35m0.8128[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3517
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8108],
        [0.9195],
        [0.9373],
        [0.1324],
        [0.8445],
        [0.2848],
        [0.4771],
        [0.1447],
        [0.4568],
        [0.9293],
        [0.0472],
        [0.1429]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [67/100], Loss: 14.5713
val_Accuracy: [92m0.7535[0m
val_Precision: [4;34m0.7218[0m,               val_Recall: [4;33m0.8125[0m,                 val_F1 Score: [4;35m0.7607[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  648
Epoch [68/100], Loss: 55.5441
train_Accuracy: [91m0.8242[0m
train_Precision: [4;34m0.8397[0m,               train_Recall: [4;33m0.8117[0m,                 train_F1 Score: [4;35m0.8195[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3544
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5797],
        [0.9410],
        [0.9360],
        [0.0420],
        [0.8805],
        [0.2893],
        [0.4505],
        [0.1871],
        [0.5529],
        [0.9432],
        [0.0438],
        [0.2322]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [68/100], Loss: 13.5795
val_Accuracy: [92m0.7767[0m
val_Precision: [4;34m0.7806[0m,               val_Recall: [4;33m0.7566[0m,                 val_F1 Score: [4;35m0.7649[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  668
Epoch [69/100], Loss: 56.1099
train_Accuracy: [91m0.8181[0m
train_Precision: [4;34m0.8289[0m,               train_Recall: [4;33m0.8110[0m,                 train_F1 Score: [4;35m0.8148[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3518
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7565],
        [0.9645],
        [0.9012],
        [0.0291],
        [0.8839],
        [0.3531],
        [0.6525],
        [0.2099],
        [0.2519],
        [0.9336],
        [0.0648],
        [0.1429]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [69/100], Loss: 17.8922
val_Accuracy: [92m0.7698[0m
val_Precision: [4;34m0.7881[0m,               val_Recall: [4;33m0.7366[0m,                 val_F1 Score: [4;35m0.7554[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  662
Epoch [70/100], Loss: 56.5512
train_Accuracy: [91m0.8170[0m
train_Precision: [4;34m0.8291[0m,               train_Recall: [4;33m0.8093[0m,                 train_F1 Score: [4;35m0.8132[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3513
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5115],
        [0.9530],
        [0.8854],
        [0.1198],
        [0.9071],
        [0.2418],
        [0.6637],
        [0.1480],
        [0.4600],
        [0.9456],
        [0.0267],
        [0.1842]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [70/100], Loss: 14.1408
val_Accuracy: [92m0.7826[0m
val_Precision: [4;34m0.8096[0m,               val_Recall: [4;33m0.7299[0m,                 val_F1 Score: [4;35m0.7624[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  673
Epoch [71/100], Loss: 54.4299
train_Accuracy: [91m0.8277[0m
train_Precision: [4;34m0.8432[0m,               train_Recall: [4;33m0.8159[0m,                 train_F1 Score: [4;35m0.8233[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3559
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7004],
        [0.9511],
        [0.9366],
        [0.0395],
        [0.8593],
        [0.1785],
        [0.7055],
        [0.1879],
        [0.3594],
        [0.9098],
        [0.0719],
        [0.2360]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [71/100], Loss: 14.2565
val_Accuracy: [92m0.7430[0m
val_Precision: [4;34m0.7063[0m,               val_Recall: [4;33m0.8303[0m,                 val_F1 Score: [4;35m0.7585[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  639
Epoch [72/100], Loss: 54.9793
train_Accuracy: [91m0.8198[0m
train_Precision: [4;34m0.8306[0m,               train_Recall: [4;33m0.8100[0m,                 train_F1 Score: [4;35m0.8155[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3525
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7451],
        [0.9035],
        [0.9348],
        [0.0814],
        [0.7225],
        [0.1907],
        [0.7142],
        [0.1293],
        [0.4660],
        [0.9396],
        [0.0771],
        [0.1927]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [72/100], Loss: 13.6825
val_Accuracy: [92m0.7930[0m
val_Precision: [4;34m0.7946[0m,               val_Recall: [4;33m0.7864[0m,                 val_F1 Score: [4;35m0.7854[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  682
Epoch [73/100], Loss: 54.8184
train_Accuracy: [91m0.8209[0m
train_Precision: [4;34m0.8303[0m,               train_Recall: [4;33m0.8142[0m,                 train_F1 Score: [4;35m0.8172[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3530
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8377],
        [0.9426],
        [0.9176],
        [0.0406],
        [0.8292],
        [0.2429],
        [0.7008],
        [0.1536],
        [0.4917],
        [0.9143],
        [0.0487],
        [0.1642]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [73/100], Loss: 15.0205
val_Accuracy: [92m0.7407[0m
val_Precision: [4;34m0.7017[0m,               val_Recall: [4;33m0.8238[0m,                 val_F1 Score: [4;35m0.7535[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  637
Epoch [74/100], Loss: 54.1084
train_Accuracy: [91m0.8258[0m
train_Precision: [4;34m0.8338[0m,               train_Recall: [4;33m0.8223[0m,                 train_F1 Score: [4;35m0.8228[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3551
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5261],
        [0.9582],
        [0.9331],
        [0.1059],
        [0.8650],
        [0.1440],
        [0.5636],
        [0.1300],
        [0.5394],
        [0.9557],
        [0.0512],
        [0.1282]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [74/100], Loss: 14.4968
val_Accuracy: [92m0.7826[0m
val_Precision: [4;34m0.8483[0m,               val_Recall: [4;33m0.6888[0m,                 val_F1 Score: [4;35m0.7520[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  673
Epoch [75/100], Loss: 53.8958
train_Accuracy: [91m0.8270[0m
train_Precision: [4;34m0.8387[0m,               train_Recall: [4;33m0.8193[0m,                 train_F1 Score: [4;35m0.8236[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3556
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7368],
        [0.9637],
        [0.9190],
        [0.0268],
        [0.7147],
        [0.2245],
        [0.4764],
        [0.1308],
        [0.4684],
        [0.9757],
        [0.1053],
        [0.1743]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [75/100], Loss: 15.0474
val_Accuracy: [92m0.7826[0m
val_Precision: [4;34m0.8441[0m,               val_Recall: [4;33m0.6854[0m,                 val_F1 Score: [4;35m0.7491[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  673
Epoch [76/100], Loss: 53.5451
train_Accuracy: [91m0.8305[0m
train_Precision: [4;34m0.8417[0m,               train_Recall: [4;33m0.8223[0m,                 train_F1 Score: [4;35m0.8265[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3571
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7474],
        [0.9352],
        [0.8955],
        [0.0382],
        [0.6957],
        [0.1003],
        [0.6883],
        [0.1595],
        [0.4545],
        [0.9796],
        [0.0855],
        [0.2258]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [76/100], Loss: 13.8005
val_Accuracy: [92m0.7709[0m
val_Precision: [4;34m0.7682[0m,               val_Recall: [4;33m0.7641[0m,                 val_F1 Score: [4;35m0.7607[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  663
Epoch [77/100], Loss: 53.5356
train_Accuracy: [91m0.8293[0m
train_Precision: [4;34m0.8402[0m,               train_Recall: [4;33m0.8227[0m,                 train_F1 Score: [4;35m0.8259[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3566
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7327],
        [0.9534],
        [0.9560],
        [0.0284],
        [0.8788],
        [0.0967],
        [0.5946],
        [0.1279],
        [0.5011],
        [0.9213],
        [0.1029],
        [0.2184]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [77/100], Loss: 13.6950
val_Accuracy: [92m0.7919[0m
val_Precision: [4;34m0.7962[0m,               val_Recall: [4;33m0.7780[0m,                 val_F1 Score: [4;35m0.7827[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  681
Epoch [78/100], Loss: 52.1805
train_Accuracy: [91m0.8323[0m
train_Precision: [4;34m0.8428[0m,               train_Recall: [4;33m0.8265[0m,                 train_F1 Score: [4;35m0.8287[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3579
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7865],
        [0.9720],
        [0.9197],
        [0.0660],
        [0.8960],
        [0.0872],
        [0.5301],
        [0.1410],
        [0.4605],
        [0.8961],
        [0.1090],
        [0.1302]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [78/100], Loss: 13.8348
val_Accuracy: [92m0.7698[0m
val_Precision: [4;34m0.7546[0m,               val_Recall: [4;33m0.7941[0m,                 val_F1 Score: [4;35m0.7684[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  662
Epoch [79/100], Loss: 51.1703
train_Accuracy: [91m0.8379[0m
train_Precision: [4;34m0.8458[0m,               train_Recall: [4;33m0.8349[0m,                 train_F1 Score: [4;35m0.8353[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3603
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8146],
        [0.9716],
        [0.8643],
        [0.0601],
        [0.9038],
        [0.0682],
        [0.6163],
        [0.1888],
        [0.3684],
        [0.9638],
        [0.0782],
        [0.0695]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [79/100], Loss: 16.0017
val_Accuracy: [92m0.7663[0m
val_Precision: [4;34m0.8277[0m,               val_Recall: [4;33m0.6693[0m,                 val_F1 Score: [4;35m0.7339[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  659
Epoch [80/100], Loss: 51.3629
train_Accuracy: [91m0.8351[0m
train_Precision: [4;34m0.8429[0m,               train_Recall: [4;33m0.8346[0m,                 train_F1 Score: [4;35m0.8326[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3591
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6350],
        [0.9659],
        [0.9316],
        [0.0508],
        [0.9555],
        [0.1667],
        [0.6501],
        [0.1733],
        [0.2065],
        [0.9624],
        [0.0916],
        [0.0513]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [80/100], Loss: 16.1267
val_Accuracy: [92m0.7721[0m
val_Precision: [4;34m0.8171[0m,               val_Recall: [4;33m0.6943[0m,                 val_F1 Score: [4;35m0.7451[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  664
Epoch [81/100], Loss: 51.8885
train_Accuracy: [91m0.8302[0m
train_Precision: [4;34m0.8385[0m,               train_Recall: [4;33m0.8278[0m,                 train_F1 Score: [4;35m0.8270[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3570
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8354],
        [0.9778],
        [0.9079],
        [0.0741],
        [0.9148],
        [0.0989],
        [0.6252],
        [0.0728],
        [0.4481],
        [0.9182],
        [0.0341],
        [0.1388]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [81/100], Loss: 14.0616
val_Accuracy: [92m0.7733[0m
val_Precision: [4;34m0.7761[0m,               val_Recall: [4;33m0.7530[0m,                 val_F1 Score: [4;35m0.7601[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  665
Epoch [82/100], Loss: 50.6089
train_Accuracy: [91m0.8347[0m
train_Precision: [4;34m0.8421[0m,               train_Recall: [4;33m0.8333[0m,                 train_F1 Score: [4;35m0.8322[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3589
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8699],
        [0.9618],
        [0.8994],
        [0.0542],
        [0.8478],
        [0.1229],
        [0.6050],
        [0.1743],
        [0.5009],
        [0.9634],
        [0.0883],
        [0.0277]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [82/100], Loss: 17.9103
val_Accuracy: [92m0.7360[0m
val_Precision: [4;34m0.8544[0m,               val_Recall: [4;33m0.5698[0m,                 val_F1 Score: [4;35m0.6736[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  633
Epoch [83/100], Loss: 51.6076
train_Accuracy: [91m0.8333[0m
train_Precision: [4;34m0.8442[0m,               train_Recall: [4;33m0.8238[0m,                 train_F1 Score: [4;35m0.8292[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3583
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9028],
        [0.8890],
        [0.9013],
        [0.0716],
        [0.8041],
        [0.1371],
        [0.6867],
        [0.1545],
        [0.7343],
        [0.9727],
        [0.0116],
        [0.1378]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [83/100], Loss: 14.8418
val_Accuracy: [92m0.7872[0m
val_Precision: [4;34m0.8194[0m,               val_Recall: [4;33m0.7305[0m,                 val_F1 Score: [4;35m0.7660[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  677
Epoch [84/100], Loss: 50.9365
train_Accuracy: [91m0.8363[0m
train_Precision: [4;34m0.8391[0m,               train_Recall: [4;33m0.8405[0m,                 train_F1 Score: [4;35m0.8344[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3596
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7700],
        [0.9728],
        [0.9344],
        [0.0239],
        [0.7985],
        [0.1225],
        [0.5093],
        [0.2098],
        [0.6213],
        [0.9429],
        [0.0383],
        [0.2556]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [84/100], Loss: 15.7738
val_Accuracy: [92m0.7628[0m
val_Precision: [4;34m0.8454[0m,               val_Recall: [4;33m0.6351[0m,                 val_F1 Score: [4;35m0.7198[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  656
Epoch [85/100], Loss: 51.3665
train_Accuracy: [91m0.8372[0m
train_Precision: [4;34m0.8427[0m,               train_Recall: [4;33m0.8369[0m,                 train_F1 Score: [4;35m0.8345[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3600
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8679],
        [0.9625],
        [0.9142],
        [0.0689],
        [0.8447],
        [0.2161],
        [0.6609],
        [0.0914],
        [0.4872],
        [0.9159],
        [0.0357],
        [0.1120]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [85/100], Loss: 15.0988
val_Accuracy: [92m0.7570[0m
val_Precision: [4;34m0.7471[0m,               val_Recall: [4;33m0.7787[0m,                 val_F1 Score: [4;35m0.7566[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  651
Epoch [86/100], Loss: 49.1547
train_Accuracy: [91m0.8430[0m
train_Precision: [4;34m0.8507[0m,               train_Recall: [4;33m0.8410[0m,                 train_F1 Score: [4;35m0.8400[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3625
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8937],
        [0.9521],
        [0.9114],
        [0.0617],
        [0.8536],
        [0.0786],
        [0.5572],
        [0.2014],
        [0.3686],
        [0.9647],
        [0.0472],
        [0.1074]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [86/100], Loss: 14.7161
val_Accuracy: [92m0.7837[0m
val_Precision: [4;34m0.8315[0m,               val_Recall: [4;33m0.7169[0m,                 val_F1 Score: [4;35m0.7608[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  674
Epoch [87/100], Loss: 49.9005
train_Accuracy: [91m0.8409[0m
train_Precision: [4;34m0.8510[0m,               train_Recall: [4;33m0.8370[0m,                 train_F1 Score: [4;35m0.8385[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3616
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8161],
        [0.9748],
        [0.9587],
        [0.1001],
        [0.8670],
        [0.0595],
        [0.5272],
        [0.0759],
        [0.5254],
        [0.9561],
        [0.0579],
        [0.0905]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [87/100], Loss: 15.6925
val_Accuracy: [92m0.7733[0m
val_Precision: [4;34m0.8515[0m,               val_Recall: [4;33m0.6560[0m,                 val_F1 Score: [4;35m0.7330[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  665
Epoch [88/100], Loss: 55.8435
train_Accuracy: [91m0.8198[0m
train_Precision: [4;34m0.8335[0m,               train_Recall: [4;33m0.8096[0m,                 train_F1 Score: [4;35m0.8155[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3525
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5571],
        [0.9630],
        [0.8626],
        [0.0624],
        [0.8603],
        [0.2795],
        [0.5712],
        [0.3526],
        [0.5062],
        [0.8823],
        [0.0691],
        [0.1249]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [88/100], Loss: 14.5221
val_Accuracy: [92m0.7721[0m
val_Precision: [4;34m0.8148[0m,               val_Recall: [4;33m0.6971[0m,                 val_F1 Score: [4;35m0.7445[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  664
Epoch [89/100], Loss: 60.2285
train_Accuracy: [91m0.7984[0m
train_Precision: [4;34m0.8146[0m,               train_Recall: [4;33m0.7844[0m,                 train_F1 Score: [4;35m0.7928[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3433
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8240],
        [0.9606],
        [0.7552],
        [0.1030],
        [0.8120],
        [0.2939],
        [0.5810],
        [0.1620],
        [0.4734],
        [0.9009],
        [0.2211],
        [0.0394]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [89/100], Loss: 15.0201
val_Accuracy: [92m0.7895[0m
val_Precision: [4;34m0.8221[0m,               val_Recall: [4;33m0.7338[0m,                 val_F1 Score: [4;35m0.7688[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  679
Epoch [90/100], Loss: 55.2892
train_Accuracy: [91m0.8177[0m
train_Precision: [4;34m0.8293[0m,               train_Recall: [4;33m0.8102[0m,                 train_F1 Score: [4;35m0.8141[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3516
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.6108],
        [0.9109],
        [0.9398],
        [0.0576],
        [0.8020],
        [0.1651],
        [0.6380],
        [0.1775],
        [0.6370],
        [0.9669],
        [0.1086],
        [0.0614]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [90/100], Loss: 14.0500
val_Accuracy: [92m0.7826[0m
val_Precision: [4;34m0.8041[0m,               val_Recall: [4;33m0.7446[0m,                 val_F1 Score: [4;35m0.7681[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  673
Epoch [91/100], Loss: 53.4810
train_Accuracy: [91m0.8270[0m
train_Precision: [4;34m0.8367[0m,               train_Recall: [4;33m0.8231[0m,                 train_F1 Score: [4;35m0.8241[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3556
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5849],
        [0.9677],
        [0.8819],
        [0.0453],
        [0.8741],
        [0.1901],
        [0.6377],
        [0.1924],
        [0.6096],
        [0.9330],
        [0.0849],
        [0.0703]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [91/100], Loss: 14.4454
val_Accuracy: [92m0.7756[0m
val_Precision: [4;34m0.7846[0m,               val_Recall: [4;33m0.7566[0m,                 val_F1 Score: [4;35m0.7646[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  667
Epoch [92/100], Loss: 51.7525
train_Accuracy: [91m0.8363[0m
train_Precision: [4;34m0.8469[0m,               train_Recall: [4;33m0.8314[0m,                 train_F1 Score: [4;35m0.8337[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3596
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.5184],
        [0.9603],
        [0.9011],
        [0.0514],
        [0.8782],
        [0.3883],
        [0.4275],
        [0.1216],
        [0.5414],
        [0.9512],
        [0.0775],
        [0.1009]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [92/100], Loss: 15.3147
val_Accuracy: [92m0.7721[0m
val_Precision: [4;34m0.8289[0m,               val_Recall: [4;33m0.6802[0m,                 val_F1 Score: [4;35m0.7412[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  664
Epoch [93/100], Loss: 51.4870
train_Accuracy: [91m0.8381[0m
train_Precision: [4;34m0.8466[0m,               train_Recall: [4;33m0.8342[0m,                 train_F1 Score: [4;35m0.8357[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3604
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8679],
        [0.9422],
        [0.8111],
        [0.0124],
        [0.8912],
        [0.2103],
        [0.6989],
        [0.2167],
        [0.3404],
        [0.9702],
        [0.1322],
        [0.0602]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [93/100], Loss: 14.9943
val_Accuracy: [92m0.7756[0m
val_Precision: [4;34m0.7965[0m,               val_Recall: [4;33m0.7313[0m,                 val_F1 Score: [4;35m0.7575[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  667
Epoch [94/100], Loss: 50.7561
train_Accuracy: [91m0.8391[0m
train_Precision: [4;34m0.8501[0m,               train_Recall: [4;33m0.8343[0m,                 train_F1 Score: [4;35m0.8364[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3608
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7697],
        [0.9962],
        [0.8063],
        [0.0359],
        [0.7575],
        [0.1224],
        [0.4762],
        [0.2039],
        [0.1323],
        [0.9816],
        [0.0924],
        [0.0873]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [94/100], Loss: 25.8595
val_Accuracy: [92m0.6802[0m
val_Precision: [4;34m0.8803[0m,               val_Recall: [4;33m0.4155[0m,                 val_F1 Score: [4;35m0.5521[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  585
Epoch [95/100], Loss: 53.1347
train_Accuracy: [91m0.8302[0m
train_Precision: [4;34m0.8429[0m,               train_Recall: [4;33m0.8213[0m,                 train_F1 Score: [4;35m0.8264[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3570
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.8424],
        [0.9912],
        [0.9539],
        [0.0154],
        [0.7636],
        [0.1207],
        [0.5167],
        [0.1896],
        [0.3135],
        [0.9163],
        [0.0652],
        [0.1120]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [95/100], Loss: 15.2181
val_Accuracy: [92m0.7756[0m
val_Precision: [4;34m0.8141[0m,               val_Recall: [4;33m0.7021[0m,                 val_F1 Score: [4;35m0.7486[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  667
Epoch [96/100], Loss: 52.3932
train_Accuracy: [91m0.8344[0m
train_Precision: [4;34m0.8409[0m,               train_Recall: [4;33m0.8351[0m,                 train_F1 Score: [4;35m0.8327[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3588
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7883],
        [0.9902],
        [0.8585],
        [0.0162],
        [0.8389],
        [0.0338],
        [0.3748],
        [0.2014],
        [0.8342],
        [0.9664],
        [0.0454],
        [0.1793]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [96/100], Loss: 23.1490
val_Accuracy: [92m0.7558[0m
val_Precision: [4;34m0.8322[0m,               val_Recall: [4;33m0.6399[0m,                 val_F1 Score: [4;35m0.7180[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  650
Epoch [97/100], Loss: 50.9356
train_Accuracy: [91m0.8388[0m
train_Precision: [4;34m0.8484[0m,               train_Recall: [4;33m0.8349[0m,                 train_F1 Score: [4;35m0.8362[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3607
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9003],
        [0.9900],
        [0.8901],
        [0.0037],
        [0.5212],
        [0.1189],
        [0.5626],
        [0.2359],
        [0.5739],
        [0.9436],
        [0.1229],
        [0.2377]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [97/100], Loss: 15.3526
val_Accuracy: [92m0.7558[0m
val_Precision: [4;34m0.8210[0m,               val_Recall: [4;33m0.6473[0m,                 val_F1 Score: [4;35m0.7184[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  650
Epoch [98/100], Loss: 51.8051
train_Accuracy: [91m0.8337[0m
train_Precision: [4;34m0.8430[0m,               train_Recall: [4;33m0.8297[0m,                 train_F1 Score: [4;35m0.8307[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3585
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9263],
        [0.9784],
        [0.8092],
        [0.0093],
        [0.6890],
        [0.1270],
        [0.5618],
        [0.1318],
        [0.5843],
        [0.9832],
        [0.0532],
        [0.1461]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [98/100], Loss: 24.5518
val_Accuracy: [92m0.6628[0m
val_Precision: [4;34m0.8909[0m,               val_Recall: [4;33m0.3701[0m,                 val_F1 Score: [4;35m0.5152[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  570
Epoch [99/100], Loss: 48.4053
train_Accuracy: [91m0.8481[0m
train_Precision: [4;34m0.8583[0m,               train_Recall: [4;33m0.8430[0m,                 train_F1 Score: [4;35m0.8455[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3647
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.9510],
        [0.9880],
        [0.8771],
        [0.0045],
        [0.6915],
        [0.0287],
        [0.5147],
        [0.0921],
        [0.6911],
        [0.9862],
        [0.0922],
        [0.1699]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [99/100], Loss: 18.8463
val_Accuracy: [92m0.7488[0m
val_Precision: [4;34m0.8675[0m,               val_Recall: [4;33m0.5894[0m,                 val_F1 Score: [4;35m0.6942[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  644
Epoch [100/100], Loss: 50.8267
train_Accuracy: [91m0.8374[0m
train_Precision: [4;34m0.8446[0m,               train_Recall: [4;33m0.8374[0m,                 train_F1 Score: [4;35m0.8355[0m
标签里1的个数:  2150
标签里0的个数:  2150
总数:  4300
正确的个数:  3601
最后一个批次的输出, 不满batchsize是正常的:
 tensor([[0.7809],
        [0.9842],
        [0.7831],
        [0.0259],
        [0.8539],
        [0.1523],
        [0.4296],
        [0.1063],
        [0.7874],
        [0.9708],
        [0.0255],
        [0.1478]], device='cuda:0', grad_fn=<SigmoidBackward0>)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
((26, 25), 1)
Epoch [100/100], Loss: 16.0361
val_Accuracy: [92m0.7686[0m
val_Precision: [4;34m0.8371[0m,               val_Recall: [4;33m0.6629[0m,                 val_F1 Score: [4;35m0.7328[0m
标签里1的个数:  430
标签里0的个数:  430
总数:  860
正确的个数:  661
第0批第2个, 99
第3批第7个, 99
第7批第17个, 99
第8批第13个, 99
第10批第24个, 99
send email successfully
