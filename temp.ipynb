{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asal\n"
     ]
    }
   ],
   "source": [
    "total_length = 2\n",
    "sequence = 'asal'\n",
    "sequence = sequence + 'K' * (total_length - len(sequence))\n",
    "print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "csv_path = r'/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/'\n",
    "\n",
    "# 定义Dataset类\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.total_length = 20\n",
    "        self.data = self.get_sequence_lable(csv_file)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return self.data[key]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_sequence_lable(self, csv_file)->list:\n",
    "        with open(csv_file, 'r') as f:\n",
    "            out = []\n",
    "            for line in f:\n",
    "                tmp = []\n",
    "                seq = self.encode_sequence(line.strip().split(',')[1])\n",
    "                tmp.append(seq)\n",
    "                tmp.append(int(line.strip().split(',')[2]))\n",
    "                out.append(tmp)\n",
    "            return out\n",
    "\n",
    "    # 定义一个函数，用于将序列转换为one-hot编码\n",
    "    def encode_sequence(self, sequence:str)->torch.Tensor:\n",
    "        # 把sequence: AGCT...用K填充到46398这么长\n",
    "        # sequence = sequence + 'K' * (self.total_length - len(sequence))\n",
    "        encoding = torch.tensor([\n",
    "            [1, 0, 0, 0, 0] if base == 'A' else\n",
    "            [0, 1, 0, 0, 0] if base == 'G' else\n",
    "            [0, 0, 1, 0, 0] if base == 'C' else\n",
    "            [0, 0, 0, 1, 0] if base == 'T' else\n",
    "            [0, 0, 0, 0, 1] if base == 'N' else\n",
    "            [0, 0, 0, 0, 0] for base in sequence\n",
    "        ],dtype=torch.float32)\n",
    "        # 把encoding用[0, 0, 0, 0, 0]填充到46398这么长\n",
    "        encoding = torch.cat([encoding, torch.zeros(self.total_length - len(encoding), 5, dtype=torch.float32)])\n",
    "        return encoding\n",
    "        \n",
    "from torch.utils.data import DataLoader\n",
    "# 读取zero_rows_val.csv\n",
    "data = MyDataset(csv_path + 'test.csv')\n",
    "# print(data[0])\n",
    "# 创建DataLoader\n",
    "dataloader = DataLoader(data, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 20, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 20, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([4, 20, 5])\n",
      "torch.Size([4])\n",
      "torch.Size([2, 20, 5])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for i in (dataloader):\n",
    "    # print(i[0])\n",
    "    print(i[0].shape)\n",
    "    # print(i[1])\n",
    "    print(i[1].shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([3, 20, 5])\n",
      "tensor([0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for i in  enumerate(dataloader):\n",
    "    # print(i)\n",
    "    print(i[0])\n",
    "    print(i[1][0].shape)\n",
    "    print(i[1][1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取两个CSV文件\n",
    "df1 = pd.read_csv('/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/one_rows_val_app.csv', header=None)\n",
    "df2 = pd.read_csv('/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/zero_rows_val.csv', header=None)\n",
    "\n",
    "# 使用zip函数将两个数据框的行逐行交叉合并\n",
    "merged_rows = []\n",
    "for row_a, row_b in zip(df1.values, df2.values):\n",
    "    merged_rows.append(row_a)\n",
    "    merged_rows.append(row_b)\n",
    "\n",
    "# 创建新的DataFrame\n",
    "merged_df = pd.DataFrame(merged_rows, columns=df1.columns)\n",
    "\n",
    "# 将合并后的结果保存为新的CSV文件\n",
    "merged_df.to_csv('/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/val.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence-shape torch.Size([32, 46398, 5])\n",
      "label-shape torch.Size([32])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# 给一个二进制数据集路径\n",
    "import pickle\n",
    "train_data_dir = '/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/二进制分批数据集/train/'\n",
    "val_data_dir = '/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/二进制分批数据集/val/'\n",
    "# 加载 DataLoader 对象分好的数据集\n",
    "with open(train_data_dir+'train_batch_0.pkl', 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "    # 测试\n",
    "    print('sequence-shape',batch[0].shape)\n",
    "    print('label-shape',batch[1].shape)\n",
    "    # print('label-shape',batch[1].unsqueeze(1).shape)\n",
    "    print(type(batch[1].unsqueeze(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 CUDA device(s):\n",
      "Device 0: NVIDIA RTX A6000, Memory: 48669.75 MB\n",
      "Device 1: NVIDIA RTX A6000, Memory: 48669.75 MB\n",
      "Device 2: NVIDIA GeForce RTX 3090, Memory: 24252.69 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def print_visible_cuda_devices():\n",
    "    if torch.cuda.is_available():\n",
    "        num_devices = torch.cuda.device_count()\n",
    "        print(f\"Found {num_devices} CUDA device(s):\")\n",
    "        for i in range(num_devices):\n",
    "            device = torch.cuda.get_device_properties(i)\n",
    "            print(f\"Device {i}: {device.name}, Memory: {device.total_memory / 1024 ** 2:.2f} MB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available on this system.\")\n",
    "\n",
    "print_visible_cuda_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 CUDA device(s):\n",
      "Device 0: NVIDIA RTX A6000, Memory: 48669.75 MB\n",
      "Device 1: NVIDIA RTX A6000, Memory: 48669.75 MB\n",
      "Device 2: NVIDIA GeForce RTX 3090, Memory: 24252.69 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def set_visible_cuda_devices(device_ids):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(map(str, device_ids))\n",
    "\n",
    "# 设置可见的显卡为第 0 和第 1 个显卡\n",
    "visible_devices = [0, 1]\n",
    "set_visible_cuda_devices(visible_devices)\n",
    "\n",
    "# 输出当前可见的 CUDA 设备信息\n",
    "def print_visible_cuda_devices():\n",
    "    if torch.cuda.is_available():\n",
    "        num_devices = torch.cuda.device_count()\n",
    "        print(f\"Found {num_devices} CUDA device(s):\")\n",
    "        for i in range(num_devices):\n",
    "            device = torch.cuda.get_device_properties(i)\n",
    "            print(f\"Device {i}: {device.name}, Memory: {device.total_memory / 1024 ** 2:.2f} MB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available on this system.\")\n",
    "\n",
    "print_visible_cuda_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前可用的显卡: 1\n",
      "Found 3 CUDA device(s):\n",
      "Device 0: NVIDIA RTX A6000, Memory: 48669.75 MB\n",
      "Device 1: NVIDIA RTX A6000, Memory: 48669.75 MB\n",
      "Device 2: NVIDIA GeForce RTX 3090, Memory: 24252.69 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 设置当前可用的显卡为显卡0\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "# 验证是否已成功设置\n",
    "print(\"当前可用的显卡:\", torch.cuda.current_device())\n",
    "\n",
    "print_visible_cuda_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显卡 0 的名称: NVIDIA RTX A6000\n",
      "True\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'nvidia-smi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnvidia-smi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    503\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/subprocess.py:1837\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1835\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1836\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1837\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'nvidia-smi'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 获取显卡 0 的属性\n",
    "device_properties = torch.cuda.get_device_properties(0)\n",
    "\n",
    "# 输出显卡 0 的名称\n",
    "print(\"显卡 0 的名称:\", device_properties.name)\n",
    "print(torch.cuda.is_available())\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, check=True)\n",
    "    print(result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"An error occurred: {e.stderr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given transposed=1, weight of size [1, 1, 1, 1], expected input[32, 1280, 46, 1] to have 1 channels, but got 1280 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m1280\u001b[39m, \u001b[38;5;241m46\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 将输入张量通过模型\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m output_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 输出张量的形状\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m输出张量的形状:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_tensor\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m, in \u001b[0;36mConvTransposeNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# 输入 x 的形状为 [batch_size, 1280, 46, 1]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# 1x1 卷积操作\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/site-packages/torch/nn/modules/conv.py:952\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    947\u001b[0m num_spatial_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    948\u001b[0m output_padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_padding(\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28minput\u001b[39m, output_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_size,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    950\u001b[0m     num_spatial_dims, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_transpose2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_padding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given transposed=1, weight of size [1, 1, 1, 1], expected input[32, 1280, 46, 1] to have 1 channels, but got 1280 channels instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvTransposeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvTransposeNet, self).__init__()\n",
    "        # 1x1 卷积层\n",
    "        self.conv_transpose = nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=(1, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 输入 x 的形状为 [batch_size, 1280, 46, 1]\n",
    "        # 1x1 卷积操作\n",
    "        x = self.conv_transpose(x)\n",
    "        return x\n",
    "\n",
    "# 创建模型实例\n",
    "model = ConvTransposeNet()\n",
    "\n",
    "# 输入张量\n",
    "input_tensor = torch.randn(32, 1280, 46, 1)\n",
    "\n",
    "# 将输入张量通过模型\n",
    "output_tensor = model(input_tensor)\n",
    "\n",
    "# 输出张量的形状\n",
    "print(\"输出张量的形状:\", output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence.shape torch.Size([32, 5, 46398, 1])\n",
      "label.shape torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = '/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/二进制分批数据集/train/'\n",
    "import pickle, torch\n",
    "with open(train_data_dir+'train_batch_'+str(1)+'.pkl', 'rb') as f:\n",
    "            batch = pickle.load(f)\n",
    "            sequence = batch[0].unsqueeze(3).to(torch.float32).permute(0,2,1,3)\n",
    "            print('sequence.shape',sequence.shape)\n",
    "            label = batch[1].unsqueeze(1).to(torch.float32)\n",
    "            print('label.shape',label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded_tensor.shape torch.Size([32, 5, 46656, 1])\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "reshaped_tensor.shape torch.Size([32, 5, 216, 216])\n",
      "tensor([[1., 1., 1.,  ..., 0., 0., 1.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "padded_tensor = torch.nn.functional.pad(sequence, [0,0,0,258])\n",
    "print('padded_tensor.shape',padded_tensor.shape)\n",
    "print(padded_tensor[0][0])\n",
    "reshaped_tensor = padded_tensor.view(32, 5, 216, 216)\n",
    "print('reshaped_tensor.shape',reshaped_tensor.shape)\n",
    "print(reshaped_tensor[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4,  5,  0,  0],\n",
      "        [ 0,  6,  7,  8,  9, 10,  0,  0]])\n",
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  0,  0],\n",
      "        [ 0,  6,  7,  8],\n",
      "        [ 9, 10,  0,  0]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "a = a.view([2, 5])\n",
    "a = torch.nn.functional.pad(a, [1,2])\n",
    "b = a.reshape(4,4)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5, 216, 216])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 假设sequence是你的张量，已经reshape成了(32, 5, 216, 216)\n",
    "# 注意：如果数据范围在[0, 1]之间，你可能需要将其乘以255来转换为0到255的整数值\n",
    "\n",
    "# 循环遍历32个样本\n",
    "for i in range(reshaped_tensor.size(0)):\n",
    "    # 获取第i个样本的图像数据\n",
    "    image = reshaped_tensor[i].numpy()  # 转换为NumPy数组\n",
    "    print(image[-1, :, :])\n",
    "    # 显示图像\n",
    "    plt.imshow(image[-1, :, :])\n",
    "    plt.title(f\"Image {i+1}\")  # 图像标题\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 200])\n",
      "tensor([[-1.4304,  0.3237, -0.0132, -1.3303,  1.1703,  1.0173,  0.4059,  0.3081,\n",
      "         -1.3395, -0.4861,  0.1144, -1.0111, -1.4158, -0.9841, -0.5336, -0.7502,\n",
      "         -1.0283, -1.2647, -0.0675, -1.2177, -0.6403, -0.7225, -1.0329, -1.0738,\n",
      "          0.0183,  0.0169, -0.5792, -1.9447, -0.2478,  0.9735,  0.4360,  0.4366,\n",
      "          0.3391, -0.9739, -0.4972,  0.3725, -0.6670, -0.2559,  0.4954, -0.3566,\n",
      "          0.3327,  1.1274,  1.0086, -0.1968,  0.6833,  1.8984,  0.0961,  0.3747,\n",
      "          0.2691,  0.4133,  0.0920, -0.1650,  1.8821, -0.6112,  1.9376, -1.0613,\n",
      "          0.8602,  0.9520, -0.1953, -0.2950,  1.1901, -1.4603,  1.2043, -0.0176,\n",
      "          0.0475, -1.1394,  0.8392, -0.2775,  0.0117,  0.5932,  0.2197,  0.7108,\n",
      "         -2.0340, -0.9808, -0.0842, -1.8289,  0.1120,  0.4086, -0.5622,  2.5936,\n",
      "         -0.9814, -0.7245,  0.9674,  0.4688,  0.0252, -0.7327,  1.1493, -0.3584,\n",
      "          0.7250, -2.7110, -1.6229, -0.8306,  1.6714, -0.4671, -0.3991,  0.4011,\n",
      "          0.7539,  1.7413,  1.4896, -0.8297,  1.0159, -1.6956,  0.0042,  0.3447,\n",
      "         -0.2093, -0.8816,  1.6126,  2.2630,  1.0554, -2.0834,  1.5839, -0.1301,\n",
      "         -0.3440,  1.4439,  0.2540, -0.5347, -0.4807, -0.4058,  0.1452, -0.6402,\n",
      "          1.0201,  1.4431, -0.0768, -0.5089, -0.7912,  1.1854, -0.1867,  0.0895,\n",
      "         -0.9850, -0.7415,  1.6422,  1.3404, -0.2139,  0.2729,  0.8121,  0.6317,\n",
      "         -1.6260,  0.3309,  0.6014, -1.3369, -0.9817, -1.5187,  0.0167,  0.1937,\n",
      "         -0.7226,  0.3156, -0.2234, -1.7993,  0.0574, -1.5231, -0.8389,  1.1189,\n",
      "         -0.4584,  0.5956, -0.8871,  0.0848,  2.2020, -0.3937, -0.9237,  0.3120,\n",
      "          0.1968,  0.2483, -1.6165,  1.9188,  0.6509, -0.6960, -0.4410, -1.3086,\n",
      "          0.1574, -0.1495, -1.8239, -0.2786,  0.7748,  0.4219, -0.9772, -0.6847,\n",
      "         -0.4066,  0.8995,  0.6326, -0.9034, -0.2634, -0.5475,  0.2867,  0.5571,\n",
      "          0.9763,  0.9858, -0.2732,  0.8906, -0.6579, -0.1665, -0.1624,  1.3745,\n",
      "         -0.1968,  1.7348, -2.0575, -1.4059, -0.1511, -0.8402,  0.5072, -0.5448],\n",
      "        [ 0.3642, -0.1583,  1.6282,  1.5937,  0.8221, -0.9333, -0.4213,  0.2880,\n",
      "          1.4837,  1.1638,  0.1239,  0.0283, -1.7760, -0.6078,  0.0634, -0.5791,\n",
      "         -0.0872,  0.3510, -0.8638, -0.7346,  0.8136, -1.1112,  0.0091, -0.3059,\n",
      "          0.1997, -0.6156, -0.5961,  0.1930,  2.0747,  0.3055, -1.3303, -0.5663,\n",
      "         -0.6933,  1.3841, -0.2850, -0.0634,  1.0760,  0.4474,  1.2059, -0.5096,\n",
      "          0.0795, -0.0176,  1.6579,  1.5726,  0.1037, -1.6049, -1.4838,  1.1934,\n",
      "          1.3991,  1.0816,  0.1911, -0.4345,  0.5628,  1.3869,  0.1729,  0.0193,\n",
      "          0.4695,  0.5605, -0.0509, -1.1730, -0.6463,  0.9251,  0.8034,  0.0514,\n",
      "         -0.2631, -0.7396, -0.3593, -0.0179,  0.6133, -2.3179,  0.0846, -0.5650,\n",
      "         -0.8727,  0.5705, -0.0929, -1.5282,  0.3789,  0.2272, -0.7459,  0.4822,\n",
      "         -0.8211, -0.4076, -0.7879,  0.2603,  0.3746, -1.0658,  0.8149,  0.1868,\n",
      "          2.3761,  0.2572, -0.6353, -0.7316,  0.2578, -1.6419,  0.5888,  1.2104,\n",
      "          1.9726,  0.2127, -0.7105,  2.6722,  0.0378,  0.9401,  1.6067, -1.0295,\n",
      "         -0.8416,  0.2866,  1.0860,  0.3949, -0.9801, -0.4999,  1.3606, -0.9037,\n",
      "          0.1390,  0.8152, -0.6164, -0.2621, -0.0352,  0.8698,  0.4068, -0.8313,\n",
      "         -0.0157,  0.8861,  0.1679,  0.4959, -0.1817,  2.0312, -0.0284, -0.8742,\n",
      "          0.8828, -0.7740, -0.1490,  0.1617,  0.5189,  0.2442, -0.5881,  1.8262,\n",
      "         -2.4899,  0.7601, -0.9587, -1.8500, -0.9067,  0.4490,  0.2202, -0.9315,\n",
      "          0.4163, -0.2204, -1.1324,  0.3305,  0.9290,  0.2980,  0.6911,  0.5495,\n",
      "          1.2889, -0.3042,  1.8314,  0.1699,  0.1395,  0.5358, -0.1730,  0.9023,\n",
      "          0.3669, -1.2088, -0.9257, -1.3620,  1.2746,  0.1350,  1.0187, -0.0418,\n",
      "         -2.2016, -0.2708, -0.8458,  0.0965, -0.7248,  0.4413,  0.1444,  0.1647,\n",
      "          2.7094, -0.0032, -0.9005,  0.5642,  0.5197, -1.1523,  0.0892,  0.7324,\n",
      "          0.2379,  1.8471,  0.7747,  1.8828, -1.0836, -0.9498,  1.8020,  0.1271,\n",
      "         -0.0542,  0.0254,  0.7482, -1.8394,  0.2402,  1.8155, -0.8961,  0.0339],\n",
      "        [-0.1396,  1.4608, -0.7359,  0.4639, -0.9198,  0.8941, -0.5757, -0.5174,\n",
      "          0.0349, -0.5468,  0.3351,  0.8920,  0.5690, -0.2422,  0.3374, -1.1935,\n",
      "          0.3080,  2.9494,  0.1752,  0.7595, -0.6940,  0.1592, -1.0475,  0.2820,\n",
      "         -2.2986,  0.3728, -1.0578, -1.3149,  0.7686, -0.8590, -3.1845, -0.4634,\n",
      "          0.4637, -0.3488, -0.5387, -0.0232,  0.0146, -1.1068, -1.1529,  0.4465,\n",
      "         -3.1962,  0.5884, -0.0320,  1.2319,  1.3257, -0.1740, -0.0913,  0.4056,\n",
      "          0.2816, -0.5601,  0.8868, -0.1456, -1.8426, -0.0845,  0.2206, -0.4631,\n",
      "          1.3653, -1.6214,  0.1947,  0.6371, -2.6402,  1.1455, -0.4260,  0.6110,\n",
      "         -0.3513,  0.8117,  1.8233,  0.6765,  2.3725, -0.5915,  0.0391,  0.3291,\n",
      "         -1.5102, -0.6791, -1.9515, -0.8393,  0.3131, -1.9905,  0.6241, -0.1022,\n",
      "         -1.3663,  0.4934, -3.0307, -0.8484, -1.0864,  0.6053, -1.1053, -0.4122,\n",
      "          1.1122,  0.1650,  0.0602, -0.2372, -0.4782,  0.1662,  0.1759, -0.1308,\n",
      "          0.7556, -0.8313, -0.2826, -0.6701,  0.2876,  1.5442, -0.6696,  0.3672,\n",
      "         -0.5301, -0.3854,  0.8691, -0.6004,  0.5820, -0.6546, -0.9060, -1.6102,\n",
      "          0.5974,  1.2673, -0.0255, -1.3546, -0.6706,  0.0321,  1.2456, -0.5480,\n",
      "         -0.4979,  0.9326, -0.7971, -0.1498,  1.0375,  0.4719,  1.1439, -0.4708,\n",
      "         -1.4332, -1.1556, -0.6026, -1.2203, -1.1540,  0.2337, -0.9766, -1.3645,\n",
      "          1.3346,  0.4640, -0.3237, -0.2840,  0.7862, -0.5107, -1.7312,  0.3872,\n",
      "         -1.0836,  0.1901, -0.6561, -1.8067,  1.1044,  0.7821,  0.8424, -0.3856,\n",
      "         -2.6650,  0.5442,  0.4990,  1.1801,  0.7101,  0.3917, -2.2925, -0.4633,\n",
      "          0.9433, -0.1702,  1.3411,  1.8127, -1.3877, -0.2247,  0.5687, -0.1251,\n",
      "          2.6543,  0.3813,  1.3192, -0.7847,  1.7752, -0.3992, -0.3124, -0.2234,\n",
      "         -0.4472, -0.9794,  0.6693, -0.5352, -0.2858, -1.0847,  0.2711,  0.4261,\n",
      "          0.5543, -0.9025,  0.4388,  0.0196, -0.3575, -0.7032,  0.5534, -0.4097,\n",
      "          1.1353, -0.7897, -0.6323, -1.1385, -0.6466,  0.8605,  0.0475, -0.3660]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设词汇表大小为100，嵌入维度为200\n",
    "vocab_size = 100\n",
    "embedding_dim = 200\n",
    "\n",
    "# 创建一个Embedding层\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# 假设有一个输入张量，每个元素是一个词的索引\n",
    "input_indices = torch.LongTensor([[1, 4, 2], [3, 0, 5]])\n",
    "\n",
    "# 将索引映射为嵌入向量\n",
    "embedded_vectors = embedding_layer(input_indices)\n",
    "\n",
    "# 输出嵌入向量的形状\n",
    "print(embedded_vectors.size())\n",
    "print(embedded_vectors[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 23.69 GiB. GPU 2 has a total capacty of 23.68 GiB of which 23.43 GiB is free. Including non-PyTorch memory, this process has 254.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 指定设备编号为2\u001b[39;00m\n\u001b[1;32m      8\u001b[0m total_memory \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_properties(device)\u001b[38;5;241m.\u001b[39mtotal_memory\n\u001b[0;32m---> 10\u001b[0m tmp_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtotal_memory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 作者：kaiyuan\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 链接：https://www.zhihu.com/question/451889681/answer/1814206862\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 来源：知乎\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 23.69 GiB. GPU 2 has a total capacty of 23.68 GiB of which 23.43 GiB is free. Including non-PyTorch memory, this process has 254.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 这个python的代码\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device('cuda:2')  # 指定设备编号为2\n",
    "\n",
    "total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "\n",
    "tmp_tensor = torch.empty(int(total_memory), dtype=torch.int8, device=device)\n",
    "\n",
    "\n",
    "# 作者：kaiyuan\n",
    "# 链接：https://www.zhihu.com/question/451889681/answer/1814206862\n",
    "# 来源：知乎\n",
    "# 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 23.69 GiB. GPU 2 has a total capacty of 23.68 GiB of which 23.43 GiB is free. Including non-PyTorch memory, this process has 254.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:2\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 指定设备编号为0\u001b[39;00m\n\u001b[1;32m      6\u001b[0m total_memory \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_properties(device)\u001b[38;5;241m.\u001b[39mtotal_memory\n\u001b[0;32m----> 8\u001b[0m tmp_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtotal_memory\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint8\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 23.69 GiB. GPU 2 has a total capacty of 23.68 GiB of which 23.43 GiB is free. Including non-PyTorch memory, this process has 254.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device('cuda:2')  # 指定设备编号为0\n",
    "\n",
    "total_memory = torch.cuda.get_device_properties(device).total_memory\n",
    "\n",
    "tmp_tensor = torch.empty(int(total_memory), dtype=torch.int8, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 生成10个0到1之间的小数，保留4位小数\n",
    "train_losses =  sorted([round(random.uniform(0, 1), 4) for _ in range(10)])\n",
    "val_losses =  sorted([round(random.uniform(0, 1), 4) for _ in range(10)])\n",
    "\n",
    "train_accs = [round(random.uniform(0, 1), 4) for _ in range(10)]\n",
    "val_accs = [round(random.uniform(0, 1), 4) for _ in range(10)]\n",
    "# print(random_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(val_losses, label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig('lossttt.png')\n",
    "# 清空plot\n",
    "plt.clf()\n",
    "plt.plot(train_accs, label='train_acc')\n",
    "plt.plot(val_accs, label='val_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.savefig('accttt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_609711/560421718.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'train_batch_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "train_data_dir = '/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/二进制分批数据集/train/'\n",
    "import pickle\n",
    "with open(train_data_dir+'train_batch_'+str(1)+'.pkl', 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "    sequence = batch[0].to(torch.float32).permute(0, 2, 1).unsqueeze(1).to(device)\n",
    "    label = batch[1].to(torch.float32).to(device)\n",
    "    # 查看标签的分布\n",
    "    print(label.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mThis is a blue text.\u001b[0m\n",
      "\u001b[93mThis is a warning text.\u001b[0m\n",
      "\u001b[91mThis is a fail text.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ANSI 转义码定义颜色\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "# 使用颜色输出\n",
    "print(f\"{bcolors.OKBLUE}This is a blue text.{bcolors.ENDC}\")\n",
    "print(f\"{bcolors.WARNING}This is a warning text.{bcolors.ENDC}\")\n",
    "print(f\"{bcolors.FAIL}This is a fail text.{bcolors.ENDC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0998,  0.6486,  1.3596,  0.9276, -0.6701],\n",
      "         [-0.7041,  1.6789,  0.9009, -0.0642,  0.6626],\n",
      "         [ 1.9269, -0.9433,  2.1135, -0.8710,  0.7194]],\n",
      "\n",
      "        [[-0.7041,  1.6789,  0.9009, -0.0642,  0.6626],\n",
      "         [ 0.0998,  0.6486,  1.3596,  0.9276, -0.6701],\n",
      "         [ 0.3562, -0.2997,  0.1108,  0.0980, -0.4070]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[ 0.0660, -0.5946, -0.8315, -0.9325,  0.0886],\n",
      "         [ 1.1981,  1.7968, -0.6174, -1.0448,  0.1236],\n",
      "         [-0.5655, -0.4027,  0.8215, -1.2259,  2.0235]],\n",
      "\n",
      "        [[ 1.1981,  1.7968, -0.6174, -1.0448,  0.1236],\n",
      "         [ 0.0660, -0.5946, -0.8315, -0.9325,  0.0886],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "a = torch.tensor([[1,2,3], [2,1,0]])\n",
    "net = nn.Embedding(num_embeddings=10, embedding_dim=5)  # 并未设置padding_index参数\n",
    "print(net(a))\n",
    "\n",
    "net = nn.Embedding(num_embeddings=10, embedding_dim=5, padding_idx=0)\n",
    "print(net(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.6277,  0.7734, -0.2388,  1.5212,  0.1412],\n",
      "         [ 1.3355,  1.2613, -1.3401,  0.4666,  0.0279],\n",
      "         [ 0.2684,  1.1881,  1.0919, -1.4586, -1.0775],\n",
      "         [ 0.2684,  1.1881,  1.0919, -1.4586, -1.0775],\n",
      "         [ 0.2684,  1.1881,  1.0919, -1.4586, -1.0775]],\n",
      "\n",
      "        [[-0.6562,  0.6157,  0.2941,  0.4966, -2.2336],\n",
      "         [-0.2847,  0.3101,  0.5156,  1.1138, -1.1316],\n",
      "         [-0.1117, -0.5562, -0.5425,  0.0519, -0.6485],\n",
      "         [-0.3836, -0.3585,  0.1276,  1.0731,  0.9092],\n",
      "         [ 0.2684,  1.1881,  1.0919, -1.4586, -1.0775],\n",
      "         [ 0.2684,  1.1881,  1.0919, -1.4586, -1.0775]],\n",
      "\n",
      "        [[ 1.5688, -0.1014, -1.4711,  0.2026,  1.5185],\n",
      "         [ 0.5544,  0.2456, -0.6664,  0.0346,  0.7820],\n",
      "         [ 0.1673,  0.3437,  0.1484,  0.7142, -0.1526],\n",
      "         [ 1.8919,  1.6237,  1.1682,  1.3470, -1.0067],\n",
      "         [ 0.4937, -0.6931,  0.8153, -0.4091,  1.2370],\n",
      "         [ 0.2684,  1.1881,  1.0919, -1.4586, -1.0775]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义输入序列\n",
    "sequences = [\n",
    "    [1, 2, 3],        # 长度为3的序列\n",
    "    [4, 5, 6, 7],     # 长度为4的序列\n",
    "    [8, 9, 10, 11, 12]  # 长度为5的序列\n",
    "]\n",
    "\n",
    "# 求出最长序列的长度\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "\n",
    "# 填充所有序列到相同的长度\n",
    "padded_sequences = [seq + [0] * (max_length - len(seq)) for seq in sequences]\n",
    "\n",
    "# 转换成张量\n",
    "tensor_sequences = torch.tensor(padded_sequences)\n",
    "\n",
    "# 创建 Embedding 层\n",
    "embedding = nn.Embedding(num_embeddings=13, embedding_dim=5, padding_idx=1)\n",
    "\n",
    "# 获取嵌入表示\n",
    "embeddings = embedding(tensor_sequences)\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0., 1., 1.],\n",
      "          [1., 1., 0., 1.],\n",
      "          [0., 1., 0., 1.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 1., 1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[1., 0., 1., 1.],\n",
      "          [0., 1., 1., 1.],\n",
      "          [0., 0., 0., 1.],\n",
      "          [1., 0., 0., 0.],\n",
      "          [1., 1., 0., 1.]]]])\n",
      "池化后的张量形状: torch.Size([2, 1, 5, 2])\n",
      "tensor([[[[1., 1.],\n",
      "          [1., 1.],\n",
      "          [1., 1.],\n",
      "          [0., 0.],\n",
      "          [1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.],\n",
      "          [0., 1.],\n",
      "          [1., 0.],\n",
      "          [1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设输入张量为 x，大小为 32x1x5x46386\n",
    "x = torch.randn(2, 1, 5, 4)\n",
    "x = torch.where(x > 0, torch.tensor(1.0, dtype=torch.float32), torch.tensor(0.0, dtype=torch.float32))\n",
    "\n",
    "print(x)\n",
    "# 指定池化后的输出大小\n",
    "output_size = (5, 2)  # 输出大小为 1x1\n",
    "\n",
    "# 使用 adaptive_max_pool2d 进行自适应最大池化\n",
    "pooled_tensor = F.adaptive_max_pool2d(x, output_size)\n",
    "\n",
    "# 打印池化后的张量形状\n",
    "print(\"池化后的张量形状:\", pooled_tensor.shape)\n",
    "print(pooled_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "池化后的张量形状: torch.Size([2, 1, 5, 2])\n",
      "tensor([[[[1., 1.],\n",
      "          [1., 1.],\n",
      "          [1., 1.],\n",
      "          [0., 0.],\n",
      "          [1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.],\n",
      "          [0., 1.],\n",
      "          [1., 0.],\n",
      "          [1., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "# 指定池化核的大小和步幅\n",
    "kernel_size = (1, 2)  # 池化核大小为 1x5\n",
    "stride = (1, 2)        # 步幅为 1x5\n",
    "\n",
    "# 使用 max_pool2d 进行池化\n",
    "pooled_tensor = F.max_pool2d(x, kernel_size=kernel_size, stride=stride)\n",
    "# 打印池化后的张量形状\n",
    "print(\"池化后的张量形状:\", pooled_tensor.shape)\n",
    "print(pooled_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 46398, 5])\n",
      "<class 'list'>\n",
      "2\n",
      "torch.Size([32, 46398, 5])\n",
      "torch.Size([32])\n",
      "tensor([1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = '/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/二进制分批数据集/train/'\n",
    "import pickle, torch, random\n",
    "with open(train_data_dir+'train_batch_'+str(1)+'.pkl', 'rb') as f:\n",
    "    batch = pickle.load(f)\n",
    "    # random.shuffle(batch)\n",
    "    sequence = batch[0].to(torch.float32)\n",
    "    label = batch[1].to(torch.float32)\n",
    "    print(sequence.shape)\n",
    "    size_0_sequence = sequence.size(0)\n",
    "    size_0_label = label.size(0)\n",
    "\n",
    "    # 生成相同的随机排列索引\n",
    "    permuted_index = torch.randperm(size_0_sequence)\n",
    "\n",
    "    # 使用相同的索引对两个张量进行重新排列\n",
    "    permuted_sequence = sequence[permuted_index]\n",
    "    permuted_label = label[permuted_index]\n",
    "\n",
    "    # 查看标签的分布\n",
    "    print(type(batch))\n",
    "    print(len(batch))\n",
    "    print(permuted_sequence.shape)\n",
    "    print(permuted_label.shape)\n",
    "    print(permuted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9020],\n",
      "         [ 1.8761]],\n",
      "\n",
      "        [[ 0.3737],\n",
      "         [-0.0800]],\n",
      "\n",
      "        [[-0.4059],\n",
      "         [ 1.0705]],\n",
      "\n",
      "        [[ 0.5663],\n",
      "         [ 0.2678]]])\n",
      "tensor([-0.2940,  0.5546, -1.0710,  0.9444])\n",
      "tensor([[[-0.4059],\n",
      "         [ 1.0705]],\n",
      "\n",
      "        [[ 0.5663],\n",
      "         [ 0.2678]],\n",
      "\n",
      "        [[ 0.9020],\n",
      "         [ 1.8761]],\n",
      "\n",
      "        [[ 0.3737],\n",
      "         [-0.0800]]])\n",
      "tensor([-1.0710,  0.9444, -0.2940,  0.5546])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建示例张量\n",
    "tensor_large = torch.randn(4, 2, 1)\n",
    "tensor_small = torch.randn(4)\n",
    "print(tensor_large)\n",
    "print(tensor_small)\n",
    "# 获取张量的大小\n",
    "size_0_large = tensor_large.size(0)\n",
    "size_0_small = tensor_small.size(0)\n",
    "\n",
    "# 设置随机数种子\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# 生成相同的随机排列索引\n",
    "permuted_index = torch.randperm(size_0_large)\n",
    "\n",
    "# 使用相同的索引对两个张量进行重新排列\n",
    "permuted_tensor_large = tensor_large[permuted_index]\n",
    "permuted_tensor_small = tensor_small[permuted_index]\n",
    "\n",
    "print(permuted_tensor_large)\n",
    "print(permuted_tensor_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mThis is a blue text.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "print(f\"{bcolors.HEADER}This is a blue text.{bcolors.ENDC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([690, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 1 elements not 690",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_norm \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(\u001b[38;5;241m690\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 应用批量归一化\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m normalized_output \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m归一化后的输出:\u001b[39m\u001b[38;5;124m\"\u001b[39m, normalized_output)\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Data4/gly_wkdir/environment/yolo2/lib/python3.9/site-packages/torch/nn/functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2479\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 1 elements not 690"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 输入数据\n",
    "input_data = torch.randn(3, 5, 46)\n",
    "# print(input_data)\n",
    "# 将输入数据转换为二维张量，因为 Batch Normalization 期望的是一个 batch 数据\n",
    "input_data = input_data.view(-1, 1)\n",
    "print(input_data.shape)\n",
    "\n",
    "# 批量归一化层，输入的特征维度为 3\n",
    "batch_norm = nn.BatchNorm1d(690)\n",
    "\n",
    "# 应用批量归一化\n",
    "normalized_output = batch_norm(input_data)\n",
    "\n",
    "print(\"归一化后的输出:\", normalized_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "#import numpy as np\n",
    "\n",
    "\n",
    "dataName = open(dataPath,\"r\")\n",
    "result = dataName.readlines()\n",
    "\n",
    "arrX = []\n",
    "arrY = []\n",
    "for line in result:\n",
    "    lineX = float(line.strip(\"\\n\").split(\"\\t\")[0])\n",
    "    lineY = float(line.strip(\"\\n\").split(\"\\t\")[1])\n",
    "    arrX.append(lineX)\n",
    "    arrY.append(lineY)\n",
    "    \n",
    "plt.plot(arrX,arrY,c=\"b\")\n",
    "plt.axis('off') #不显示坐标轴及边框\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (6.0, 4.0) #设置figure_size尺寸\n",
    "plt.rcParams['savefig.dpi'] = 100 #图片像素\n",
    "\n",
    "plt.show() #在 plt.savefig 之前\n",
    "plt.savefig('black.png',facecolor =\"k\") #设置背景为黑色\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 12, 1, 72])\n"
     ]
    }
   ],
   "source": [
    "# haha\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "layer_N = nn.LayerNorm(normalized_shape=[12, 1, 72], eps=1e-05, elementwise_affine=True)\n",
    "\n",
    "t = torch.randn(3, 12, 1, 72)\n",
    "t_t = layer_N(t)\n",
    "print(t_t.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相同元素的数量: 2\n",
      "总元素的数量: 4\n",
      "相同率: 50.0 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义两个tensor\n",
    "tensor1 = torch.tensor([[0, 1],\n",
    "                        [1, 0]])\n",
    "\n",
    "tensor2 = torch.tensor([[1, 0],\n",
    "                        [1, 0]])\n",
    "\n",
    "# 比较两个tensor是否相等，得到一个布尔型的tensor\n",
    "equal_tensor = tensor1 == tensor2\n",
    "\n",
    "# 计算相同元素的数量\n",
    "num_equal_elements = torch.sum(equal_tensor).item()\n",
    "\n",
    "# 计算总元素的数量\n",
    "total_elements = equal_tensor.numel()\n",
    "\n",
    "# 计算相同率\n",
    "similarity_percentage = (num_equal_elements / total_elements) * 100\n",
    "\n",
    "print(\"相同元素的数量:\", num_equal_elements)\n",
    "print(\"总元素的数量:\", total_elements)\n",
    "print(\"相同率:\", similarity_percentage, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率： 0.5\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 定义神经网络输出的结果和真实标签\n",
    "tensor1 = torch.tensor([[0, 1],\n",
    "                        [1, 0]])\n",
    "tensor2 = torch.tensor([[1, 0],\n",
    "                        [1, 0]])\n",
    "\n",
    "# 比较预测值和真实值，计算准确率\n",
    "total = tensor1.numel()  # 总数量\n",
    "correct = (tensor1 == tensor2).sum().item()  # 相同预测值和真实值的数量\n",
    "accuracy = correct / total  # 准确率\n",
    "\n",
    "print(\"准确率：\", accuracy)\n",
    "print(correct)\n",
    "print(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu121\n",
      "True\n",
      "3\n",
      "NVIDIA RTX A6000\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "# 输出可见GPU的名称\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# 输出cuda:2对应GPU的名称\n",
    "print(torch.cuda.get_device_name(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4634, 5])\n",
      "32\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# 创建一个张量\n",
    "shape = [32,4634,5]\n",
    "t = torch.ones(shape)\n",
    "print(t.shape)\n",
    "a = t.shape[0]\n",
    "print(a)\n",
    "print(type(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(0):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm, time\n",
    "for e in tqdm.tqdm(range(10)):\n",
    "    # print(e)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-15-23:43:06\n"
     ]
    }
   ],
   "source": [
    "# 获取当前时间yy:mm:dd:hh:mm:ss\n",
    "import time\n",
    "print(str(time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6078, -1.9689,  2.9219, -0.7258, -0.6083],\n",
      "         [ 0.5614,  0.9803, -0.5313, -2.0395,  0.8974],\n",
      "         [-0.3832,  0.7642, -0.3712,  1.1476, -0.9181],\n",
      "         [-0.6455,  0.1229, -0.0568,  0.2947, -0.0849],\n",
      "         [-0.0528,  1.1971, -0.6759, -1.3760, -1.4606]],\n",
      "\n",
      "        [[-0.3206, -1.0888,  0.4327,  1.2018, -0.8583],\n",
      "         [-0.6180, -0.7792,  0.9368,  0.2814,  0.0360],\n",
      "         [ 0.4320,  1.4195, -0.1430,  0.2279, -1.0816],\n",
      "         [-0.4013,  0.0612,  0.1625, -0.6073, -0.1219],\n",
      "         [-1.0133, -0.8650,  1.1110,  0.8135, -1.4759]],\n",
      "\n",
      "        [[ 0.3332,  1.4323, -0.6665,  0.0580, -0.4765],\n",
      "         [-0.5036, -0.8490, -0.7179, -1.0895,  0.1538],\n",
      "         [-0.6970,  1.3743, -1.1301,  0.0735,  1.1462],\n",
      "         [-0.3967,  1.2532,  0.1282,  1.2311,  1.5014],\n",
      "         [ 0.6486, -0.0119, -0.1383, -0.5730,  0.2313]]])\n",
      "tensor([[[-4.7063e-01, -1.6461e+00,  2.5774e+00, -5.7255e-01, -4.7107e-01],\n",
      "         [ 9.3448e-01,  1.4363e+00, -3.7437e-01, -2.1811e+00,  1.3370e+00],\n",
      "         [-5.8673e-01,  7.4042e-01, -5.7288e-01,  1.1838e+00, -1.2054e+00],\n",
      "         [-1.2550e+00, -6.1857e-02, -3.4093e-01,  2.0492e-01, -3.8447e-01],\n",
      "         [ 2.1496e-01,  1.6298e+00, -4.9026e-01, -1.2828e+00, -1.3786e+00]],\n",
      "\n",
      "        [[-2.2264e-01, -8.8606e-01,  4.2791e-01,  1.0920e+00, -6.8695e-01],\n",
      "         [-4.7828e-01, -6.7140e-01,  1.3841e+00,  5.9908e-01,  3.0520e-01],\n",
      "         [ 3.5617e-01,  1.4983e+00, -3.0887e-01,  1.2006e-01, -1.3945e+00],\n",
      "         [-8.7587e-01, -1.5764e-01, -2.8733e-04, -1.1957e+00, -4.4202e-01],\n",
      "         [-8.7217e-01, -7.0431e-01,  1.5324e+00,  1.1956e+00, -1.3959e+00]],\n",
      "\n",
      "        [[ 3.4192e-01,  1.2910e+00, -5.2134e-01,  1.0431e-01, -3.5725e-01],\n",
      "         [-3.4122e-01, -7.5498e-01, -5.9800e-01, -1.0431e+00,  4.4631e-01],\n",
      "         [-9.4964e-01,  1.4461e+00, -1.4506e+00, -5.8506e-02,  1.1822e+00],\n",
      "         [-8.6862e-01,  1.6933e+00, -5.3570e-02,  1.6590e+00,  2.0787e+00],\n",
      "         [ 1.0090e+00,  2.6125e-01,  1.1827e-01, -3.7385e-01,  5.3659e-01]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor([[-0.2256,  0.2191,  0.2573, -0.5398, -0.4349],\n",
      "        [-0.3842, -0.2505,  0.5000,  0.3835, -0.7003],\n",
      "        [-0.1231,  0.6398, -0.5049, -0.0600,  0.5113]])\n",
      "tensor(6.3578e-09, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.randn([3,5,5])\n",
    "print(a)\n",
    "import torch.nn as nn\n",
    "batch_norm1 = nn.BatchNorm1d(5)\n",
    "print(batch_norm1(a))\n",
    "print(a.mean(dim=1))\n",
    "print(batch_norm1(a).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0    2824\n",
      "1    2064\n",
      "Name: count, dtype: int64\n",
      "2\n",
      "0    707\n",
      "1    516\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv1 = pd.read_csv(\"/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/new/train_data.csv\", header=None)\n",
    "csv2 = pd.read_csv(\"/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/new/val_data.csv\", header=None)\n",
    "# # 输出表头\n",
    "# print(csv1.columns)\n",
    "# print(csv2.columns)\n",
    "# 统计第三列的数据情况\n",
    "print(csv1[2].value_counts())\n",
    "print(csv2[2].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9258820632003453"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "a = random.random()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SequenceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, seq_input_dim, seq_hidden_dim, seq_output_dim, graph_input_dim, graph_hidden_dim, graph_output_dim, final_output_dim):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.sequence_model = SequenceModel(seq_input_dim, seq_hidden_dim, seq_output_dim)\n",
    "        self.graph_model = GraphModel(graph_input_dim, graph_hidden_dim, graph_output_dim)\n",
    "        self.fc1 = nn.Linear(seq_output_dim + graph_output_dim, final_output_dim)\n",
    "    \n",
    "    def forward(self, sequence_data, graph_data):\n",
    "        seq_out = self.sequence_model(sequence_data)\n",
    "        graph_out = self.graph_model(graph_data.x, graph_data.edge_index, graph_data.batch)\n",
    "        combined = torch.cat([seq_out, graph_out], dim=1)\n",
    "        out = self.fc1(combined)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = f'/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/new/二进制一位分批数据集/train/'\n",
    "val_data_dir = f'/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/new/二进制一位分批数据集/val/'\n",
    "train_graph_dir = f'/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/new/二进制一位分批数据集/Data/32/train/'\n",
    "val_graph_dir = f'/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/分好的数据集csv/new/二进制一位分批数据集/Data/32/val/'\n",
    "def get_graph_data(index, train_val):\n",
    "    if train_val == 'train_batch':\n",
    "        with open(train_graph_dir+train_val+'_'+str(index)+'.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "    elif train_val == 'val_batch':\n",
    "        with open(val_graph_dir+train_val+'_'+str(index)+'.pkl', 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "    else: # raise报错\n",
    "        raise Exception(f'get_graph_data函数参数错误{index}和{train_val}')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-18-23:08:02\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "TheTime = str(time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.localtime()))\n",
    "print(TheTime)\n",
    "# 设置随机种子\n",
    "# seed = 3407 # https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2109.08203.pdf\n",
    "# torch.manual_seed(seed)\n",
    "# =============================================\n",
    "# 此次训练的目的是什么？\n",
    "Thetarget = '新模新分'\n",
    "# =============================================\n",
    "# 参数定义\n",
    "torch.cuda.set_device(0)\n",
    "device = torch.device(\"cuda:0\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "# 学习率和L2正则化参数\n",
    "lr=0.0001\n",
    "weight_decay=1e-4\n",
    "epochs = 200\n",
    "\n",
    "# 定义一个最好的精度，val最好精度的模型被保存，没0.8你就别存了\n",
    "best_acc = 0.8\n",
    "databasename = '二进制一位分批数据集'\n",
    "# 保存图片的名字\n",
    "root_dir = '/Data4/gly_wkdir/coldgenepredict/raw_sec/S_italica/CNN_GCN/'\n",
    "loss_png = root_dir + f'loss64-{lr}-{weight_decay}-{epochs}-{databasename}-正常数据集{TheTime}-{Thetarget}.png'\n",
    "acc_png = root_dir + f'acc64-{lr}-{weight_decay}-{epochs}-{databasename}-正常数据集{TheTime}-{Thetarget}.png'\n",
    "# 给一个二进制数据集路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设我们已经有了序列数据、图数据和标签\n",
    "# sequences: [64, 46398] 的序列数据\n",
    "# labels: [64, 1] 的标签数据\n",
    "# edge_index: [2, num_edges] 的图边数据\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    epoch_loss = 0\n",
    "    right_num = 0\n",
    "    num1s = 0\n",
    "    num0s = 0\n",
    "    # 用于合并sequence和label的list\n",
    "    sequence_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for i in range(129):\n",
    "        with open(train_data_dir+'train_batch_'+str(i)+'.pkl', 'rb') as f:\n",
    "            optimizer.zero_grad()\n",
    "            batch = pickle.load(f)\n",
    "            sequence = batch[0].to(torch.float32)\n",
    "            label = batch[1].to(torch.float32)\n",
    "\n",
    "            # print('sequence: ', sequence.shape) # torch.Size([64, 46398, 1])\n",
    "            # print('label: ', label.shape) # torch.Size([64])\n",
    "            sequence = sequence.squeeze(2) # torch.Size([64, 46398])\n",
    "            label = label.unsqueeze(1) # torch.Size([64, 1])\n",
    "            num1s += (label == 1).sum().item()\n",
    "            num0s += (label == 0).sum().item()\n",
    "            \n",
    "            # print('sequence: ', sequence.shape)\n",
    "            # print('label: ', label.shape)\n",
    "            size_0_sequence = sequence.size(0)\n",
    "            # size_0_label = label.size(0)\n",
    "\n",
    "            # 生成相同的随机排列索引\n",
    "            permuted_index = torch.randperm(size_0_sequence)\n",
    "            # print('train_permuted_index: ', permuted_index)\n",
    "            # 使用相同的索引对两个张量进行重新排列\n",
    "            permuted_sequence = sequence[permuted_index]\n",
    "            permuted_label = label[permuted_index]\n",
    "\n",
    "            # --------------------------------------------------------------------------------------\n",
    "            data = get_graph_data(i, 'train_batch').to(device) # type: ignore\n",
    "            # --------------------------------------------------------------------------------------\n",
    "            permuted_sequence = permuted_sequence.to(device)\n",
    "            permuted_label = permuted_label.to(device)\n",
    "            outputs = model(data, permuted_sequence)\n",
    "            # print('outputs: ', outputs.shape)\n",
    "            # print('realoutputs', outputs)\n",
    "            loss = criterion(outputs, permuted_label)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # outputs = torch.where(outputs > 0, torch.tensor(torch.float32(1)).to(device), torch.tensor(torch.float32(0)).to(device))\n",
    "            outputs10 = torch.where(outputs >= 0.5, torch.tensor(1.0, dtype=torch.float32).to(device), torch.tensor(0.0, dtype=torch.float32).to(device))\n",
    "\n",
    "            right_num += (outputs10 == permuted_label).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step() \n",
    "            \n",
    "    \n",
    "    print('标签里1的个数：', num1s)\n",
    "    print('标签里0的个数：', num0s)\n",
    "    _all = num1s + num0s\n",
    "    print('训练集总数：', _all)\n",
    "    print('正确的个数：', right_num)\n",
    "    accuracy = right_num / _all\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}')\n",
    "    print(f'Train Accuracy: {bcolors.FAIL}{accuracy:.4f}{bcolors.ENDC}')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(accuracy)\n",
    "    print('最后一个批次的输出，不满batchsize是正常的:\\n',outputs)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    right_num = 0\n",
    "    num1s = 0\n",
    "    num0s = 0\n",
    "    for i in range(92):\n",
    "        with open(val_data_dir+'val_batch_'+str(i)+'.pkl', 'rb') as f:\n",
    "            batch = pickle.load(f)\n",
    "            valsequence = batch[0].to(torch.float32)\n",
    "            label = batch[1].to(torch.float32)\n",
    "\n",
    "            size_0_sequence = valsequence.size(0)\n",
    "            # size_0_label = label.size(0)\n",
    "\n",
    "            # 生成相同的随机排列索引\n",
    "            permuted_index = torch.randperm(size_0_sequence)\n",
    "            # print('eval_permuted_index: ', permuted_index)\n",
    "            # 使用相同的索引对两个张量进行重新排列\n",
    "            permuted_sequence = valsequence[permuted_index]\n",
    "            permuted_label = label[permuted_index]\n",
    "            permuted_sequence = permuted_sequence.squeeze(2) # torch.Size([64, 46398])\n",
    "            permuted_label = permuted_label.unsqueeze(1) # torch.Size([64, 1])\n",
    "            # --------------------------------------------------------------------------------------\n",
    "            data = get_graph_data(i, 'val_batch').to(device) # type: ignore\n",
    "            # --------------------------------------------------------------------------------------\n",
    "            permuted_sequence = permuted_sequence.to(device)\n",
    "            permuted_label = permuted_label.to(device)\n",
    "            outputs = model(data, permuted_sequence)\n",
    "            loss = criterion(outputs, permuted_label)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # outputs = torch.where(outputs > 0, torch.tensor(torch.float32(1)).to(device), torch.tensor(torch.float32(0)).to(device))\n",
    "            outputs = torch.where(outputs >= 0.5, torch.tensor(1.0, dtype=torch.float32).to(device), torch.tensor(0.0, dtype=torch.float32).to(device))\n",
    "            # 计算标签为1的个数\n",
    "            num1s += (permuted_label == 1).sum().item()\n",
    "            num0s += (permuted_label == 0).sum().item()\n",
    "            right_num += (outputs == permuted_label).sum().item()\n",
    "\n",
    "    print('标签里1的个数：', num1s)\n",
    "    print('标签里0的个数：', num0s)\n",
    "    _all = num1s + num0s\n",
    "    print('训练集总数：', _all)\n",
    "    print('正确的个数：', right_num)\n",
    "    print(f'Validation Loss: {loss.item():.4f}')\n",
    "    accuracy = right_num / _all\n",
    "    print(f\"Validation Accuracy: {bcolors.OKGREEN}{accuracy:.4f}{bcolors.ENDC}\")\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7262\n"
     ]
    }
   ],
   "source": [
    "a = {}\n",
    "a['a'] = 'a'\n",
    "\n",
    "if a.get('b'):\n",
    "    raise TypeError('duplicate gene ID')\n",
    "print(len('GGCATGGCATTCCTCGTGCCCTGTCTGTTGTGAACAGAAATAAATTTGTAATGTCATAGATCTTGAGCTCGACTTCAGTTGCCTGAGCCAATGGCCACATCCTAAAAGAAGGAAATCGAGCTAATAATGGGCAACTTGGCAAGCAGAAGCAGCAGAGCAACTTTTCCATCGCTGGGCTGCTTCTTCCTGCTTGCAACGTGGCCGCTGTTTCTGCGGCACACCCCGCCGGCCCTCCCTGACCCTCTGGCGATGTGGCCCCTCTCCCCGTGTGCGCGCTTGCAGTCTTGTGGTTCCCAAGCGCAGAGCAGTTCGTGGAGCCAGGTGGCCTGCAGCCCACACCACGCATCGCGTAGTTGGCTCGCGGGACCCAGGCGTCAGCATCGCGCCTCCCTCTCCCGAAGCTCGCGTCTCGGCGTCTGTCTCCTCGCACCTCGGCGCCCGGACCCGGAGCGAGCCTGAGGCGCGCGACAAAGCGATGGCCTCGCCGGCGGCGGTGACGCGGCACCCTTCCCCCACCGTCCTTGCCTCCGGCCCTCGCTACTGCCGCCGCGTGAGTGCTCCCCCTCTCCCGCTCCCCCGGTGTAGTCTGCGGATGTAACACTGTGATTCCACTGGTGGAATCCACGCCCAGCGGTGCGGTTAGTGAGCTCCTGAGAACCGTAGGGTTTCAACGCCGCACCTCGTTCCGAAGCTGCCATATTATTCTTAATTCTTCTAGGAGGGAATGAGCGGTGCGAGTTTTTAGGGGAACCCGTTTAGCCATGGATTATTCTGATTGACACGAAACAGTACAGTTGAGTACTTGAGTGAGTGTGTTAGATTTGGAAGCAGGAGGCTGATGTGCACAATTGTTTGGATGATCGTTTTGTACTGAAGGGCCGGATTGATGGTTTGGACTGTCATTATATATATGCCACACGCAGAAATCATGATTTCCTCGTATAATATATACTGATTTAGGTATTGTTAGATAATGGTATGGCCCATAGGCCATATTGATGGTTTGTTCGAGTGCTTCATTAAGCAGGAGAGAAATGGATATATTGCACACTACAAGTTGCTTGTCTGAGTCTTGTGCACATGTAACATTGAACGCCGCAAACTGCCTGGGCTGTTCCAGAATAAGTTTGGTCTGAAGTGGCCATATGGTTTACACCCATTCTGGCATCTGTTTAGTTTCCTTTGTTTACCTATATTCTGTTCTGTATAATGTTTGTTCATCCCGCTACAGAATTTTGTTCCCAAAACTAAGTTTGTTCACTCTGGCAACGATCATTTGCAGGGACATCCACCCTCAAAAGTTGGCTTCCGAAGCTTGGCGCCACGGCTAAAGGTCAATGCACTTTTTGGGTGGCCTAAGGGAGACACGTCAACACGTCAACTGATCCCTCCTGCTGCTGAATCATATACGCTCTCAGGGTCAGCCTTAGAGGTGTTTTGTGTTTCTTGAGTGAACTCCTTTTCCAGGACTTATGCACCTAATTCATGATTTCCTTAATCGCTCGTTCGTTTCAGGTGGGTGCAAAACCACGTGAGGTGTCTATTTCTGTTGCTTCTTCTATCATGGACATTCCTGCTGCGGATTGGGATGCCTGTGCGTGTGATCCAGATGATCCTGAAAACTTTAACCCTTTCCTTACTTATGCATTCCTCTCAAGCTTAGAAGAATCACATTCTGCAGTAAAGGTAAGCACATAAATCACCATGTATCCTCGTCAGATCATACAAAGACATTTCTGTTTTAATCACTGTTCACCTACTGCATACACAGACGTTTAGCCCGTTTGACCGTTTAATTGGTTGTTTACACCAAATAATGGCTAAATGATAGGTGACCGACTGTATAACATTTAGCGTTTAGGTGAACACTAGTTTTAACCGTTAAGTGCTCAAGCTCCATTATAAGCATGTGTAATGTCTTACACATTGATTTTGACGATAAATTTGCTGTGTTTAATTGACAACAGAACTACAAACAAGATTTGTCTGCAATACCACCAGGCATATTGAGACATCAAAAATGATGAATTACCTATGACCAGGGGGTGTTCTGTGTGCTTAGCCTGACCCATCATGATTGTGATTCTATTTCTTTTGCGATTCTTAATTGCACAATTGCTTTCTTTATGAAAATTACTCCCGTAGATTGAACAAAGATTAGCTCTAACTTTTATTCAGTACCAACATGCATGGATGTACACACTGTTATCTTATTGTCTTCCTTGAGACCTTGGTCTCAACTGATTTCAGGAAACTGGCTGGTTACCTTTCCATGTTGTTGCACGGGATGAGAATGGACATATTATAGGTGTTGTTCCGCTTTACCTTAAAAGGTTTAACATCATTAACAGAATATCATCTCCTGTCTTCCTACTTGCTATGTACTATGTGCTCCTTTCATCTTGTTCATTGGTTGAGTGACAACATTGTGAACTTGCAGTCATTCTAGAGGAGAGTTTGTGTTTGATCAATCATGGGCAGAAGCTTACTACAACTATGGCCTTGAATACTATCCAAAGCTCCAGTCCTGTGTGCCTTTTACTCCAGTAACTGGTCAAAGAATATTACTTCGAAATACATCATATCGTGATCAAGTTTTTGATGCACTTGTCAAAGGTTTGATGAGCCTGACTACCAAGGTATCTGGATTAGCGTTCTTGCAAATATTTGTTTAAGTGGTGACTACTAAGAATGCCTAAAAATTATTATATCAAAATCATCCTATATTTTTAGCATCTATGTGCTACTGTTCATTGTTTCCACTTTCCACCTTTTATCAGCTCTACTTCATATGGCATTGTGATATCCTCTAGGACTAACCATTGCTTAATTCTTGAGTCATTTGTCTTCTTTTATTCTTGTTTTCTTGACATTTACAGTGTATACCAAAGGGCACCAAGTCTGTTTCATTTAAATAGAAGAGTTTGGTTGTCTGCTTGCAGCTACAAAGTTGCTAAATCAGGGCTTGATCGTTAATGTGTGTCGGTAATGAGTCAATGCTTTTTTTCCTCGAAAAATGCAGGAGAGCTGCGCATCATTATATTAAGAAGTGAAAAAAAGGGAAAGAACCCATACAACACGCCCCAGGCCAGCCAAAAGGCAAGCCCACACACTCACACCAACTCACGCCAACTCACACAAAACTCCCCCAAACTCTCTGATCCTTAGGCGTCCGTTTCAAAGGGCGACCAACTAATGAGTCAATGCTGAAGTAATAAAAGTTTAAAATCCTGTCTCTCTTCACAACTCATGTTTCATTATCTTTATGGTGTTAACTTGTAACACCCCAAAGTCCAAACAGCTCAGATTCACTCTGAGCGCTCACACTCTCACCAACCCACTTAACCTAGGGTTAACCCGGGGTTTGGTGGGCCTAAAACCCCTACAAACTTGCATCAACACACACATGGGCCACCATGGGCCTAATTCAAACTGGGCCGATGTCACATTACTAATTATTGATGTAGGCTCATGTATATGTGAAGTAGTGACAACCTTTTTGGGTTGCTTTGTTTATTTATCAACTACCTCTGTGTAGCTCTTATAAGACTACCCTCAGATGTATTGAACCAAGTTAATATCTGTCGGTTTCTGCTGCATTTCAGATGAACGTGTCATCATTACATATTACTTTTCCGTCTGAAGGTGAATTCAGCAAATTGAAGAATAGTGGGTTGTTACAAAGAATTGGGTTGCAATATCACTGGAGAAATCGGAATTACAAGAGGTGCTAACGCATTATGATATTAATAGCATTTCCTTCTGGATGGTTCAATGCTTGAAGTTGGGACTTCTACGTTCTAACCATATTATACTGCAACTTGGGGTTTCAATACTTGGTTGGAACATCTAGTTTTAAGAAAATCTTGGTGGACTAGAAGTGCAAACAAGCTCACAGTTTGGATGCAGCTACTATTTCCCTCATATACTGTTAATTCAAGGCATTTTTCTGTTCTTTTCCCACAACATCTCATTTTTGTTAAAAAATATGACACTTGGTTGTTGTATACTCTCTATCATTTGCTGTAGTAATTTATTTGTTAATCGTTGTGAATCAGCTTGTTATAGCATTCTAGTTAGACTTTCTCTGTGGGACATGAGGTCTTATACCTATTTTGGCTAACTTCTTCCTTTATTAGTGCCAAAAAAGTAGTTATCTTGACCAGATAATTGTAGCTAAGAGGACACATTTCAGATAAAAGCATAGCATGTGGACCATCGTTTTAAAGCAGTGTTTTTTTATGGAATCACTGCCTTGTTGACTCTGTGCTAAACTTTGCGAGATTACATTTTAGTTGCCTAGTTTATTGTGATTTCTCAATGTTTGCTGATATTCATTGCTCACCATGTTTTTTCAGTTTTGATGAGTTTCTGATGGATTTGAAGCAACCTAAACGGAAGAATATCAGACAAGAACGTAAAAAGGTTTACCTTCTTTTGGCTTAATTGATTCAAATGTGCTTGTCAATTGAGGATAATCTTTTTTGGAAACTTCCCAGATTCCTGCTCAAAATTTGCAAATGAAGCGACTTCGTGGAGACGAAATAAAGGTAATTATAAGGGAGAGATAGTTCTTTAATCGTACTCTTCAGTCACTTCTTTTACATTATCATATTCTTCACAGTATCTCATTAGCTTTGTTGCTTTCTGGACAGCTTACTTATAATTGTTTCCATTCACATTGCAGAGCAGCCACTGGGATGCCTTCTATAAATTCTACCGTAACACAACTGATAATCAGTTTGGTTTCACATTCTTCTTAACTTGTATTTTTTTTATTCTATACCTAACATCATGTTCTTGAAATGGTTGTTCATCTTCTGTCAGCATTCATACATATCGCGATGCCGCACCATTCTTGTTGACTCACTCTTCAACTTGAATTCCGGTGTCCATTTCTTCTTATTTACAATGTCACATAGTTTCACCTAGGTTGATCTATTTTTTTATCTGCACCCTTTGTAAACATGTATGATTTTTTTTAAAGGATTAATATTTAAGTGTGCTACTGTGTATTGAGAACTGAAGTTAATCAAAGCAAGGAAGGAATAGAAGTTTAGCAAATTATCAGGCAAAAAGGTCATTTAATCGAGCTAAATGGCCACTTAAACAGATACATTTGGCCATTGTGTAGTGTTTAAACAGGCTAAATTGCCATTTAGGAAAAAAAGGATTGGAGTTTGAACTTTGAAGTAATTACTGATAAATGCATGTGACTGCTAGCACATTGCCTTCTACTTGAACTGAAAGAGGCAACAAAGTTTTAAGAACCATCACCGCGTGAGTGCGTGACCCCCTCACCTTTTTGCACTTTCTTTTTGTTACACGGCATATCTGTAGGTATTTGTGGTGACCATGCCTAGGCACGTTTTTCATTAACAGGGGCATATATGTAGGTATGAATTAAGATTGTATAGAATTCGCTAGTGCAGTAATGTAGGTTTCTGTATTTTCACTTGTAGCTAGGGAAGTAGGGATGCTTCCATAGGTCTTTTCTGTCCCATGTCCTCTGTTTTTGAAATCCGAATCTGTTAATTAAATGAGTTCTGTGGCGACCCAGTGATCCAGAGAAAGCAAAACTTGCATCCCTACTCATAGCTTACTTTTCACTGCAGTTGGGGCCGACCATACTTGACAAGGGATTTCTTTCACCTCTTGGGCGAAAAGATGGGGGAGAATGTGATGCTTATTGTTGCTGAAAAAGATGATAAACTAGTTGCTGGAGCTCTTAACCTTATTGGAGGTGATACACTGTTTGGCCGGTTATGGGGATGCCTGCCAGATGCTTACTTTCCCAATTTGCATTTTGAAGCTTGCTATTATCAGGTAATTTGCTCATGTTTAGAACCATATCTTTGGAACAATGCAATAATATGGTTTGTTTATAGAATTTGATATTGTCCAGGCGATTGAAGCAGCCATAGAGTTAAACCTGAGTAATGTGGAGGCAGGTGCTCAGGGAGAGCACAAGATCCAGCGTGGTTACCTCCCAGTGACAACTTACAGCTGCCACTACTTTTCAAATCCTGGTTTTGCGGCAGCTATTGGAAATTTTCTTACACATGAGACGGCTCAGGTATTTTCGTGTTGATATTTTGAACCAGTTTCTTGCCAAAACTATGTGATATCAACCTTGCTGTCTTTGTTCTACTCACTTCTGTGTGCTGAAAATAATCTTTTGTGGACACATATACAACTCTTTCATCTGAGTGCATAGTATCTGTAGTTAATCAGTGCCATCCACATCCAATGCCAAACTCACCTCCTAGATTGAGCACCACATCTGGAACCCTTACATCTGAAGCTTGTCATGTTTTGGTTTCAATATTTTCCACTAGATTAGCCTCACATTCTGATGGGCTGATTGGGTGCTCTAGTGGACGGCATCATCACCAATAGTTGATATACTCACACAAAAAAGAAATTATTACCTCAGCAATACCACTTTTTGGAGCTAATGCGATTCTATGTTAGCCAGTGCTGAGTGTGACTAAGATCAGGACATCTTAGTAAACATGCATTGACTTTAGCAGTACTTTGTTGATACCATATATTAACGCATAAGGCATGATATCTTATTTCACCTTTTTCTAGCTTATTGTTGAGAAATTCTATTTTTCCTCCCGGTGGTAACTGCTGACACTACCAGTGTGGCGTTTATTTTATGTCAGACACTTATTTTCTTAAAATCCTTAGGGAAATGCAGTTTATTATGATGGACAGTTTGCATACCTTTCTGCCTTTTCCTGAAACTCCCAACTAATATTCTTGGTGTTAATAATACCAGGTTAAGCGTGCTATTAAGGTCCTTCATGATTCGGGTCCATACAAGGAAGACATACTGAAAGAATTTGCAGCTCAACAAGGCATCGACCTGTAGAACACAGAAGGAGCTAACACTTTGCATACTGTTTTATAGGATTAGCATCTTTTATGTAGCAACAGGAATACGGGTAATCCCATCAACTATACCAAATTACGGATCCGACATTTGTACACTGCTAGGAATGTAAATATTCAACATGTAAATCTAAAACCATTGGCTCCAATGGTCAACATCTAAACCCAAACATTCTGCGATACTATGCATCTCTGCGTCAGAATTCAGAAATGCTTTCTGGGCGCTATTACCTCAGCCTTAAATAAACCTAGCCGTCAAGTTGGGAGCTATAGCTATACTTGTTTCTACTTTTCCCAACAGAAGGATCTGATGCTTCATGTATATTGCGCTCTTTTCTAATGGGATCTCTGATGCTTCATGT'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def reshape_it(input_tensor: torch.Tensor, n=215) -> torch.Tensor:\n",
    "    # 获取第一个维度的大小\n",
    "    batch_size = input_tensor.shape[0]\n",
    "    \n",
    "    # 计算每个样本所需的元素数\n",
    "    required_elements_per_sample = n * n\n",
    "    \n",
    "    # 将输入张量展平，并计算每个样本的元素数\n",
    "    flat_tensor = input_tensor.view(batch_size, -1)\n",
    "    num_elements = flat_tensor.size(1)\n",
    "    \n",
    "    # 如果当前样本元素数不足，进行填充\n",
    "    if num_elements < required_elements_per_sample:\n",
    "        # 计算填充元素的数量\n",
    "        padding_elements = required_elements_per_sample - num_elements\n",
    "        # 对所有样本进行填充\n",
    "        padded_tensor = torch.cat((flat_tensor, torch.zeros(batch_size, padding_elements, device=input_tensor.device)), dim=1)\n",
    "    else:\n",
    "        # 如果元素数足够或过多，进行截断\n",
    "        padded_tensor = flat_tensor[:, :required_elements_per_sample]\n",
    "    \n",
    "    # 将调整后的张量重新调整为 (batch_size, n, n) 的形状\n",
    "    reshaped_tensor = padded_tensor.view(batch_size, n, n)\n",
    "    \n",
    "    # 扩展维度并重复3次，形成 (batch_size, 3, n, n)\n",
    "    reshaped_tensor = reshaped_tensor.unsqueeze(1).expand(-1, 3, -1, -1)\n",
    "    \n",
    "    return reshaped_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 46398])\n",
      "torch.Size([32, 3, 215, 215])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(32, 1, 46398)\n",
    "print(a.shape)\n",
    "a = reshape_it(a)\n",
    "print(a.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "tensor([[ 2.0702,  0.0406,  1.1342,  0.0933],\n",
      "        [ 0.7887, -1.5404,  0.3875, -0.9056],\n",
      "        [ 0.0022, -1.8251,  1.3807,  1.8410]])\n",
      "tensor([[ True,  True,  True, False],\n",
      "        [False,  True,  True,  True],\n",
      "        [False, False,  True, False]])\n",
      "torch.Size([3, 4])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0933],\n",
      "        [ 0.7887, -0.0000,  0.0000, -0.0000],\n",
      "        [ 0.0022, -1.8251,  0.0000,  1.8410]])\n"
     ]
    }
   ],
   "source": [
    "def mutate_tensor(input_tensor: torch.Tensor, mutation_rate=0.5) -> torch.Tensor:\n",
    "    # 获取张量的形状\n",
    "    num_samples, num_features = input_tensor.shape\n",
    "    \n",
    "    # 计算需要置零的位置数量\n",
    "    num_mutations = int(num_features * mutation_rate)\n",
    "    \n",
    "    # 生成随机位置\n",
    "    mutation_indices = torch.rand(num_samples, num_features) < mutation_rate\n",
    "    print(mutation_indices)\n",
    "    # 创建一个掩码\n",
    "    mask = ~mutation_indices\n",
    "    \n",
    "    # 使用掩码将选定位置的值变为0\n",
    "    mutated_tensor = input_tensor * mask\n",
    "    \n",
    "    return mutated_tensor\n",
    "\n",
    "import torch\n",
    "\n",
    "a = torch.randn(3, 4)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "a = mutate_tensor(a)\n",
    "print(a.shape)\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2350, 0.8241, 0.7370, 0.2785, 0.8987]])\n",
      "tensor([[False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(1, 5)\n",
    "print(a)\n",
    "a = a < 0.2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成不均匀分布的数据\n",
    "data = torch.cat([torch.randn(1000, 1) * 0.5 + 2, torch.randn(1000, 1) * 5 - 2], dim=0)\n",
    "\n",
    "# 定义没有BN层的简单网络\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 定义有BN层的简单网络\n",
    "class SimpleNetWithBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNetWithBN, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 10)\n",
    "        self.bn1 = nn.BatchNorm1d(10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 初始化网络\n",
    "net = SimpleNet()\n",
    "net_bn = SimpleNetWithBN()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "optimizer_bn = optim.SGD(net_bn.parameters(), lr=0.01)\n",
    "\n",
    "# 定义目标\n",
    "target = torch.ones_like(data)\n",
    "\n",
    "# 训练网络\n",
    "def train(net, optimizer, data, target):\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = net(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return output\n",
    "\n",
    "# 训练若干轮次\n",
    "outputs_no_bn = []\n",
    "outputs_bn = []\n",
    "for epoch in range(20):\n",
    "    output_no_bn = train(net, optimizer, data, target)\n",
    "    output_bn = train(net_bn, optimizer_bn, data, target)\n",
    "    outputs_no_bn.append(output_no_bn.detach().numpy())\n",
    "    outputs_bn.append(output_bn.detach().numpy())\n",
    "\n",
    "# 可视化结果\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 没有BN层的网络输出分布\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(outputs_no_bn[-1], bins=30, alpha=0.6, color='blue')\n",
    "plt.title('Without BatchNorm')\n",
    "plt.xlabel('Output value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 有BN层的网络输出分布\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(outputs_bn[-1], bins=30, alpha=0.6, color='green')\n",
    "plt.title('With BatchNorm')\n",
    "plt.xlabel('Output value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96mThis is red text\u001b[0m\n",
      "\u001b[4;94mThis is bold blue text\u001b[0m\n",
      "\u001b[42m\u001b[90mThis is black text on green background\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class bcolors:\n",
    "    # Regular colors\n",
    "    PURPLE = '\\033[95m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    WHITE = '\\033[97m'\n",
    "    BLACK = '\\033[90m'\n",
    "    CYAN = '\\033[96m'\n",
    "    \n",
    "    # Bright colors\n",
    "    BRIGHT_BLUE = '\\033[94;1m'\n",
    "    BRIGHT_GREEN = '\\033[92;1m'\n",
    "    BRIGHT_YELLOW = '\\033[93;1m'\n",
    "    BRIGHT_RED = '\\033[91;1m'\n",
    "    BRIGHT_WHITE = '\\033[97;1m'\n",
    "    BRIGHT_BLACK = '\\033[90;1m'\n",
    "    BRIGHT_CYAN = '\\033[96;1m'\n",
    "    \n",
    "    # Background colors\n",
    "    BG_BLUE = '\\033[44m'\n",
    "    BG_GREEN = '\\033[42m'\n",
    "    BG_YELLOW = '\\033[43m'\n",
    "    BG_RED = '\\033[41m'\n",
    "    BG_WHITE = '\\033[47m'\n",
    "    BG_BLACK = '\\033[40m'\n",
    "    BG_CYAN = '\\033[46m'\n",
    "    BG_PURPLE = '\\033[45m'\n",
    "    \n",
    "    # Additional text styles\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    REVERSED = '\\033[7m'\n",
    "    RESET = '\\033[0m'\n",
    "    \n",
    "    # Combine styles\n",
    "    BOLD_BLUE = '\\033[4;94m'\n",
    "    UNDERLINE_GREEN = '\\033[4;92m'\n",
    "    BOLD_UNDERLINE_RED = '\\033[1;4;91m'\n",
    "\n",
    "# 示例使用\n",
    "print(f\"{bcolors.CYAN}This is red text{bcolors.RESET}\")\n",
    "print(f\"{bcolors.BOLD_BLUE}This is bold blue text{bcolors.RESET}\")\n",
    "print(f\"{bcolors.BG_GREEN}{bcolors.BLACK}This is black text on green background{bcolors.RESET}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\u001b[4;34m下划线蓝色文本\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('\\033[4;34m' + '下划线蓝色文本' + '\\033[0m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1+0.2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
